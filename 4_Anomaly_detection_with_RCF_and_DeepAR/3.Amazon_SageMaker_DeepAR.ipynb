{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab3. Amazon SageMaker DeepAR\n",
    "\n",
    "This notebook shows how to apply the SageMaker [DeepAR built-in algorithm](https://docs.aws.amazon.com/sagemaker/latest/dg/deepar.html). DeepAR forecasting algorithm is a supervised learning algorithm for forecasting scalar (one-dimensional) time series using recurrent neural networks (RNN) to produce both point and probabilistic forecasts.The DeepAR forecasting algorithm can provide better forecast accuracies compared to classical forecasting techniques such as Autoregressive Integrated Moving Average (ARIMA) or Exponential Smoothing (ES), both of which are implemented in many open-source and commercial software packages for forecasting. \n",
    "\n",
    "## Table Of Contents\n",
    "The overall process for this is:\n",
    "\n",
    "1. Setup\n",
    "1. Data Preparation\n",
    "1. Training the DeepAR Model\n",
    "1. Prediction\n",
    "1. Plotting the Prediction\n",
    "\n",
    "To get started, simply execute the cells below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup \n",
    "\n",
    "We use variables and dataframes that we stored in Lab1. Please make sure you already finished 1st step.\n",
    "- [1.Exploratory_Data_Analysis.ipynb](1.Exploratory_Data_Analysis.ipynb)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation\n",
    "\n",
    "We will divide our clikstream events by page so that each page has its own clickstream timesereis.\n",
    "\n",
    "**Note**\n",
    "> If you went through the [3rd Hands on Lab](../3_Automate_sales_projections_with_Amazon_Forecast/README.md) of Amazon forecast service. You may consider the pages as products (SKU) sold in retail store.  \n",
    "> If we use Amazon Forecast, page click data will be target timeseries and other series (users, urls) will be related timesreies. \n",
    "\n",
    "We will predict the number of clicks in 10 minutes by referring to the number of visitors. To do this, we use the number of clicks as the target feature and the number of users as the dynamic feature.\n",
    "\n",
    "Change the data to the format that DeepAR algorithm use. The records in your input files should contain the following fields:\n",
    "\n",
    "* **start** : The start timestamp. A string with the format YYYY-MM-DD HH:MM:SS.\n",
    "* **target** : An array of floating-point values or integers that represent the time series. Here, we will use clickstream counts in 10 minutes for forecasting value.\n",
    "* **dynamic_feat (optional)** : An array of arrays of floating-point values or integers that represents the vector of custom feature time series. Here, we will use the number of visitors in 10 minutes for dynamic features.\n",
    "* **cat (optional)** : An array of categorical features that can be used to encode the groups that the record belongs to. We do not use categorical values in this example.\n",
    "\n",
    "```python\n",
    "# example:\n",
    "{\"start\": \"2012-03-01 00:00:00\", \"target\": [24.0, 22.0, 20.0, 17.0, ...], \"dynamic_feat\": [[13, 14, 8, ...]]}\n",
    "```\n",
    "\n",
    "For more information regarding input/outpot format of DeepAR : https://docs.aws.amazon.com/sagemaker/latest/dg/deepar.html#deepar-inputoutput\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "for index, url in zip(range(len(urls)), urls):\n",
    "    agg_click_users = filtered_clickstream[filtered_clickstream['url'] == url].set_index('timestamp').resample('10T')\n",
    "    clicks = agg_click_users.sum()['clickstream_id']\n",
    "    users  = agg_click_users.nunique()['user_session_id']\n",
    "    \n",
    "    data = {'start' : str(agg_click_users.nunique().index[0]),\n",
    "            'target': list(clicks.values.astype('float')),\n",
    "            'dynamic_feat': [list(users.values.astype('float'))]\n",
    "            }\n",
    "    training_data.append(data)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert the dict type above into a json file.  \n",
    "Write training and test files in JSON Lines, and upload to S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def write_dicts_to_file(path, data):\n",
    "    with open(path, 'wb') as fp:\n",
    "        for row in training_data:\n",
    "            fp.write(json.dumps(row).encode(\"utf-8\"))\n",
    "            fp.write(\"\\n\".encode('utf-8'))\n",
    "            \n",
    "write_dicts_to_file(\"train.json\", training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-308961792850/deepar-clickstream/train.json'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "s3_bucket = sagemaker.Session().default_bucket()  # replace with an existing bucket if needed\n",
    "s3_prefix = 'deepar-clickstream'    # prefix used for all data stored within the bucket\n",
    "\n",
    "role = sagemaker.get_execution_role()             # IAM role to use by SageMaker\n",
    "\n",
    "train_s3 = sagemaker_session.upload_data(path='train.json', key_prefix=s3_prefix)\n",
    "train_s3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the status of the upload by skiming the uploaded file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"start\": \"2012-03-01 00:00:00\", \"target\": [24.0, 22.0, 20.0, 17.0, 15.0, 12.0, 15.0, 10.0, 14.0, 9....\n"
     ]
    }
   ],
   "source": [
    "import s3fs\n",
    "\n",
    "s3filesystem = s3fs.S3FileSystem()\n",
    "with s3filesystem.open(train_s3, 'rb') as fp:\n",
    "    print(fp.readline().decode(\"utf-8\")[:100] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training the DeepAR Model\n",
    "\n",
    "Just like other built-in algorithms, we need to define Estimator with algorhtim and hyperparameters and fit the model with the training data that we prepared above.\n",
    "\n",
    "We are using the [Python SageMaker SDK](https://sagemaker.readthedocs.io/en/stable/index.html) to:\n",
    "\n",
    "1. Create our [Estimator](https://sagemaker.readthedocs.io/en/stable/estimators.html) defining the algorithm and fitting/hyper-parameters\n",
    "2. Define our [data channels](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-training-algo-running-container.html#your-algorithms-training-algo-running-container-inputdataconfig) to fit and validate on\n",
    "3. [Fit](https://sagemaker.readthedocs.io/en/stable/estimators.html#sagemaker.estimator.Estimator.fit) a model to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "import datetime \n",
    "\n",
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "# we use 10 minutes frequency for the time series\n",
    "freq = datetime.timedelta(minutes=10)\n",
    "\n",
    "# we predict for 24 hours and use same context length with prediction length.\n",
    "prediction_length = 24 * 6\n",
    "context_length = 24 * 6\n",
    "\n",
    "image_name = sagemaker.amazon.amazon_estimator.get_image_uri(region, \"forecasting-deepar\", \"latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "estimator = sagemaker.estimator.Estimator(\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    image_name=image_name,\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.c4.2xlarge',\n",
    "    base_job_name='deepar-clickstream'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to set some hyperparameters. Some of them are related to the algorithm and some others are related to the training job. \n",
    "- `time_freq` : The granularity of the time series in the dataset. (M, W, D, H, min, ...)\n",
    "- `context_length` : The number of time-points that the model gets to see before making the prediction. \n",
    "- `prediction_length` : The number of time-steps that the model is trained to predict (forecast horizon)\n",
    "- `num_dynamic_feat` : The number of dynamic_feat provided in the data (default:`auto`) \n",
    "- `epochs` : The maximum number of passes over the training data\n",
    "- `early_stopping_patience` : Training stops when no progress is made within the specified number of `epochs`.\n",
    "- `mini_batch_size` : The size of mini-batches used during training\n",
    "- `learning_rate` : The learning rate used in training\n",
    "\n",
    "For more information, refer to the [DeepAR document](https://docs.aws.amazon.com/sagemaker/latest/dg/deepar_hyperparameters.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"time_freq\": '10min',\n",
    "    \"context_length\": str(context_length),\n",
    "    \"prediction_length\": str(prediction_length),\n",
    "    \"num_dynamic_feat\" : \"auto\",\n",
    "    \"epochs\": \"400\",\n",
    "    \"early_stopping_patience\": \"40\",\n",
    "    \"mini_batch_size\": \"64\",\n",
    "    \"learning_rate\": \"5E-4\"\n",
    "}\n",
    "estimator.set_hyperparameters(**hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to launch the training job. SageMaker will start an EC2 instance, download the data from S3, start training the model and save the trained model. Training will take about 20 minutes in c4.2xlarge instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.2 ms, sys: 5 Âµs, total: 12.2 ms\n",
      "Wall time: 217 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_channels = {\n",
    "    \"train\": train_s3\n",
    "}\n",
    "\n",
    "estimator.fit(data_channels, wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-04 07:33:17 Starting - Starting the training job...\n",
      "2020-10-04 07:33:18 Starting - Launching requested ML instances......\n",
      "2020-10-04 07:34:22 Starting - Preparing the instances for training...\n",
      "2020-10-04 07:35:09 Downloading - Downloading input data...\n",
      "2020-10-04 07:35:31 Training - Downloading the training image.\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:35:53 INFO 139662618720064] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'num_dynamic_feat': u'auto', u'dropout_rate': u'0.10', u'mini_batch_size': u'128', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'num_eval_samples': u'100', u'learning_rate': u'0.001', u'num_cells': u'40', u'num_layers': u'2', u'embedding_dimension': u'10', u'_kvstore': u'auto', u'_num_kv_servers': u'auto', u'cardinality': u'auto', u'likelihood': u'student-t', u'early_stopping_patience': u''}\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:35:53 INFO 139662618720064] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'num_dynamic_feat': u'auto', u'learning_rate': u'5E-4', u'prediction_length': u'144', u'epochs': u'400', u'time_freq': u'10min', u'context_length': u'144', u'mini_batch_size': u'64', u'early_stopping_patience': u'40'}\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:35:53 INFO 139662618720064] Final configuration: {u'dropout_rate': u'0.10', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'num_eval_samples': u'100', u'learning_rate': u'5E-4', u'num_layers': u'2', u'epochs': u'400', u'embedding_dimension': u'10', u'num_cells': u'40', u'_num_kv_servers': u'auto', u'mini_batch_size': u'64', u'likelihood': u'student-t', u'num_dynamic_feat': u'auto', u'cardinality': u'auto', u'_num_gpus': u'auto', u'prediction_length': u'144', u'time_freq': u'10min', u'context_length': u'144', u'_kvstore': u'auto', u'early_stopping_patience': u'40'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:35:53 INFO 139662618720064] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:35:54 INFO 139662618720064] Using early stopping with patience 40\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:35:54 INFO 139662618720064] [cardinality=auto] `cat` field was NOT found in the file `/opt/ml/input/data/train/train.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:35:54 INFO 139662618720064] [num_dynamic_feat=auto] `dynamic_feat` field was found in the file `/opt/ml/input/data/train/train.json` and will be used for training.\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:35:54 INFO 139662618720064] [num_dynamic_feat=auto] Inferred value of num_dynamic_feat=1 from dataset.\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:35:54 INFO 139662618720064] Training set statistics:\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:35:54 INFO 139662618720064] Integer time series\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:35:54 INFO 139662618720064] number of time series: 16\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:35:54 INFO 139662618720064] number of observations: 34556\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:35:54 INFO 139662618720064] mean target length: 2159\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:35:54 INFO 139662618720064] min/mean/max target: 0.0/12.1908206968/477.0\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:35:54 INFO 139662618720064] mean abs(target): 12.1908206968\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:35:54 INFO 139662618720064] contains missing values: no\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:35:54 INFO 139662618720064] Small number of time series. Doing 40 passes over dataset with prob 1.0 per epoch.\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:35:54 INFO 139662618720064] No test channel found not running evaluations\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:35:54 INFO 139662618720064] nvidia-smi took: 0.0251989364624 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:35:54 INFO 139662618720064] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:35:54 INFO 139662618720064] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 2218.140125274658, \"sum\": 2218.140125274658, \"min\": 2218.140125274658}}, \"EndTime\": 1601796956.415348, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601796954.196309}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:35:56 INFO 139662618720064] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 3502.686023712158, \"sum\": 3502.686023712158, \"min\": 3502.686023712158}}, \"EndTime\": 1601796957.699138, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601796956.415429}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:35:58 INFO 139662618720064] Epoch[0] Batch[0] avg_epoch_loss=4.075746\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:35:58 INFO 139662618720064] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=4.07574558258\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:00 INFO 139662618720064] Epoch[0] Batch[5] avg_epoch_loss=3.749502\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:00 INFO 139662618720064] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=3.7495024999\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:00 INFO 139662618720064] Epoch[0] Batch [5]#011Speed: 190.05 samples/sec#011loss=3.749502\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:01 INFO 139662618720064] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 400, \"sum\": 400.0, \"min\": 400}, \"update.time\": {\"count\": 1, \"max\": 4030.1477909088135, \"sum\": 4030.1477909088135, \"min\": 4030.1477909088135}}, \"EndTime\": 1601796961.729479, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601796957.699243}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:01 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=153.835078988 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:01 INFO 139662618720064] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:01 INFO 139662618720064] #quality_metric: host=algo-1, epoch=0, train loss <loss>=3.64237034321\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:01 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:01 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_0d085e75-f599-4657-8768-9b3b8e011d5c-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 110.01396179199219, \"sum\": 110.01396179199219, \"min\": 110.01396179199219}}, \"EndTime\": 1601796961.840169, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601796961.729581}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:02 INFO 139662618720064] Epoch[1] Batch[0] avg_epoch_loss=3.239583\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:02 INFO 139662618720064] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=3.23958301544\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:04 INFO 139662618720064] Epoch[1] Batch[5] avg_epoch_loss=3.315229\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:04 INFO 139662618720064] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=3.31522921721\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:04 INFO 139662618720064] Epoch[1] Batch [5]#011Speed: 166.10 samples/sec#011loss=3.315229\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:06 INFO 139662618720064] Epoch[1] Batch[10] avg_epoch_loss=3.213666\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:06 INFO 139662618720064] #quality_metric: host=algo-1, epoch=1, batch=10 train loss <loss>=3.09179005623\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:06 INFO 139662618720064] Epoch[1] Batch [10]#011Speed: 190.47 samples/sec#011loss=3.091790\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:06 INFO 139662618720064] processed a total of 666 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4525.310039520264, \"sum\": 4525.310039520264, \"min\": 4525.310039520264}}, \"EndTime\": 1601796966.365607, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601796961.840238}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:06 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=147.168398581 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:06 INFO 139662618720064] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:06 INFO 139662618720064] #quality_metric: host=algo-1, epoch=1, train loss <loss>=3.21366596222\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:06 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:06 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_a7842019-1024-4916-ac9f-2c0210236260-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 112.38288879394531, \"sum\": 112.38288879394531, \"min\": 112.38288879394531}}, \"EndTime\": 1601796966.478553, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601796966.365687}\n",
      "\u001b[0m\n",
      "\n",
      "2020-10-04 07:35:51 Training - Training image download completed. Training in progress.\u001b[34m[10/04/2020 07:36:07 INFO 139662618720064] Epoch[2] Batch[0] avg_epoch_loss=3.216480\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:07 INFO 139662618720064] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=3.21648049355\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:09 INFO 139662618720064] Epoch[2] Batch[5] avg_epoch_loss=3.143059\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:09 INFO 139662618720064] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=3.14305901527\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:09 INFO 139662618720064] Epoch[2] Batch [5]#011Speed: 183.75 samples/sec#011loss=3.143059\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:10 INFO 139662618720064] Epoch[2] Batch[10] avg_epoch_loss=3.078658\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:10 INFO 139662618720064] #quality_metric: host=algo-1, epoch=2, batch=10 train loss <loss>=3.00137720108\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:10 INFO 139662618720064] Epoch[2] Batch [10]#011Speed: 189.85 samples/sec#011loss=3.001377\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:10 INFO 139662618720064] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4242.134094238281, \"sum\": 4242.134094238281, \"min\": 4242.134094238281}}, \"EndTime\": 1601796970.720834, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601796966.478627}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:10 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=154.163042613 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:10 INFO 139662618720064] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:10 INFO 139662618720064] #quality_metric: host=algo-1, epoch=2, train loss <loss>=3.07865819064\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:10 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:10 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_7839e15c-032a-47e4-a73d-5ead4962c444-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 110.19015312194824, \"sum\": 110.19015312194824, \"min\": 110.19015312194824}}, \"EndTime\": 1601796970.831619, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601796970.720916}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:11 INFO 139662618720064] Epoch[3] Batch[0] avg_epoch_loss=2.827902\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:11 INFO 139662618720064] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=2.82790160179\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:13 INFO 139662618720064] Epoch[3] Batch[5] avg_epoch_loss=2.987466\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:13 INFO 139662618720064] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=2.9874663353\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:13 INFO 139662618720064] Epoch[3] Batch [5]#011Speed: 187.80 samples/sec#011loss=2.987466\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:14 INFO 139662618720064] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3846.0640907287598, \"sum\": 3846.0640907287598, \"min\": 3846.0640907287598}}, \"EndTime\": 1601796974.677826, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601796970.831691}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:14 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=165.6183621 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:14 INFO 139662618720064] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:14 INFO 139662618720064] #quality_metric: host=algo-1, epoch=3, train loss <loss>=2.92979209423\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:14 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:14 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_f467a768-3de6-46e5-8ee1-4f2916e8df5f-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 107.2700023651123, \"sum\": 107.2700023651123, \"min\": 107.2700023651123}}, \"EndTime\": 1601796974.785735, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601796974.677912}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:15 INFO 139662618720064] Epoch[4] Batch[0] avg_epoch_loss=2.832989\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:15 INFO 139662618720064] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=2.83298921585\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:17 INFO 139662618720064] Epoch[4] Batch[5] avg_epoch_loss=2.822954\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:17 INFO 139662618720064] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=2.82295385997\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:17 INFO 139662618720064] Epoch[4] Batch [5]#011Speed: 190.57 samples/sec#011loss=2.822954\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:18 INFO 139662618720064] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3832.1290016174316, \"sum\": 3832.1290016174316, \"min\": 3832.1290016174316}}, \"EndTime\": 1601796978.618013, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601796974.785814}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:18 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=167.003463931 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:18 INFO 139662618720064] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:18 INFO 139662618720064] #quality_metric: host=algo-1, epoch=4, train loss <loss>=2.83537068367\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:18 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:18 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_d31bb58c-9e10-47f2-90d6-7b024b9c1883-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 121.0629940032959, \"sum\": 121.0629940032959, \"min\": 121.0629940032959}}, \"EndTime\": 1601796978.739697, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601796978.618099}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:19 INFO 139662618720064] Epoch[5] Batch[0] avg_epoch_loss=2.690667\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:19 INFO 139662618720064] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=2.6906671524\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:21 INFO 139662618720064] Epoch[5] Batch[5] avg_epoch_loss=2.776643\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:21 INFO 139662618720064] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=2.77664252122\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:21 INFO 139662618720064] Epoch[5] Batch [5]#011Speed: 188.38 samples/sec#011loss=2.776643\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:22 INFO 139662618720064] Epoch[5] Batch[10] avg_epoch_loss=2.691411\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:22 INFO 139662618720064] #quality_metric: host=algo-1, epoch=5, batch=10 train loss <loss>=2.58913359642\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:22 INFO 139662618720064] Epoch[5] Batch [10]#011Speed: 186.95 samples/sec#011loss=2.589134\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:22 INFO 139662618720064] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4201.092958450317, \"sum\": 4201.092958450317, \"min\": 4201.092958450317}}, \"EndTime\": 1601796982.940912, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601796978.739758}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:22 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=153.76532869 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:22 INFO 139662618720064] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:22 INFO 139662618720064] #quality_metric: host=algo-1, epoch=5, train loss <loss>=2.69141119177\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:22 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:23 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_92d38712-60f3-4f71-95d8-2761b0ab7888-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 102.91314125061035, \"sum\": 102.91314125061035, \"min\": 102.91314125061035}}, \"EndTime\": 1601796983.044442, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601796982.940986}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:23 INFO 139662618720064] Epoch[6] Batch[0] avg_epoch_loss=2.527387\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:23 INFO 139662618720064] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=2.52738690376\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:25 INFO 139662618720064] Epoch[6] Batch[5] avg_epoch_loss=2.583894\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:25 INFO 139662618720064] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=2.58389413357\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:25 INFO 139662618720064] Epoch[6] Batch [5]#011Speed: 188.08 samples/sec#011loss=2.583894\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:26 INFO 139662618720064] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3833.8799476623535, \"sum\": 3833.8799476623535, \"min\": 3833.8799476623535}}, \"EndTime\": 1601796986.878457, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601796983.044513}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:26 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=164.58020133 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:26 INFO 139662618720064] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:26 INFO 139662618720064] #quality_metric: host=algo-1, epoch=6, train loss <loss>=2.56626226902\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:26 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:26 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_36d87931-ea70-49d4-9156-74af6ed28420-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 108.79087448120117, \"sum\": 108.79087448120117, \"min\": 108.79087448120117}}, \"EndTime\": 1601796986.987908, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601796986.878531}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:27 INFO 139662618720064] Epoch[7] Batch[0] avg_epoch_loss=2.601110\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:27 INFO 139662618720064] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=2.60110998154\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:29 INFO 139662618720064] Epoch[7] Batch[5] avg_epoch_loss=2.573926\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:29 INFO 139662618720064] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=2.57392569383\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:29 INFO 139662618720064] Epoch[7] Batch [5]#011Speed: 185.99 samples/sec#011loss=2.573926\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:31 INFO 139662618720064] Epoch[7] Batch[10] avg_epoch_loss=2.571833\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:31 INFO 139662618720064] #quality_metric: host=algo-1, epoch=7, batch=10 train loss <loss>=2.56932191849\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:31 INFO 139662618720064] Epoch[7] Batch [10]#011Speed: 188.78 samples/sec#011loss=2.569322\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:31 INFO 139662618720064] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4210.2789878845215, \"sum\": 4210.2789878845215, \"min\": 4210.2789878845215}}, \"EndTime\": 1601796991.198327, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601796986.987979}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:31 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=157.704736157 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:31 INFO 139662618720064] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:31 INFO 139662618720064] #quality_metric: host=algo-1, epoch=7, train loss <loss>=2.57183306867\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:31 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:31 INFO 139662618720064] Epoch[8] Batch[0] avg_epoch_loss=2.514980\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:31 INFO 139662618720064] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=2.51497983932\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:33 INFO 139662618720064] Epoch[8] Batch[5] avg_epoch_loss=2.535532\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:33 INFO 139662618720064] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=2.53553187847\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:33 INFO 139662618720064] Epoch[8] Batch [5]#011Speed: 186.05 samples/sec#011loss=2.535532\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:35 INFO 139662618720064] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3868.3481216430664, \"sum\": 3868.3481216430664, \"min\": 3868.3481216430664}}, \"EndTime\": 1601796995.067218, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601796991.198406}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:35 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=163.371953571 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:35 INFO 139662618720064] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:35 INFO 139662618720064] #quality_metric: host=algo-1, epoch=8, train loss <loss>=2.50490820408\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:35 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:35 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_1dc40a64-71f8-4a50-a1e4-ed730024df1c-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 113.11602592468262, \"sum\": 113.11602592468262, \"min\": 113.11602592468262}}, \"EndTime\": 1601796995.180938, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601796995.067303}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:35 INFO 139662618720064] Epoch[9] Batch[0] avg_epoch_loss=2.354897\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:35 INFO 139662618720064] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=2.35489654541\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:37 INFO 139662618720064] Epoch[9] Batch[5] avg_epoch_loss=2.382313\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:37 INFO 139662618720064] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=2.38231269519\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:37 INFO 139662618720064] Epoch[9] Batch [5]#011Speed: 187.69 samples/sec#011loss=2.382313\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:39 INFO 139662618720064] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3899.4030952453613, \"sum\": 3899.4030952453613, \"min\": 3899.4030952453613}}, \"EndTime\": 1601796999.080497, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601796995.181024}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:39 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=160.27575765 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:39 INFO 139662618720064] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:39 INFO 139662618720064] #quality_metric: host=algo-1, epoch=9, train loss <loss>=2.33851840496\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:39 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:39 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_1f62e652-2bdd-489b-98c2-80f9316366d8-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 107.70797729492188, \"sum\": 107.70797729492188, \"min\": 107.70797729492188}}, \"EndTime\": 1601796999.188868, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601796999.08058}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:39 INFO 139662618720064] Epoch[10] Batch[0] avg_epoch_loss=2.323233\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:39 INFO 139662618720064] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=2.32323265076\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:41 INFO 139662618720064] Epoch[10] Batch[5] avg_epoch_loss=2.330728\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:41 INFO 139662618720064] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=2.3307278951\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:41 INFO 139662618720064] Epoch[10] Batch [5]#011Speed: 189.28 samples/sec#011loss=2.330728\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:43 INFO 139662618720064] Epoch[10] Batch[10] avg_epoch_loss=2.230922\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:43 INFO 139662618720064] #quality_metric: host=algo-1, epoch=10, batch=10 train loss <loss>=2.11115572453\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:43 INFO 139662618720064] Epoch[10] Batch [10]#011Speed: 185.90 samples/sec#011loss=2.111156\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:43 INFO 139662618720064] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4190.577030181885, \"sum\": 4190.577030181885, \"min\": 4190.577030181885}}, \"EndTime\": 1601797003.3796, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601796999.188953}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:43 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=154.389374072 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:43 INFO 139662618720064] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:43 INFO 139662618720064] #quality_metric: host=algo-1, epoch=10, train loss <loss>=2.23092236302\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:43 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:43 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_15994e8d-ad21-419a-826f-5673dc7b66be-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 106.72307014465332, \"sum\": 106.72307014465332, \"min\": 106.72307014465332}}, \"EndTime\": 1601797003.486934, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797003.379683}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:44 INFO 139662618720064] Epoch[11] Batch[0] avg_epoch_loss=2.156110\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:44 INFO 139662618720064] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=2.15610980988\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:45 INFO 139662618720064] Epoch[11] Batch[5] avg_epoch_loss=2.248940\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:45 INFO 139662618720064] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=2.24894011021\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:45 INFO 139662618720064] Epoch[11] Batch [5]#011Speed: 189.24 samples/sec#011loss=2.248940\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:47 INFO 139662618720064] Epoch[11] Batch[10] avg_epoch_loss=2.217598\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:47 INFO 139662618720064] #quality_metric: host=algo-1, epoch=11, batch=10 train loss <loss>=2.17998661995\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:47 INFO 139662618720064] Epoch[11] Batch [10]#011Speed: 186.10 samples/sec#011loss=2.179987\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:47 INFO 139662618720064] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4196.413993835449, \"sum\": 4196.413993835449, \"min\": 4196.413993835449}}, \"EndTime\": 1601797007.683492, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797003.487009}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:47 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=155.366012344 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:47 INFO 139662618720064] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:47 INFO 139662618720064] #quality_metric: host=algo-1, epoch=11, train loss <loss>=2.21759761464\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:47 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:47 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_1a4f0cb5-9da1-496a-b353-7a6af0adb732-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 101.93800926208496, \"sum\": 101.93800926208496, \"min\": 101.93800926208496}}, \"EndTime\": 1601797007.786066, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797007.683577}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:48 INFO 139662618720064] Epoch[12] Batch[0] avg_epoch_loss=2.292846\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:48 INFO 139662618720064] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=2.29284620285\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:50 INFO 139662618720064] Epoch[12] Batch[5] avg_epoch_loss=2.169287\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:50 INFO 139662618720064] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=2.16928684711\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:50 INFO 139662618720064] Epoch[12] Batch [5]#011Speed: 188.79 samples/sec#011loss=2.169287\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:51 INFO 139662618720064] Epoch[12] Batch[10] avg_epoch_loss=2.105532\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:51 INFO 139662618720064] #quality_metric: host=algo-1, epoch=12, batch=10 train loss <loss>=2.02902595997\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:51 INFO 139662618720064] Epoch[12] Batch [10]#011Speed: 190.85 samples/sec#011loss=2.029026\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:51 INFO 139662618720064] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4163.100957870483, \"sum\": 4163.100957870483, \"min\": 4163.100957870483}}, \"EndTime\": 1601797011.949305, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797007.786139}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:51 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=157.810543581 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:51 INFO 139662618720064] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:51 INFO 139662618720064] #quality_metric: host=algo-1, epoch=12, train loss <loss>=2.10553189841\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:51 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:52 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_cba3a39b-b594-4045-82e8-5594689d5cc7-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 110.2759838104248, \"sum\": 110.2759838104248, \"min\": 110.2759838104248}}, \"EndTime\": 1601797012.060159, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797011.949383}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:52 INFO 139662618720064] Epoch[13] Batch[0] avg_epoch_loss=2.151905\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:52 INFO 139662618720064] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=2.1519048214\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:54 INFO 139662618720064] Epoch[13] Batch[5] avg_epoch_loss=2.146342\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:54 INFO 139662618720064] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=2.14634199937\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:54 INFO 139662618720064] Epoch[13] Batch [5]#011Speed: 187.23 samples/sec#011loss=2.146342\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:55 INFO 139662618720064] processed a total of 614 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3843.7910079956055, \"sum\": 3843.7910079956055, \"min\": 3843.7910079956055}}, \"EndTime\": 1601797015.904085, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797012.060233}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:55 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=159.732901905 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:55 INFO 139662618720064] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:55 INFO 139662618720064] #quality_metric: host=algo-1, epoch=13, train loss <loss>=2.16200222969\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:55 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:56 INFO 139662618720064] Epoch[14] Batch[0] avg_epoch_loss=1.969120\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:56 INFO 139662618720064] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=1.96912026405\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:58 INFO 139662618720064] Epoch[14] Batch[5] avg_epoch_loss=2.027004\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:58 INFO 139662618720064] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=2.02700382471\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:58 INFO 139662618720064] Epoch[14] Batch [5]#011Speed: 187.25 samples/sec#011loss=2.027004\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:59 INFO 139662618720064] processed a total of 600 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3900.0368118286133, \"sum\": 3900.0368118286133, \"min\": 3900.0368118286133}}, \"EndTime\": 1601797019.80467, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797015.904171}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:59 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=153.839604433 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:59 INFO 139662618720064] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:59 INFO 139662618720064] #quality_metric: host=algo-1, epoch=14, train loss <loss>=2.04225124121\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:59 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:36:59 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_b24fb7d4-5aea-4010-98a3-6749647e779f-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 124.9399185180664, \"sum\": 124.9399185180664, \"min\": 124.9399185180664}}, \"EndTime\": 1601797019.930227, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797019.804757}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:00 INFO 139662618720064] Epoch[15] Batch[0] avg_epoch_loss=2.108050\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:00 INFO 139662618720064] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=2.10805010796\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:02 INFO 139662618720064] Epoch[15] Batch[5] avg_epoch_loss=2.097496\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:02 INFO 139662618720064] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=2.09749599298\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:02 INFO 139662618720064] Epoch[15] Batch [5]#011Speed: 187.42 samples/sec#011loss=2.097496\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:04 INFO 139662618720064] Epoch[15] Batch[10] avg_epoch_loss=2.069587\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:04 INFO 139662618720064] #quality_metric: host=algo-1, epoch=15, batch=10 train loss <loss>=2.03609516621\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:04 INFO 139662618720064] Epoch[15] Batch [10]#011Speed: 188.36 samples/sec#011loss=2.036095\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:04 INFO 139662618720064] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4206.493139266968, \"sum\": 4206.493139266968, \"min\": 4206.493139266968}}, \"EndTime\": 1601797024.136836, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797019.930286}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:04 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=157.846818608 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:04 INFO 139662618720064] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:04 INFO 139662618720064] #quality_metric: host=algo-1, epoch=15, train loss <loss>=2.06958652626\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:04 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:04 INFO 139662618720064] Epoch[16] Batch[0] avg_epoch_loss=2.027693\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:04 INFO 139662618720064] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=2.02769303322\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:06 INFO 139662618720064] Epoch[16] Batch[5] avg_epoch_loss=2.022931\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:06 INFO 139662618720064] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=2.02293066184\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:06 INFO 139662618720064] Epoch[16] Batch [5]#011Speed: 189.13 samples/sec#011loss=2.022931\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:08 INFO 139662618720064] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3882.533073425293, \"sum\": 3882.533073425293, \"min\": 3882.533073425293}}, \"EndTime\": 1601797028.019885, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797024.136915}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:08 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=162.002968991 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:08 INFO 139662618720064] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:08 INFO 139662618720064] #quality_metric: host=algo-1, epoch=16, train loss <loss>=2.02228888273\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:08 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:08 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_deeee696-e06b-4896-926c-60d1e6fcff17-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 113.72709274291992, \"sum\": 113.72709274291992, \"min\": 113.72709274291992}}, \"EndTime\": 1601797028.134236, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797028.019961}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:08 INFO 139662618720064] Epoch[17] Batch[0] avg_epoch_loss=2.096674\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:08 INFO 139662618720064] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=2.09667444229\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:10 INFO 139662618720064] Epoch[17] Batch[5] avg_epoch_loss=2.044996\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:10 INFO 139662618720064] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=2.0449962616\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:10 INFO 139662618720064] Epoch[17] Batch [5]#011Speed: 188.18 samples/sec#011loss=2.044996\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:12 INFO 139662618720064] Epoch[17] Batch[10] avg_epoch_loss=1.952040\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:12 INFO 139662618720064] #quality_metric: host=algo-1, epoch=17, batch=10 train loss <loss>=1.84049165249\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:12 INFO 139662618720064] Epoch[17] Batch [10]#011Speed: 185.65 samples/sec#011loss=1.840492\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:12 INFO 139662618720064] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4242.103099822998, \"sum\": 4242.103099822998, \"min\": 4242.103099822998}}, \"EndTime\": 1601797032.376482, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797028.134309}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:12 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=154.164420216 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:12 INFO 139662618720064] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:12 INFO 139662618720064] #quality_metric: host=algo-1, epoch=17, train loss <loss>=1.95203962109\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:12 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:12 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_e1f7090d-2614-47cd-bafd-9880ead7c928-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 112.12301254272461, \"sum\": 112.12301254272461, \"min\": 112.12301254272461}}, \"EndTime\": 1601797032.489172, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797032.376561}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:13 INFO 139662618720064] Epoch[18] Batch[0] avg_epoch_loss=1.926411\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:13 INFO 139662618720064] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=1.92641055584\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:14 INFO 139662618720064] Epoch[18] Batch[5] avg_epoch_loss=1.949937\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:14 INFO 139662618720064] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=1.94993724426\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:14 INFO 139662618720064] Epoch[18] Batch [5]#011Speed: 187.46 samples/sec#011loss=1.949937\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:16 INFO 139662618720064] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3840.481996536255, \"sum\": 3840.481996536255, \"min\": 3840.481996536255}}, \"EndTime\": 1601797036.3298, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797032.489249}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:16 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=164.817658955 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:16 INFO 139662618720064] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:16 INFO 139662618720064] #quality_metric: host=algo-1, epoch=18, train loss <loss>=1.94923176765\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:16 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:16 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_d6df7db2-cbfb-4da0-9bad-5b0db7a7716e-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 152.24385261535645, \"sum\": 152.24385261535645, \"min\": 152.24385261535645}}, \"EndTime\": 1601797036.482644, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797036.329884}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:17 INFO 139662618720064] Epoch[19] Batch[0] avg_epoch_loss=1.860478\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:17 INFO 139662618720064] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=1.86047780514\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:19 INFO 139662618720064] Epoch[19] Batch[5] avg_epoch_loss=1.899024\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:19 INFO 139662618720064] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=1.89902385076\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:19 INFO 139662618720064] Epoch[19] Batch [5]#011Speed: 183.74 samples/sec#011loss=1.899024\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:20 INFO 139662618720064] Epoch[19] Batch[10] avg_epoch_loss=1.898120\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:20 INFO 139662618720064] #quality_metric: host=algo-1, epoch=19, batch=10 train loss <loss>=1.8970344305\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:20 INFO 139662618720064] Epoch[19] Batch [10]#011Speed: 189.46 samples/sec#011loss=1.897034\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:20 INFO 139662618720064] processed a total of 679 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4223.325967788696, \"sum\": 4223.325967788696, \"min\": 4223.325967788696}}, \"EndTime\": 1601797040.706104, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797036.482707}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:20 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=160.769186815 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:20 INFO 139662618720064] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:20 INFO 139662618720064] #quality_metric: host=algo-1, epoch=19, train loss <loss>=1.89811956882\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:20 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:20 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_7a5e722f-c345-42b6-99eb-b763913b4388-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 117.48003959655762, \"sum\": 117.48003959655762, \"min\": 117.48003959655762}}, \"EndTime\": 1601797040.824152, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797040.706183}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:21 INFO 139662618720064] Epoch[20] Batch[0] avg_epoch_loss=2.045905\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:21 INFO 139662618720064] #quality_metric: host=algo-1, epoch=20, batch=0 train loss <loss>=2.04590463638\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:23 INFO 139662618720064] Epoch[20] Batch[5] avg_epoch_loss=1.909453\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:23 INFO 139662618720064] #quality_metric: host=algo-1, epoch=20, batch=5 train loss <loss>=1.90945311387\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:23 INFO 139662618720064] Epoch[20] Batch [5]#011Speed: 185.00 samples/sec#011loss=1.909453\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:25 INFO 139662618720064] Epoch[20] Batch[10] avg_epoch_loss=1.947018\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:25 INFO 139662618720064] #quality_metric: host=algo-1, epoch=20, batch=10 train loss <loss>=1.992096591\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:25 INFO 139662618720064] Epoch[20] Batch [10]#011Speed: 187.45 samples/sec#011loss=1.992097\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:25 INFO 139662618720064] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4224.112987518311, \"sum\": 4224.112987518311, \"min\": 4224.112987518311}}, \"EndTime\": 1601797045.048374, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797040.824204}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:25 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=154.821078504 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:25 INFO 139662618720064] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:25 INFO 139662618720064] #quality_metric: host=algo-1, epoch=20, train loss <loss>=1.94701833075\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:25 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:25 INFO 139662618720064] Epoch[21] Batch[0] avg_epoch_loss=1.942441\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:25 INFO 139662618720064] #quality_metric: host=algo-1, epoch=21, batch=0 train loss <loss>=1.94244062901\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:27 INFO 139662618720064] Epoch[21] Batch[5] avg_epoch_loss=1.847226\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:27 INFO 139662618720064] #quality_metric: host=algo-1, epoch=21, batch=5 train loss <loss>=1.84722630183\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:27 INFO 139662618720064] Epoch[21] Batch [5]#011Speed: 188.86 samples/sec#011loss=1.847226\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:28 INFO 139662618720064] processed a total of 616 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3883.394956588745, \"sum\": 3883.394956588745, \"min\": 3883.394956588745}}, \"EndTime\": 1601797048.932267, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797045.048453}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:28 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=158.61956396 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:28 INFO 139662618720064] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:28 INFO 139662618720064] #quality_metric: host=algo-1, epoch=21, train loss <loss>=1.8320432663\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:28 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:29 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_050626ef-a4b6-4df7-ad38-4c545e006c21-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 103.93691062927246, \"sum\": 103.93691062927246, \"min\": 103.93691062927246}}, \"EndTime\": 1601797049.036808, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797048.932344}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:29 INFO 139662618720064] Epoch[22] Batch[0] avg_epoch_loss=2.031100\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:29 INFO 139662618720064] #quality_metric: host=algo-1, epoch=22, batch=0 train loss <loss>=2.03110027313\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:31 INFO 139662618720064] Epoch[22] Batch[5] avg_epoch_loss=1.930369\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:31 INFO 139662618720064] #quality_metric: host=algo-1, epoch=22, batch=5 train loss <loss>=1.93036905924\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:31 INFO 139662618720064] Epoch[22] Batch [5]#011Speed: 189.81 samples/sec#011loss=1.930369\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:33 INFO 139662618720064] Epoch[22] Batch[10] avg_epoch_loss=1.879053\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:33 INFO 139662618720064] #quality_metric: host=algo-1, epoch=22, batch=10 train loss <loss>=1.81747415066\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:33 INFO 139662618720064] Epoch[22] Batch [10]#011Speed: 188.04 samples/sec#011loss=1.817474\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:33 INFO 139662618720064] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4169.724941253662, \"sum\": 4169.724941253662, \"min\": 4169.724941253662}}, \"EndTime\": 1601797053.206734, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797049.036939}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:33 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=157.319578603 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:33 INFO 139662618720064] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:33 INFO 139662618720064] #quality_metric: host=algo-1, epoch=22, train loss <loss>=1.87905319171\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:33 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:34 INFO 139662618720064] Epoch[23] Batch[0] avg_epoch_loss=1.742244\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:34 INFO 139662618720064] #quality_metric: host=algo-1, epoch=23, batch=0 train loss <loss>=1.7422440052\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:35 INFO 139662618720064] Epoch[23] Batch[5] avg_epoch_loss=1.834159\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:35 INFO 139662618720064] #quality_metric: host=algo-1, epoch=23, batch=5 train loss <loss>=1.83415881793\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:35 INFO 139662618720064] Epoch[23] Batch [5]#011Speed: 188.76 samples/sec#011loss=1.834159\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:37 INFO 139662618720064] Epoch[23] Batch[10] avg_epoch_loss=1.763378\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:37 INFO 139662618720064] #quality_metric: host=algo-1, epoch=23, batch=10 train loss <loss>=1.67844107151\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:37 INFO 139662618720064] Epoch[23] Batch [10]#011Speed: 189.57 samples/sec#011loss=1.678441\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:37 INFO 139662618720064] processed a total of 675 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4182.806015014648, \"sum\": 4182.806015014648, \"min\": 4182.806015014648}}, \"EndTime\": 1601797057.390119, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797053.206824}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:37 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=161.370250725 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:37 INFO 139662618720064] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:37 INFO 139662618720064] #quality_metric: host=algo-1, epoch=23, train loss <loss>=1.7633780241\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:37 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:37 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_499a3680-4876-49df-aac2-4d2da1e433b2-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 131.1800479888916, \"sum\": 131.1800479888916, \"min\": 131.1800479888916}}, \"EndTime\": 1601797057.521909, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797057.3902}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:38 INFO 139662618720064] Epoch[24] Batch[0] avg_epoch_loss=1.732751\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:38 INFO 139662618720064] #quality_metric: host=algo-1, epoch=24, batch=0 train loss <loss>=1.73275148869\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:40 INFO 139662618720064] Epoch[24] Batch[5] avg_epoch_loss=1.700717\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:40 INFO 139662618720064] #quality_metric: host=algo-1, epoch=24, batch=5 train loss <loss>=1.70071740945\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:40 INFO 139662618720064] Epoch[24] Batch [5]#011Speed: 183.66 samples/sec#011loss=1.700717\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:41 INFO 139662618720064] Epoch[24] Batch[10] avg_epoch_loss=1.812269\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:41 INFO 139662618720064] #quality_metric: host=algo-1, epoch=24, batch=10 train loss <loss>=1.94613041878\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:41 INFO 139662618720064] Epoch[24] Batch [10]#011Speed: 190.97 samples/sec#011loss=1.946130\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:41 INFO 139662618720064] processed a total of 668 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4244.627952575684, \"sum\": 4244.627952575684, \"min\": 4244.627952575684}}, \"EndTime\": 1601797061.766676, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797057.52198}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:41 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=157.371160743 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:41 INFO 139662618720064] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:41 INFO 139662618720064] #quality_metric: host=algo-1, epoch=24, train loss <loss>=1.81226877733\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:41 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:42 INFO 139662618720064] Epoch[25] Batch[0] avg_epoch_loss=1.830256\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:42 INFO 139662618720064] #quality_metric: host=algo-1, epoch=25, batch=0 train loss <loss>=1.83025586605\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:44 INFO 139662618720064] Epoch[25] Batch[5] avg_epoch_loss=1.812613\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:44 INFO 139662618720064] #quality_metric: host=algo-1, epoch=25, batch=5 train loss <loss>=1.81261257331\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:44 INFO 139662618720064] Epoch[25] Batch [5]#011Speed: 186.79 samples/sec#011loss=1.812613\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:45 INFO 139662618720064] Epoch[25] Batch[10] avg_epoch_loss=1.790698\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:45 INFO 139662618720064] #quality_metric: host=algo-1, epoch=25, batch=10 train loss <loss>=1.76440052986\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:45 INFO 139662618720064] Epoch[25] Batch [10]#011Speed: 190.09 samples/sec#011loss=1.764401\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:45 INFO 139662618720064] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4213.859081268311, \"sum\": 4213.859081268311, \"min\": 4213.859081268311}}, \"EndTime\": 1601797065.981074, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797061.766749}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:45 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=153.53667604 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:45 INFO 139662618720064] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:45 INFO 139662618720064] #quality_metric: host=algo-1, epoch=25, train loss <loss>=1.7906980081\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:45 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:46 INFO 139662618720064] Epoch[26] Batch[0] avg_epoch_loss=1.904269\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:46 INFO 139662618720064] #quality_metric: host=algo-1, epoch=26, batch=0 train loss <loss>=1.90426945686\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:48 INFO 139662618720064] Epoch[26] Batch[5] avg_epoch_loss=1.786110\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:48 INFO 139662618720064] #quality_metric: host=algo-1, epoch=26, batch=5 train loss <loss>=1.78610954682\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:48 INFO 139662618720064] Epoch[26] Batch [5]#011Speed: 189.12 samples/sec#011loss=1.786110\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:50 INFO 139662618720064] Epoch[26] Batch[10] avg_epoch_loss=1.784553\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:50 INFO 139662618720064] #quality_metric: host=algo-1, epoch=26, batch=10 train loss <loss>=1.78268511295\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:50 INFO 139662618720064] Epoch[26] Batch [10]#011Speed: 189.61 samples/sec#011loss=1.782685\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:50 INFO 139662618720064] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4188.161849975586, \"sum\": 4188.161849975586, \"min\": 4188.161849975586}}, \"EndTime\": 1601797070.169756, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797065.981153}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:50 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=158.77628262 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:50 INFO 139662618720064] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:50 INFO 139662618720064] #quality_metric: host=algo-1, epoch=26, train loss <loss>=1.78455298597\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:50 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:51 INFO 139662618720064] Epoch[27] Batch[0] avg_epoch_loss=1.766793\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:51 INFO 139662618720064] #quality_metric: host=algo-1, epoch=27, batch=0 train loss <loss>=1.76679289341\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:52 INFO 139662618720064] Epoch[27] Batch[5] avg_epoch_loss=1.757906\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:52 INFO 139662618720064] #quality_metric: host=algo-1, epoch=27, batch=5 train loss <loss>=1.75790611903\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:52 INFO 139662618720064] Epoch[27] Batch [5]#011Speed: 190.40 samples/sec#011loss=1.757906\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:54 INFO 139662618720064] Epoch[27] Batch[10] avg_epoch_loss=1.760047\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:54 INFO 139662618720064] #quality_metric: host=algo-1, epoch=27, batch=10 train loss <loss>=1.76261537075\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:54 INFO 139662618720064] Epoch[27] Batch [10]#011Speed: 187.62 samples/sec#011loss=1.762615\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:54 INFO 139662618720064] processed a total of 686 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4231.193780899048, \"sum\": 4231.193780899048, \"min\": 4231.193780899048}}, \"EndTime\": 1601797074.401527, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797070.169838}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:54 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=162.124654027 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:54 INFO 139662618720064] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:54 INFO 139662618720064] #quality_metric: host=algo-1, epoch=27, train loss <loss>=1.76004668799\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:54 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:54 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_1e461ab6-9311-46c1-923a-c654076d5330-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 111.24396324157715, \"sum\": 111.24396324157715, \"min\": 111.24396324157715}}, \"EndTime\": 1601797074.513346, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797074.401606}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:55 INFO 139662618720064] Epoch[28] Batch[0] avg_epoch_loss=1.557720\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:55 INFO 139662618720064] #quality_metric: host=algo-1, epoch=28, batch=0 train loss <loss>=1.55772006512\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:57 INFO 139662618720064] Epoch[28] Batch[5] avg_epoch_loss=1.680823\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:57 INFO 139662618720064] #quality_metric: host=algo-1, epoch=28, batch=5 train loss <loss>=1.68082338572\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:57 INFO 139662618720064] Epoch[28] Batch [5]#011Speed: 189.24 samples/sec#011loss=1.680823\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:58 INFO 139662618720064] Epoch[28] Batch[10] avg_epoch_loss=1.706782\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:58 INFO 139662618720064] #quality_metric: host=algo-1, epoch=28, batch=10 train loss <loss>=1.73793234825\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:58 INFO 139662618720064] Epoch[28] Batch [10]#011Speed: 187.06 samples/sec#011loss=1.737932\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:58 INFO 139662618720064] processed a total of 666 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4198.052883148193, \"sum\": 4198.052883148193, \"min\": 4198.052883148193}}, \"EndTime\": 1601797078.711535, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797074.513424}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:58 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=158.64100301 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:58 INFO 139662618720064] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:58 INFO 139662618720064] #quality_metric: host=algo-1, epoch=28, train loss <loss>=1.70678200505\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:58 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:58 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_0b647b5f-efe2-46ee-97bc-bb1bdbff2d6d-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 103.93595695495605, \"sum\": 103.93595695495605, \"min\": 103.93595695495605}}, \"EndTime\": 1601797078.816052, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797078.711602}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:59 INFO 139662618720064] Epoch[29] Batch[0] avg_epoch_loss=1.656632\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:37:59 INFO 139662618720064] #quality_metric: host=algo-1, epoch=29, batch=0 train loss <loss>=1.65663230419\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:01 INFO 139662618720064] Epoch[29] Batch[5] avg_epoch_loss=1.641496\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:01 INFO 139662618720064] #quality_metric: host=algo-1, epoch=29, batch=5 train loss <loss>=1.64149634043\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:01 INFO 139662618720064] Epoch[29] Batch [5]#011Speed: 189.52 samples/sec#011loss=1.641496\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:02 INFO 139662618720064] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3863.9779090881348, \"sum\": 3863.9779090881348, \"min\": 3863.9779090881348}}, \"EndTime\": 1601797082.680172, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797078.816123}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:02 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=163.297800273 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:02 INFO 139662618720064] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:02 INFO 139662618720064] #quality_metric: host=algo-1, epoch=29, train loss <loss>=1.65469173193\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:02 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:02 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_69c69f72-b380-4077-92e0-9cd47feca5c4-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 101.59897804260254, \"sum\": 101.59897804260254, \"min\": 101.59897804260254}}, \"EndTime\": 1601797082.782415, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797082.680257}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:03 INFO 139662618720064] Epoch[30] Batch[0] avg_epoch_loss=1.521902\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:03 INFO 139662618720064] #quality_metric: host=algo-1, epoch=30, batch=0 train loss <loss>=1.52190244198\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:05 INFO 139662618720064] Epoch[30] Batch[5] avg_epoch_loss=1.659628\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:05 INFO 139662618720064] #quality_metric: host=algo-1, epoch=30, batch=5 train loss <loss>=1.65962767601\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:05 INFO 139662618720064] Epoch[30] Batch [5]#011Speed: 189.06 samples/sec#011loss=1.659628\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:06 INFO 139662618720064] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3833.781957626343, \"sum\": 3833.781957626343, \"min\": 3833.781957626343}}, \"EndTime\": 1601797086.616331, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797082.782485}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:06 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=165.888728239 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:06 INFO 139662618720064] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:06 INFO 139662618720064] #quality_metric: host=algo-1, epoch=30, train loss <loss>=1.65218493938\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:06 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:06 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_2ed1114a-612f-4d06-a152-8d307681f16e-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 100.79717636108398, \"sum\": 100.79717636108398, \"min\": 100.79717636108398}}, \"EndTime\": 1601797086.717737, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797086.616406}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:07 INFO 139662618720064] Epoch[31] Batch[0] avg_epoch_loss=1.549572\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:07 INFO 139662618720064] #quality_metric: host=algo-1, epoch=31, batch=0 train loss <loss>=1.54957175255\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:09 INFO 139662618720064] Epoch[31] Batch[5] avg_epoch_loss=1.576179\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:09 INFO 139662618720064] #quality_metric: host=algo-1, epoch=31, batch=5 train loss <loss>=1.57617886861\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:09 INFO 139662618720064] Epoch[31] Batch [5]#011Speed: 187.26 samples/sec#011loss=1.576179\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:10 INFO 139662618720064] processed a total of 606 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3851.613998413086, \"sum\": 3851.613998413086, \"min\": 3851.613998413086}}, \"EndTime\": 1601797090.56947, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797086.717796}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:10 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=157.331613367 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:10 INFO 139662618720064] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:10 INFO 139662618720064] #quality_metric: host=algo-1, epoch=31, train loss <loss>=1.61326659918\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:10 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:10 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_58867d08-955c-415f-ab13-70bcfeb92d09-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 114.11499977111816, \"sum\": 114.11499977111816, \"min\": 114.11499977111816}}, \"EndTime\": 1601797090.684195, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797090.569555}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:11 INFO 139662618720064] Epoch[32] Batch[0] avg_epoch_loss=1.716085\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:11 INFO 139662618720064] #quality_metric: host=algo-1, epoch=32, batch=0 train loss <loss>=1.71608543396\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:13 INFO 139662618720064] Epoch[32] Batch[5] avg_epoch_loss=1.605178\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:13 INFO 139662618720064] #quality_metric: host=algo-1, epoch=32, batch=5 train loss <loss>=1.60517791907\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:13 INFO 139662618720064] Epoch[32] Batch [5]#011Speed: 189.29 samples/sec#011loss=1.605178\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:14 INFO 139662618720064] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3847.2819328308105, \"sum\": 3847.2819328308105, \"min\": 3847.2819328308105}}, \"EndTime\": 1601797094.531613, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797090.684266}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:14 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=165.30601262 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:14 INFO 139662618720064] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:14 INFO 139662618720064] #quality_metric: host=algo-1, epoch=32, train loss <loss>=1.59318077564\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:14 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:14 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_c9cd7b47-3c36-4782-851a-686e4e81d224-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 106.10508918762207, \"sum\": 106.10508918762207, \"min\": 106.10508918762207}}, \"EndTime\": 1601797094.638325, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797094.531698}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:15 INFO 139662618720064] Epoch[33] Batch[0] avg_epoch_loss=1.588576\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:15 INFO 139662618720064] #quality_metric: host=algo-1, epoch=33, batch=0 train loss <loss>=1.58857560158\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:17 INFO 139662618720064] Epoch[33] Batch[5] avg_epoch_loss=1.601838\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:17 INFO 139662618720064] #quality_metric: host=algo-1, epoch=33, batch=5 train loss <loss>=1.60183761517\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:17 INFO 139662618720064] Epoch[33] Batch [5]#011Speed: 186.88 samples/sec#011loss=1.601838\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:18 INFO 139662618720064] processed a total of 610 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3860.3780269622803, \"sum\": 3860.3780269622803, \"min\": 3860.3780269622803}}, \"EndTime\": 1601797098.498856, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797094.638405}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:18 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=158.010294375 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:18 INFO 139662618720064] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:18 INFO 139662618720064] #quality_metric: host=algo-1, epoch=33, train loss <loss>=1.55574793816\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:18 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:18 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_d9278d89-8e6a-443c-952c-be439d692eac-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 103.43503952026367, \"sum\": 103.43503952026367, \"min\": 103.43503952026367}}, \"EndTime\": 1601797098.602998, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797098.498941}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:19 INFO 139662618720064] Epoch[34] Batch[0] avg_epoch_loss=1.580600\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:19 INFO 139662618720064] #quality_metric: host=algo-1, epoch=34, batch=0 train loss <loss>=1.58059966564\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:21 INFO 139662618720064] Epoch[34] Batch[5] avg_epoch_loss=1.640742\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:21 INFO 139662618720064] #quality_metric: host=algo-1, epoch=34, batch=5 train loss <loss>=1.64074158669\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:21 INFO 139662618720064] Epoch[34] Batch [5]#011Speed: 188.01 samples/sec#011loss=1.640742\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:22 INFO 139662618720064] Epoch[34] Batch[10] avg_epoch_loss=1.551549\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:22 INFO 139662618720064] #quality_metric: host=algo-1, epoch=34, batch=10 train loss <loss>=1.44451798201\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:22 INFO 139662618720064] Epoch[34] Batch [10]#011Speed: 187.87 samples/sec#011loss=1.444518\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:22 INFO 139662618720064] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4199.303150177002, \"sum\": 4199.303150177002, \"min\": 4199.303150177002}}, \"EndTime\": 1601797102.802433, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797098.603062}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:22 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=156.926130704 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:22 INFO 139662618720064] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:22 INFO 139662618720064] #quality_metric: host=algo-1, epoch=34, train loss <loss>=1.5515490391\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:22 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:22 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_5f6ea201-9e44-4b6c-a68d-6af3349da3ee-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 105.36384582519531, \"sum\": 105.36384582519531, \"min\": 105.36384582519531}}, \"EndTime\": 1601797102.908432, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797102.802516}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:23 INFO 139662618720064] Epoch[35] Batch[0] avg_epoch_loss=1.621168\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:23 INFO 139662618720064] #quality_metric: host=algo-1, epoch=35, batch=0 train loss <loss>=1.62116789818\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:25 INFO 139662618720064] Epoch[35] Batch[5] avg_epoch_loss=1.471563\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:25 INFO 139662618720064] #quality_metric: host=algo-1, epoch=35, batch=5 train loss <loss>=1.47156318029\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:25 INFO 139662618720064] Epoch[35] Batch [5]#011Speed: 187.77 samples/sec#011loss=1.471563\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:26 INFO 139662618720064] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3845.026969909668, \"sum\": 3845.026969909668, \"min\": 3845.026969909668}}, \"EndTime\": 1601797106.753604, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797102.908508}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:26 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=164.623099553 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:26 INFO 139662618720064] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:26 INFO 139662618720064] #quality_metric: host=algo-1, epoch=35, train loss <loss>=1.49286298752\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:26 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:26 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_35fa5473-f52b-4a69-88c6-e70e183212e0-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 106.74810409545898, \"sum\": 106.74810409545898, \"min\": 106.74810409545898}}, \"EndTime\": 1601797106.86093, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797106.753684}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:27 INFO 139662618720064] Epoch[36] Batch[0] avg_epoch_loss=1.416881\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:27 INFO 139662618720064] #quality_metric: host=algo-1, epoch=36, batch=0 train loss <loss>=1.41688072681\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:29 INFO 139662618720064] Epoch[36] Batch[5] avg_epoch_loss=1.397987\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:29 INFO 139662618720064] #quality_metric: host=algo-1, epoch=36, batch=5 train loss <loss>=1.39798736572\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:29 INFO 139662618720064] Epoch[36] Batch [5]#011Speed: 187.60 samples/sec#011loss=1.397987\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:31 INFO 139662618720064] Epoch[36] Batch[10] avg_epoch_loss=1.486532\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:31 INFO 139662618720064] #quality_metric: host=algo-1, epoch=36, batch=10 train loss <loss>=1.59278509617\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:31 INFO 139662618720064] Epoch[36] Batch [10]#011Speed: 186.98 samples/sec#011loss=1.592785\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:31 INFO 139662618720064] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4200.570106506348, \"sum\": 4200.570106506348, \"min\": 4200.570106506348}}, \"EndTime\": 1601797111.061655, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797106.861018}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:31 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=153.070167925 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:31 INFO 139662618720064] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:31 INFO 139662618720064] #quality_metric: host=algo-1, epoch=36, train loss <loss>=1.48653178865\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:31 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:31 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_030eb64b-e512-463e-a894-0612fb908b50-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 112.08987236022949, \"sum\": 112.08987236022949, \"min\": 112.08987236022949}}, \"EndTime\": 1601797111.174309, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797111.061733}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:31 INFO 139662618720064] Epoch[37] Batch[0] avg_epoch_loss=1.593380\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:31 INFO 139662618720064] #quality_metric: host=algo-1, epoch=37, batch=0 train loss <loss>=1.59338033199\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:33 INFO 139662618720064] Epoch[37] Batch[5] avg_epoch_loss=1.560849\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:33 INFO 139662618720064] #quality_metric: host=algo-1, epoch=37, batch=5 train loss <loss>=1.560848852\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:33 INFO 139662618720064] Epoch[37] Batch [5]#011Speed: 187.32 samples/sec#011loss=1.560849\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:35 INFO 139662618720064] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3924.3102073669434, \"sum\": 3924.3102073669434, \"min\": 3924.3102073669434}}, \"EndTime\": 1601797115.098736, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797111.174364}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:35 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=159.002074427 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:35 INFO 139662618720064] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:35 INFO 139662618720064] #quality_metric: host=algo-1, epoch=37, train loss <loss>=1.54914157391\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:35 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:35 INFO 139662618720064] Epoch[38] Batch[0] avg_epoch_loss=1.425848\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:35 INFO 139662618720064] #quality_metric: host=algo-1, epoch=38, batch=0 train loss <loss>=1.4258480072\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:37 INFO 139662618720064] Epoch[38] Batch[5] avg_epoch_loss=1.492240\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:37 INFO 139662618720064] #quality_metric: host=algo-1, epoch=38, batch=5 train loss <loss>=1.49224001169\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:37 INFO 139662618720064] Epoch[38] Batch [5]#011Speed: 188.96 samples/sec#011loss=1.492240\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:38 INFO 139662618720064] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3866.4910793304443, \"sum\": 3866.4910793304443, \"min\": 3866.4910793304443}}, \"EndTime\": 1601797118.965835, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797115.098862}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:38 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=161.640218067 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:38 INFO 139662618720064] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:38 INFO 139662618720064] #quality_metric: host=algo-1, epoch=38, train loss <loss>=1.51151912212\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:38 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:39 INFO 139662618720064] Epoch[39] Batch[0] avg_epoch_loss=1.535283\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:39 INFO 139662618720064] #quality_metric: host=algo-1, epoch=39, batch=0 train loss <loss>=1.53528296947\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:41 INFO 139662618720064] Epoch[39] Batch[5] avg_epoch_loss=1.524099\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:41 INFO 139662618720064] #quality_metric: host=algo-1, epoch=39, batch=5 train loss <loss>=1.5240988334\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:41 INFO 139662618720064] Epoch[39] Batch [5]#011Speed: 188.54 samples/sec#011loss=1.524099\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:43 INFO 139662618720064] Epoch[39] Batch[10] avg_epoch_loss=1.462593\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:43 INFO 139662618720064] #quality_metric: host=algo-1, epoch=39, batch=10 train loss <loss>=1.38878567219\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:43 INFO 139662618720064] Epoch[39] Batch [10]#011Speed: 188.32 samples/sec#011loss=1.388786\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:43 INFO 139662618720064] processed a total of 678 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4258.555173873901, \"sum\": 4258.555173873901, \"min\": 4258.555173873901}}, \"EndTime\": 1601797123.224984, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797118.965917}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:43 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=159.204559582 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:43 INFO 139662618720064] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:43 INFO 139662618720064] #quality_metric: host=algo-1, epoch=39, train loss <loss>=1.46259285103\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:43 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:43 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_e7c0df5d-bf9d-4bf7-8c88-44fa733ed3d5-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 102.30898857116699, \"sum\": 102.30898857116699, \"min\": 102.30898857116699}}, \"EndTime\": 1601797123.327866, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797123.225059}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:44 INFO 139662618720064] Epoch[40] Batch[0] avg_epoch_loss=1.695745\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:44 INFO 139662618720064] #quality_metric: host=algo-1, epoch=40, batch=0 train loss <loss>=1.69574546814\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:45 INFO 139662618720064] Epoch[40] Batch[5] avg_epoch_loss=1.479554\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:45 INFO 139662618720064] #quality_metric: host=algo-1, epoch=40, batch=5 train loss <loss>=1.47955399752\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:45 INFO 139662618720064] Epoch[40] Batch [5]#011Speed: 189.42 samples/sec#011loss=1.479554\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:47 INFO 139662618720064] processed a total of 603 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3853.174924850464, \"sum\": 3853.174924850464, \"min\": 3853.174924850464}}, \"EndTime\": 1601797127.18119, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797123.327946}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:47 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=156.489200414 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:47 INFO 139662618720064] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:47 INFO 139662618720064] #quality_metric: host=algo-1, epoch=40, train loss <loss>=1.44608453512\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:47 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:47 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_9e183ed6-5f5e-45ca-b7e3-8e73d1e35944-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 111.43994331359863, \"sum\": 111.43994331359863, \"min\": 111.43994331359863}}, \"EndTime\": 1601797127.29325, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797127.181275}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:48 INFO 139662618720064] Epoch[41] Batch[0] avg_epoch_loss=1.703871\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:48 INFO 139662618720064] #quality_metric: host=algo-1, epoch=41, batch=0 train loss <loss>=1.70387101173\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:49 INFO 139662618720064] Epoch[41] Batch[5] avg_epoch_loss=1.494118\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:49 INFO 139662618720064] #quality_metric: host=algo-1, epoch=41, batch=5 train loss <loss>=1.49411835273\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:49 INFO 139662618720064] Epoch[41] Batch [5]#011Speed: 185.81 samples/sec#011loss=1.494118\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:51 INFO 139662618720064] Epoch[41] Batch[10] avg_epoch_loss=1.495315\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:51 INFO 139662618720064] #quality_metric: host=algo-1, epoch=41, batch=10 train loss <loss>=1.49674987793\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:51 INFO 139662618720064] Epoch[41] Batch [10]#011Speed: 188.67 samples/sec#011loss=1.496750\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:51 INFO 139662618720064] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4204.6959400177, \"sum\": 4204.6959400177, \"min\": 4204.6959400177}}, \"EndTime\": 1601797131.498073, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797127.293307}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:51 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=153.871438067 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:51 INFO 139662618720064] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:51 INFO 139662618720064] #quality_metric: host=algo-1, epoch=41, train loss <loss>=1.49531450055\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:51 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:52 INFO 139662618720064] Epoch[42] Batch[0] avg_epoch_loss=1.646625\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:52 INFO 139662618720064] #quality_metric: host=algo-1, epoch=42, batch=0 train loss <loss>=1.64662468433\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:53 INFO 139662618720064] Epoch[42] Batch[5] avg_epoch_loss=1.450426\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:53 INFO 139662618720064] #quality_metric: host=algo-1, epoch=42, batch=5 train loss <loss>=1.45042576392\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:53 INFO 139662618720064] Epoch[42] Batch [5]#011Speed: 185.67 samples/sec#011loss=1.450426\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:55 INFO 139662618720064] processed a total of 579 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3857.598066329956, \"sum\": 3857.598066329956, \"min\": 3857.598066329956}}, \"EndTime\": 1601797135.356235, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797131.498142}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:55 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=150.088536774 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:55 INFO 139662618720064] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:55 INFO 139662618720064] #quality_metric: host=algo-1, epoch=42, train loss <loss>=1.41257935762\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:55 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:55 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_f9e94716-9a04-452e-b7a7-b0831f8d0aea-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 109.87305641174316, \"sum\": 109.87305641174316, \"min\": 109.87305641174316}}, \"EndTime\": 1601797135.466709, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797135.356318}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:56 INFO 139662618720064] Epoch[43] Batch[0] avg_epoch_loss=1.548943\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:56 INFO 139662618720064] #quality_metric: host=algo-1, epoch=43, batch=0 train loss <loss>=1.54894340038\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:57 INFO 139662618720064] Epoch[43] Batch[5] avg_epoch_loss=1.478921\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:57 INFO 139662618720064] #quality_metric: host=algo-1, epoch=43, batch=5 train loss <loss>=1.47892113527\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:57 INFO 139662618720064] Epoch[43] Batch [5]#011Speed: 189.08 samples/sec#011loss=1.478921\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:59 INFO 139662618720064] Epoch[43] Batch[10] avg_epoch_loss=1.489202\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:59 INFO 139662618720064] #quality_metric: host=algo-1, epoch=43, batch=10 train loss <loss>=1.5015392065\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:59 INFO 139662618720064] Epoch[43] Batch [10]#011Speed: 185.38 samples/sec#011loss=1.501539\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:59 INFO 139662618720064] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4211.16304397583, \"sum\": 4211.16304397583, \"min\": 4211.16304397583}}, \"EndTime\": 1601797139.677983, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797135.466761}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:59 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=157.671781654 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:59 INFO 139662618720064] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:59 INFO 139662618720064] #quality_metric: host=algo-1, epoch=43, train loss <loss>=1.48920207674\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:38:59 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:00 INFO 139662618720064] Epoch[44] Batch[0] avg_epoch_loss=1.390548\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:00 INFO 139662618720064] #quality_metric: host=algo-1, epoch=44, batch=0 train loss <loss>=1.39054822922\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:02 INFO 139662618720064] Epoch[44] Batch[5] avg_epoch_loss=1.527335\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:02 INFO 139662618720064] #quality_metric: host=algo-1, epoch=44, batch=5 train loss <loss>=1.5273351868\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:02 INFO 139662618720064] Epoch[44] Batch [5]#011Speed: 187.70 samples/sec#011loss=1.527335\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:03 INFO 139662618720064] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3859.43603515625, \"sum\": 3859.43603515625, \"min\": 3859.43603515625}}, \"EndTime\": 1601797143.537929, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797139.678061}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:03 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=162.194603678 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:03 INFO 139662618720064] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:03 INFO 139662618720064] #quality_metric: host=algo-1, epoch=44, train loss <loss>=1.47744334936\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:03 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:04 INFO 139662618720064] Epoch[45] Batch[0] avg_epoch_loss=1.266967\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:04 INFO 139662618720064] #quality_metric: host=algo-1, epoch=45, batch=0 train loss <loss>=1.26696693897\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:06 INFO 139662618720064] Epoch[45] Batch[5] avg_epoch_loss=1.406709\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:06 INFO 139662618720064] #quality_metric: host=algo-1, epoch=45, batch=5 train loss <loss>=1.40670939287\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:06 INFO 139662618720064] Epoch[45] Batch [5]#011Speed: 185.17 samples/sec#011loss=1.406709\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:07 INFO 139662618720064] processed a total of 572 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3573.808193206787, \"sum\": 3573.808193206787, \"min\": 3573.808193206787}}, \"EndTime\": 1601797147.112325, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797143.538014}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:07 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=160.047100564 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:07 INFO 139662618720064] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:07 INFO 139662618720064] #quality_metric: host=algo-1, epoch=45, train loss <loss>=1.42000857989\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:07 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:07 INFO 139662618720064] Epoch[46] Batch[0] avg_epoch_loss=1.526168\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:07 INFO 139662618720064] #quality_metric: host=algo-1, epoch=46, batch=0 train loss <loss>=1.52616810799\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:09 INFO 139662618720064] Epoch[46] Batch[5] avg_epoch_loss=1.374480\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:09 INFO 139662618720064] #quality_metric: host=algo-1, epoch=46, batch=5 train loss <loss>=1.37447959185\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:09 INFO 139662618720064] Epoch[46] Batch [5]#011Speed: 185.24 samples/sec#011loss=1.374480\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:11 INFO 139662618720064] Epoch[46] Batch[10] avg_epoch_loss=1.390249\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:11 INFO 139662618720064] #quality_metric: host=algo-1, epoch=46, batch=10 train loss <loss>=1.40917220116\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:11 INFO 139662618720064] Epoch[46] Batch [10]#011Speed: 189.59 samples/sec#011loss=1.409172\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:11 INFO 139662618720064] processed a total of 695 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4259.160995483398, \"sum\": 4259.160995483398, \"min\": 4259.160995483398}}, \"EndTime\": 1601797151.372023, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797147.112407}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:11 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=163.173311561 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:11 INFO 139662618720064] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:11 INFO 139662618720064] #quality_metric: host=algo-1, epoch=46, train loss <loss>=1.39024895971\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:11 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:11 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_b03d563d-a127-49a2-8a67-a71d55f842fa-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 129.68921661376953, \"sum\": 129.68921661376953, \"min\": 129.68921661376953}}, \"EndTime\": 1601797151.502247, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797151.372098}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:12 INFO 139662618720064] Epoch[47] Batch[0] avg_epoch_loss=1.263897\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:12 INFO 139662618720064] #quality_metric: host=algo-1, epoch=47, batch=0 train loss <loss>=1.26389658451\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:13 INFO 139662618720064] Epoch[47] Batch[5] avg_epoch_loss=1.333402\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:13 INFO 139662618720064] #quality_metric: host=algo-1, epoch=47, batch=5 train loss <loss>=1.33340167999\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:13 INFO 139662618720064] Epoch[47] Batch [5]#011Speed: 188.28 samples/sec#011loss=1.333402\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:15 INFO 139662618720064] Epoch[47] Batch[10] avg_epoch_loss=1.365065\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:15 INFO 139662618720064] #quality_metric: host=algo-1, epoch=47, batch=10 train loss <loss>=1.40306034088\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:15 INFO 139662618720064] Epoch[47] Batch [10]#011Speed: 187.54 samples/sec#011loss=1.403060\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:15 INFO 139662618720064] processed a total of 668 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4201.979875564575, \"sum\": 4201.979875564575, \"min\": 4201.979875564575}}, \"EndTime\": 1601797155.704369, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797151.502319}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:15 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=158.968322933 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:15 INFO 139662618720064] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:15 INFO 139662618720064] #quality_metric: host=algo-1, epoch=47, train loss <loss>=1.36506470767\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:15 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:15 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_34debaa5-2952-4d11-9b60-e45bd4d7650b-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 111.14716529846191, \"sum\": 111.14716529846191, \"min\": 111.14716529846191}}, \"EndTime\": 1601797155.816058, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797155.704446}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:16 INFO 139662618720064] Epoch[48] Batch[0] avg_epoch_loss=1.396257\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:16 INFO 139662618720064] #quality_metric: host=algo-1, epoch=48, batch=0 train loss <loss>=1.39625692368\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:18 INFO 139662618720064] Epoch[48] Batch[5] avg_epoch_loss=1.434850\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:18 INFO 139662618720064] #quality_metric: host=algo-1, epoch=48, batch=5 train loss <loss>=1.43485019604\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:18 INFO 139662618720064] Epoch[48] Batch [5]#011Speed: 189.01 samples/sec#011loss=1.434850\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:19 INFO 139662618720064] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3857.8059673309326, \"sum\": 3857.8059673309326, \"min\": 3857.8059673309326}}, \"EndTime\": 1601797159.673984, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797155.816117}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:19 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=163.818210493 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:19 INFO 139662618720064] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:19 INFO 139662618720064] #quality_metric: host=algo-1, epoch=48, train loss <loss>=1.40669710636\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:19 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:20 INFO 139662618720064] Epoch[49] Batch[0] avg_epoch_loss=1.443172\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:20 INFO 139662618720064] #quality_metric: host=algo-1, epoch=49, batch=0 train loss <loss>=1.44317173958\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:22 INFO 139662618720064] Epoch[49] Batch[5] avg_epoch_loss=1.413192\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:22 INFO 139662618720064] #quality_metric: host=algo-1, epoch=49, batch=5 train loss <loss>=1.4131915768\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:22 INFO 139662618720064] Epoch[49] Batch [5]#011Speed: 188.60 samples/sec#011loss=1.413192\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:23 INFO 139662618720064] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3828.0739784240723, \"sum\": 3828.0739784240723, \"min\": 3828.0739784240723}}, \"EndTime\": 1601797163.502677, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797159.674071}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:23 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=165.613087774 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:23 INFO 139662618720064] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:23 INFO 139662618720064] #quality_metric: host=algo-1, epoch=49, train loss <loss>=1.41072212458\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:23 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:24 INFO 139662618720064] Epoch[50] Batch[0] avg_epoch_loss=1.321596\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:24 INFO 139662618720064] #quality_metric: host=algo-1, epoch=50, batch=0 train loss <loss>=1.32159602642\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:26 INFO 139662618720064] Epoch[50] Batch[5] avg_epoch_loss=1.390502\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:26 INFO 139662618720064] #quality_metric: host=algo-1, epoch=50, batch=5 train loss <loss>=1.39050195614\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:26 INFO 139662618720064] Epoch[50] Batch [5]#011Speed: 188.80 samples/sec#011loss=1.390502\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:27 INFO 139662618720064] Epoch[50] Batch[10] avg_epoch_loss=1.375308\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:27 INFO 139662618720064] #quality_metric: host=algo-1, epoch=50, batch=10 train loss <loss>=1.35707576275\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:27 INFO 139662618720064] Epoch[50] Batch [10]#011Speed: 186.58 samples/sec#011loss=1.357076\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:27 INFO 139662618720064] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4220.979928970337, \"sum\": 4220.979928970337, \"min\": 4220.979928970337}}, \"EndTime\": 1601797167.724287, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797163.502764}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:27 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=153.040681912 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:27 INFO 139662618720064] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:27 INFO 139662618720064] #quality_metric: host=algo-1, epoch=50, train loss <loss>=1.37530823187\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:27 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:28 INFO 139662618720064] Epoch[51] Batch[0] avg_epoch_loss=1.431741\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:28 INFO 139662618720064] #quality_metric: host=algo-1, epoch=51, batch=0 train loss <loss>=1.43174147606\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:30 INFO 139662618720064] Epoch[51] Batch[5] avg_epoch_loss=1.415499\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:30 INFO 139662618720064] #quality_metric: host=algo-1, epoch=51, batch=5 train loss <loss>=1.41549942891\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:30 INFO 139662618720064] Epoch[51] Batch [5]#011Speed: 187.18 samples/sec#011loss=1.415499\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:31 INFO 139662618720064] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3873.5828399658203, \"sum\": 3873.5828399658203, \"min\": 3873.5828399658203}}, \"EndTime\": 1601797171.598426, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797167.724366}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:31 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=163.667392131 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:31 INFO 139662618720064] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:31 INFO 139662618720064] #quality_metric: host=algo-1, epoch=51, train loss <loss>=1.421851933\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:31 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:32 INFO 139662618720064] Epoch[52] Batch[0] avg_epoch_loss=1.372915\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:32 INFO 139662618720064] #quality_metric: host=algo-1, epoch=52, batch=0 train loss <loss>=1.37291538715\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:34 INFO 139662618720064] Epoch[52] Batch[5] avg_epoch_loss=1.320798\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:34 INFO 139662618720064] #quality_metric: host=algo-1, epoch=52, batch=5 train loss <loss>=1.32079778115\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:34 INFO 139662618720064] Epoch[52] Batch [5]#011Speed: 184.52 samples/sec#011loss=1.320798\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:35 INFO 139662618720064] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3883.5418224334717, \"sum\": 3883.5418224334717, \"min\": 3883.5418224334717}}, \"EndTime\": 1601797175.482582, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797171.598511}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:35 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=162.217742114 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:35 INFO 139662618720064] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:35 INFO 139662618720064] #quality_metric: host=algo-1, epoch=52, train loss <loss>=1.29505084157\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:35 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:35 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_c9a4bea3-b704-4cc2-ab30-357f94b81268-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 137.33291625976562, \"sum\": 137.33291625976562, \"min\": 137.33291625976562}}, \"EndTime\": 1601797175.620569, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797175.482667}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:36 INFO 139662618720064] Epoch[53] Batch[0] avg_epoch_loss=1.321364\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:36 INFO 139662618720064] #quality_metric: host=algo-1, epoch=53, batch=0 train loss <loss>=1.32136392593\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:38 INFO 139662618720064] Epoch[53] Batch[5] avg_epoch_loss=1.295701\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:38 INFO 139662618720064] #quality_metric: host=algo-1, epoch=53, batch=5 train loss <loss>=1.29570074876\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:38 INFO 139662618720064] Epoch[53] Batch [5]#011Speed: 190.02 samples/sec#011loss=1.295701\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:39 INFO 139662618720064] processed a total of 616 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3833.8849544525146, \"sum\": 3833.8849544525146, \"min\": 3833.8849544525146}}, \"EndTime\": 1601797179.454605, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797175.620651}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:39 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=160.66729569 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:39 INFO 139662618720064] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:39 INFO 139662618720064] #quality_metric: host=algo-1, epoch=53, train loss <loss>=1.32240703106\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:39 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:40 INFO 139662618720064] Epoch[54] Batch[0] avg_epoch_loss=1.231034\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:40 INFO 139662618720064] #quality_metric: host=algo-1, epoch=54, batch=0 train loss <loss>=1.23103356361\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:41 INFO 139662618720064] Epoch[54] Batch[5] avg_epoch_loss=1.389287\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:41 INFO 139662618720064] #quality_metric: host=algo-1, epoch=54, batch=5 train loss <loss>=1.3892869552\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:41 INFO 139662618720064] Epoch[54] Batch [5]#011Speed: 189.66 samples/sec#011loss=1.389287\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:43 INFO 139662618720064] processed a total of 618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3886.8539333343506, \"sum\": 3886.8539333343506, \"min\": 3886.8539333343506}}, \"EndTime\": 1601797183.342142, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797179.454689}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:43 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=158.992364921 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:43 INFO 139662618720064] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:43 INFO 139662618720064] #quality_metric: host=algo-1, epoch=54, train loss <loss>=1.33911947012\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:43 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:44 INFO 139662618720064] Epoch[55] Batch[0] avg_epoch_loss=1.195096\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:44 INFO 139662618720064] #quality_metric: host=algo-1, epoch=55, batch=0 train loss <loss>=1.19509577751\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:45 INFO 139662618720064] Epoch[55] Batch[5] avg_epoch_loss=1.320780\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:45 INFO 139662618720064] #quality_metric: host=algo-1, epoch=55, batch=5 train loss <loss>=1.32078009844\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:45 INFO 139662618720064] Epoch[55] Batch [5]#011Speed: 186.67 samples/sec#011loss=1.320780\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:47 INFO 139662618720064] processed a total of 593 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3867.9018020629883, \"sum\": 3867.9018020629883, \"min\": 3867.9018020629883}}, \"EndTime\": 1601797187.210634, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797183.342225}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:47 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=153.307860656 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:47 INFO 139662618720064] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:47 INFO 139662618720064] #quality_metric: host=algo-1, epoch=55, train loss <loss>=1.34337664843\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:47 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:47 INFO 139662618720064] Epoch[56] Batch[0] avg_epoch_loss=1.301099\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:47 INFO 139662618720064] #quality_metric: host=algo-1, epoch=56, batch=0 train loss <loss>=1.30109870434\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:49 INFO 139662618720064] Epoch[56] Batch[5] avg_epoch_loss=1.326596\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:49 INFO 139662618720064] #quality_metric: host=algo-1, epoch=56, batch=5 train loss <loss>=1.32659645875\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:49 INFO 139662618720064] Epoch[56] Batch [5]#011Speed: 185.78 samples/sec#011loss=1.326596\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:51 INFO 139662618720064] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3856.8649291992188, \"sum\": 3856.8649291992188, \"min\": 3856.8649291992188}}, \"EndTime\": 1601797191.068125, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797187.210721}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:51 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=160.747027473 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:51 INFO 139662618720064] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:51 INFO 139662618720064] #quality_metric: host=algo-1, epoch=56, train loss <loss>=1.30723643303\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:51 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:51 INFO 139662618720064] Epoch[57] Batch[0] avg_epoch_loss=1.219643\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:51 INFO 139662618720064] #quality_metric: host=algo-1, epoch=57, batch=0 train loss <loss>=1.21964335442\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:53 INFO 139662618720064] Epoch[57] Batch[5] avg_epoch_loss=1.393973\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:53 INFO 139662618720064] #quality_metric: host=algo-1, epoch=57, batch=5 train loss <loss>=1.39397291342\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:53 INFO 139662618720064] Epoch[57] Batch [5]#011Speed: 190.12 samples/sec#011loss=1.393973\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:54 INFO 139662618720064] processed a total of 607 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3882.606029510498, \"sum\": 3882.606029510498, \"min\": 3882.606029510498}}, \"EndTime\": 1601797194.951293, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797191.068212}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:54 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=156.333147686 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:54 INFO 139662618720064] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:54 INFO 139662618720064] #quality_metric: host=algo-1, epoch=57, train loss <loss>=1.34084265232\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:54 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:55 INFO 139662618720064] Epoch[58] Batch[0] avg_epoch_loss=1.230710\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:55 INFO 139662618720064] #quality_metric: host=algo-1, epoch=58, batch=0 train loss <loss>=1.23070991039\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:57 INFO 139662618720064] Epoch[58] Batch[5] avg_epoch_loss=1.286537\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:57 INFO 139662618720064] #quality_metric: host=algo-1, epoch=58, batch=5 train loss <loss>=1.28653713067\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:57 INFO 139662618720064] Epoch[58] Batch [5]#011Speed: 186.97 samples/sec#011loss=1.286537\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:58 INFO 139662618720064] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3922.3110675811768, \"sum\": 3922.3110675811768, \"min\": 3922.3110675811768}}, \"EndTime\": 1601797198.874169, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797194.95138}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:58 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=159.850256622 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:58 INFO 139662618720064] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:58 INFO 139662618720064] #quality_metric: host=algo-1, epoch=58, train loss <loss>=1.28084446192\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:58 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:58 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_b2a2e85a-9468-4060-bdb0-dfc7fd1765e2-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 103.75094413757324, \"sum\": 103.75094413757324, \"min\": 103.75094413757324}}, \"EndTime\": 1601797198.978547, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797198.874246}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:59 INFO 139662618720064] Epoch[59] Batch[0] avg_epoch_loss=1.238581\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:39:59 INFO 139662618720064] #quality_metric: host=algo-1, epoch=59, batch=0 train loss <loss>=1.23858141899\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:01 INFO 139662618720064] Epoch[59] Batch[5] avg_epoch_loss=1.317945\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:01 INFO 139662618720064] #quality_metric: host=algo-1, epoch=59, batch=5 train loss <loss>=1.31794522206\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:01 INFO 139662618720064] Epoch[59] Batch [5]#011Speed: 187.82 samples/sec#011loss=1.317945\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:03 INFO 139662618720064] Epoch[59] Batch[10] avg_epoch_loss=1.401776\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:03 INFO 139662618720064] #quality_metric: host=algo-1, epoch=59, batch=10 train loss <loss>=1.50237252712\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:03 INFO 139662618720064] Epoch[59] Batch [10]#011Speed: 182.14 samples/sec#011loss=1.502373\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:03 INFO 139662618720064] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4245.774984359741, \"sum\": 4245.774984359741, \"min\": 4245.774984359741}}, \"EndTime\": 1601797203.224449, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797198.978605}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:03 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=152.853232325 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:03 INFO 139662618720064] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:03 INFO 139662618720064] #quality_metric: host=algo-1, epoch=59, train loss <loss>=1.40177581527\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:03 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:04 INFO 139662618720064] Epoch[60] Batch[0] avg_epoch_loss=1.073030\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:04 INFO 139662618720064] #quality_metric: host=algo-1, epoch=60, batch=0 train loss <loss>=1.07302975655\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:05 INFO 139662618720064] Epoch[60] Batch[5] avg_epoch_loss=1.244151\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:05 INFO 139662618720064] #quality_metric: host=algo-1, epoch=60, batch=5 train loss <loss>=1.24415091674\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:05 INFO 139662618720064] Epoch[60] Batch [5]#011Speed: 184.64 samples/sec#011loss=1.244151\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:07 INFO 139662618720064] Epoch[60] Batch[10] avg_epoch_loss=1.234548\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:07 INFO 139662618720064] #quality_metric: host=algo-1, epoch=60, batch=10 train loss <loss>=1.22302488089\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:07 INFO 139662618720064] Epoch[60] Batch [10]#011Speed: 188.15 samples/sec#011loss=1.223025\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:07 INFO 139662618720064] processed a total of 684 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4233.237028121948, \"sum\": 4233.237028121948, \"min\": 4233.237028121948}}, \"EndTime\": 1601797207.458253, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797203.224536}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:07 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=161.573901669 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:07 INFO 139662618720064] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:07 INFO 139662618720064] #quality_metric: host=algo-1, epoch=60, train loss <loss>=1.23454817317\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:07 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:07 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_36f2e547-0fb7-4194-991f-9954476b34cb-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 111.74297332763672, \"sum\": 111.74297332763672, \"min\": 111.74297332763672}}, \"EndTime\": 1601797207.570614, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797207.458331}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:08 INFO 139662618720064] Epoch[61] Batch[0] avg_epoch_loss=1.366163\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:08 INFO 139662618720064] #quality_metric: host=algo-1, epoch=61, batch=0 train loss <loss>=1.36616289616\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:10 INFO 139662618720064] Epoch[61] Batch[5] avg_epoch_loss=1.235756\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:10 INFO 139662618720064] #quality_metric: host=algo-1, epoch=61, batch=5 train loss <loss>=1.23575637738\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:10 INFO 139662618720064] Epoch[61] Batch [5]#011Speed: 187.07 samples/sec#011loss=1.235756\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:11 INFO 139662618720064] Epoch[61] Batch[10] avg_epoch_loss=1.293842\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:11 INFO 139662618720064] #quality_metric: host=algo-1, epoch=61, batch=10 train loss <loss>=1.36354572773\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:11 INFO 139662618720064] Epoch[61] Batch [10]#011Speed: 189.78 samples/sec#011loss=1.363546\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:11 INFO 139662618720064] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4209.301948547363, \"sum\": 4209.301948547363, \"min\": 4209.301948547363}}, \"EndTime\": 1601797211.780052, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797207.570693}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:11 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=153.4653938 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:11 INFO 139662618720064] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:11 INFO 139662618720064] #quality_metric: host=algo-1, epoch=61, train loss <loss>=1.29384244572\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:11 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:12 INFO 139662618720064] Epoch[62] Batch[0] avg_epoch_loss=1.220010\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:12 INFO 139662618720064] #quality_metric: host=algo-1, epoch=62, batch=0 train loss <loss>=1.22001004219\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:14 INFO 139662618720064] Epoch[62] Batch[5] avg_epoch_loss=1.227318\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:14 INFO 139662618720064] #quality_metric: host=algo-1, epoch=62, batch=5 train loss <loss>=1.22731794914\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:14 INFO 139662618720064] Epoch[62] Batch [5]#011Speed: 189.77 samples/sec#011loss=1.227318\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:15 INFO 139662618720064] processed a total of 601 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3910.5849266052246, \"sum\": 3910.5849266052246, \"min\": 3910.5849266052246}}, \"EndTime\": 1601797215.691163, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797211.780131}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:15 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=153.680220744 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:15 INFO 139662618720064] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:15 INFO 139662618720064] #quality_metric: host=algo-1, epoch=62, train loss <loss>=1.20953657031\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:15 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:15 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_ddb13d5a-12d5-44b0-930a-af4f90e79a83-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 103.82890701293945, \"sum\": 103.82890701293945, \"min\": 103.82890701293945}}, \"EndTime\": 1601797215.79567, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797215.691253}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:16 INFO 139662618720064] Epoch[63] Batch[0] avg_epoch_loss=1.449816\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:16 INFO 139662618720064] #quality_metric: host=algo-1, epoch=63, batch=0 train loss <loss>=1.44981598854\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:18 INFO 139662618720064] Epoch[63] Batch[5] avg_epoch_loss=1.351106\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:18 INFO 139662618720064] #quality_metric: host=algo-1, epoch=63, batch=5 train loss <loss>=1.35110600789\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:18 INFO 139662618720064] Epoch[63] Batch [5]#011Speed: 188.88 samples/sec#011loss=1.351106\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:19 INFO 139662618720064] Epoch[63] Batch[10] avg_epoch_loss=1.313967\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:19 INFO 139662618720064] #quality_metric: host=algo-1, epoch=63, batch=10 train loss <loss>=1.26939995289\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:19 INFO 139662618720064] Epoch[63] Batch [10]#011Speed: 186.99 samples/sec#011loss=1.269400\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:19 INFO 139662618720064] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4188.743114471436, \"sum\": 4188.743114471436, \"min\": 4188.743114471436}}, \"EndTime\": 1601797219.984562, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797215.795745}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:19 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=153.740818034 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:19 INFO 139662618720064] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:19 INFO 139662618720064] #quality_metric: host=algo-1, epoch=63, train loss <loss>=1.31396689198\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:19 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:20 INFO 139662618720064] Epoch[64] Batch[0] avg_epoch_loss=1.337568\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:20 INFO 139662618720064] #quality_metric: host=algo-1, epoch=64, batch=0 train loss <loss>=1.33756756783\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:22 INFO 139662618720064] Epoch[64] Batch[5] avg_epoch_loss=1.255419\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:22 INFO 139662618720064] #quality_metric: host=algo-1, epoch=64, batch=5 train loss <loss>=1.25541887681\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:22 INFO 139662618720064] Epoch[64] Batch [5]#011Speed: 185.97 samples/sec#011loss=1.255419\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:23 INFO 139662618720064] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3869.8129653930664, \"sum\": 3869.8129653930664, \"min\": 3869.8129653930664}}, \"EndTime\": 1601797223.854976, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797219.984643}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:23 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=164.344228798 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:23 INFO 139662618720064] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:23 INFO 139662618720064] #quality_metric: host=algo-1, epoch=64, train loss <loss>=1.31510062218\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:23 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:24 INFO 139662618720064] Epoch[65] Batch[0] avg_epoch_loss=1.468050\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:24 INFO 139662618720064] #quality_metric: host=algo-1, epoch=65, batch=0 train loss <loss>=1.46805000305\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:26 INFO 139662618720064] Epoch[65] Batch[5] avg_epoch_loss=1.353894\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:26 INFO 139662618720064] #quality_metric: host=algo-1, epoch=65, batch=5 train loss <loss>=1.35389449199\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:26 INFO 139662618720064] Epoch[65] Batch [5]#011Speed: 188.89 samples/sec#011loss=1.353894\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:28 INFO 139662618720064] Epoch[65] Batch[10] avg_epoch_loss=1.339912\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:28 INFO 139662618720064] #quality_metric: host=algo-1, epoch=65, batch=10 train loss <loss>=1.32313306332\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:28 INFO 139662618720064] Epoch[65] Batch [10]#011Speed: 187.87 samples/sec#011loss=1.323133\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:28 INFO 139662618720064] processed a total of 670 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4197.517156600952, \"sum\": 4197.517156600952, \"min\": 4197.517156600952}}, \"EndTime\": 1601797228.053052, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797223.855053}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:28 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=159.613689688 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:28 INFO 139662618720064] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:28 INFO 139662618720064] #quality_metric: host=algo-1, epoch=65, train loss <loss>=1.33991202441\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:28 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:28 INFO 139662618720064] Epoch[66] Batch[0] avg_epoch_loss=1.154504\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:28 INFO 139662618720064] #quality_metric: host=algo-1, epoch=66, batch=0 train loss <loss>=1.15450417995\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:30 INFO 139662618720064] Epoch[66] Batch[5] avg_epoch_loss=1.264506\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:30 INFO 139662618720064] #quality_metric: host=algo-1, epoch=66, batch=5 train loss <loss>=1.26450564464\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:30 INFO 139662618720064] Epoch[66] Batch [5]#011Speed: 187.20 samples/sec#011loss=1.264506\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:32 INFO 139662618720064] Epoch[66] Batch[10] avg_epoch_loss=1.184338\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:32 INFO 139662618720064] #quality_metric: host=algo-1, epoch=66, batch=10 train loss <loss>=1.08813608289\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:32 INFO 139662618720064] Epoch[66] Batch [10]#011Speed: 189.02 samples/sec#011loss=1.088136\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:32 INFO 139662618720064] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4191.337108612061, \"sum\": 4191.337108612061, \"min\": 4191.337108612061}}, \"EndTime\": 1601797232.244938, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797228.053128}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:32 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=153.168728916 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:32 INFO 139662618720064] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:32 INFO 139662618720064] #quality_metric: host=algo-1, epoch=66, train loss <loss>=1.18433766202\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:32 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:32 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_5497c2db-9160-4c49-b0c4-434878add7c5-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 109.50016975402832, \"sum\": 109.50016975402832, \"min\": 109.50016975402832}}, \"EndTime\": 1601797232.355006, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797232.245017}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:33 INFO 139662618720064] Epoch[67] Batch[0] avg_epoch_loss=1.259080\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:33 INFO 139662618720064] #quality_metric: host=algo-1, epoch=67, batch=0 train loss <loss>=1.25908005238\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:34 INFO 139662618720064] Epoch[67] Batch[5] avg_epoch_loss=1.306978\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:34 INFO 139662618720064] #quality_metric: host=algo-1, epoch=67, batch=5 train loss <loss>=1.30697784821\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:34 INFO 139662618720064] Epoch[67] Batch [5]#011Speed: 187.82 samples/sec#011loss=1.306978\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:36 INFO 139662618720064] processed a total of 619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3855.752944946289, \"sum\": 3855.752944946289, \"min\": 3855.752944946289}}, \"EndTime\": 1601797236.210896, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797232.355084}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:36 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=160.535331016 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:36 INFO 139662618720064] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:36 INFO 139662618720064] #quality_metric: host=algo-1, epoch=67, train loss <loss>=1.27296886444\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:36 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:37 INFO 139662618720064] Epoch[68] Batch[0] avg_epoch_loss=1.434902\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:37 INFO 139662618720064] #quality_metric: host=algo-1, epoch=68, batch=0 train loss <loss>=1.43490195274\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:38 INFO 139662618720064] Epoch[68] Batch[5] avg_epoch_loss=1.329448\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:38 INFO 139662618720064] #quality_metric: host=algo-1, epoch=68, batch=5 train loss <loss>=1.32944844166\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:38 INFO 139662618720064] Epoch[68] Batch [5]#011Speed: 189.17 samples/sec#011loss=1.329448\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:40 INFO 139662618720064] Epoch[68] Batch[10] avg_epoch_loss=1.345395\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:40 INFO 139662618720064] #quality_metric: host=algo-1, epoch=68, batch=10 train loss <loss>=1.36453092098\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:40 INFO 139662618720064] Epoch[68] Batch [10]#011Speed: 182.31 samples/sec#011loss=1.364531\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:40 INFO 139662618720064] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4238.6438846588135, \"sum\": 4238.6438846588135, \"min\": 4238.6438846588135}}, \"EndTime\": 1601797240.450122, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797236.21096}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:40 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=154.290293065 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:40 INFO 139662618720064] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:40 INFO 139662618720064] #quality_metric: host=algo-1, epoch=68, train loss <loss>=1.34539502317\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:40 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:41 INFO 139662618720064] Epoch[69] Batch[0] avg_epoch_loss=1.249241\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:41 INFO 139662618720064] #quality_metric: host=algo-1, epoch=69, batch=0 train loss <loss>=1.24924147129\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:42 INFO 139662618720064] Epoch[69] Batch[5] avg_epoch_loss=1.235771\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:42 INFO 139662618720064] #quality_metric: host=algo-1, epoch=69, batch=5 train loss <loss>=1.23577086131\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:42 INFO 139662618720064] Epoch[69] Batch [5]#011Speed: 189.25 samples/sec#011loss=1.235771\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:44 INFO 139662618720064] Epoch[69] Batch[10] avg_epoch_loss=1.248365\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:44 INFO 139662618720064] #quality_metric: host=algo-1, epoch=69, batch=10 train loss <loss>=1.26347773075\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:44 INFO 139662618720064] Epoch[69] Batch [10]#011Speed: 186.59 samples/sec#011loss=1.263478\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:44 INFO 139662618720064] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4195.894002914429, \"sum\": 4195.894002914429, \"min\": 4195.894002914429}}, \"EndTime\": 1601797244.646598, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797240.450199}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:44 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=155.862200209 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:44 INFO 139662618720064] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:44 INFO 139662618720064] #quality_metric: host=algo-1, epoch=69, train loss <loss>=1.24836489287\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:44 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:45 INFO 139662618720064] Epoch[70] Batch[0] avg_epoch_loss=1.318520\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:45 INFO 139662618720064] #quality_metric: host=algo-1, epoch=70, batch=0 train loss <loss>=1.31852006912\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:47 INFO 139662618720064] Epoch[70] Batch[5] avg_epoch_loss=1.241045\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:47 INFO 139662618720064] #quality_metric: host=algo-1, epoch=70, batch=5 train loss <loss>=1.24104456107\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:47 INFO 139662618720064] Epoch[70] Batch [5]#011Speed: 188.36 samples/sec#011loss=1.241045\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:48 INFO 139662618720064] Epoch[70] Batch[10] avg_epoch_loss=1.251700\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:48 INFO 139662618720064] #quality_metric: host=algo-1, epoch=70, batch=10 train loss <loss>=1.26448707581\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:48 INFO 139662618720064] Epoch[70] Batch [10]#011Speed: 187.61 samples/sec#011loss=1.264487\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:48 INFO 139662618720064] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4195.012092590332, \"sum\": 4195.012092590332, \"min\": 4195.012092590332}}, \"EndTime\": 1601797248.842224, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797244.646674}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:48 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=154.941567944 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:48 INFO 139662618720064] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:48 INFO 139662618720064] #quality_metric: host=algo-1, epoch=70, train loss <loss>=1.25170024959\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:48 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:49 INFO 139662618720064] Epoch[71] Batch[0] avg_epoch_loss=1.314212\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:49 INFO 139662618720064] #quality_metric: host=algo-1, epoch=71, batch=0 train loss <loss>=1.31421160698\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:51 INFO 139662618720064] Epoch[71] Batch[5] avg_epoch_loss=1.213070\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:51 INFO 139662618720064] #quality_metric: host=algo-1, epoch=71, batch=5 train loss <loss>=1.21307015419\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:51 INFO 139662618720064] Epoch[71] Batch [5]#011Speed: 188.38 samples/sec#011loss=1.213070\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:53 INFO 139662618720064] Epoch[71] Batch[10] avg_epoch_loss=1.181280\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:53 INFO 139662618720064] #quality_metric: host=algo-1, epoch=71, batch=10 train loss <loss>=1.14313136339\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:53 INFO 139662618720064] Epoch[71] Batch [10]#011Speed: 188.76 samples/sec#011loss=1.143131\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:53 INFO 139662618720064] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4191.065788269043, \"sum\": 4191.065788269043, \"min\": 4191.065788269043}}, \"EndTime\": 1601797253.033838, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797248.842305}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:53 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=156.996100372 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:53 INFO 139662618720064] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:53 INFO 139662618720064] #quality_metric: host=algo-1, epoch=71, train loss <loss>=1.18127979474\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:53 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:53 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_cea3ca57-44a8-436b-9521-00ed709ea0d2-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 105.82304000854492, \"sum\": 105.82304000854492, \"min\": 105.82304000854492}}, \"EndTime\": 1601797253.140265, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797253.033916}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:53 INFO 139662618720064] Epoch[72] Batch[0] avg_epoch_loss=1.261054\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:53 INFO 139662618720064] #quality_metric: host=algo-1, epoch=72, batch=0 train loss <loss>=1.26105415821\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:55 INFO 139662618720064] Epoch[72] Batch[5] avg_epoch_loss=1.239182\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:55 INFO 139662618720064] #quality_metric: host=algo-1, epoch=72, batch=5 train loss <loss>=1.23918151855\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:55 INFO 139662618720064] Epoch[72] Batch [5]#011Speed: 186.80 samples/sec#011loss=1.239182\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:57 INFO 139662618720064] Epoch[72] Batch[10] avg_epoch_loss=1.216560\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:57 INFO 139662618720064] #quality_metric: host=algo-1, epoch=72, batch=10 train loss <loss>=1.18941463232\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:57 INFO 139662618720064] Epoch[72] Batch [10]#011Speed: 187.16 samples/sec#011loss=1.189415\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:57 INFO 139662618720064] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4210.121154785156, \"sum\": 4210.121154785156, \"min\": 4210.121154785156}}, \"EndTime\": 1601797257.350529, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797253.140339}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:57 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=154.622685778 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:57 INFO 139662618720064] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:57 INFO 139662618720064] #quality_metric: host=algo-1, epoch=72, train loss <loss>=1.21656020663\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:57 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:58 INFO 139662618720064] Epoch[73] Batch[0] avg_epoch_loss=1.298530\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:58 INFO 139662618720064] #quality_metric: host=algo-1, epoch=73, batch=0 train loss <loss>=1.29852950573\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:59 INFO 139662618720064] Epoch[73] Batch[5] avg_epoch_loss=1.223870\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:59 INFO 139662618720064] #quality_metric: host=algo-1, epoch=73, batch=5 train loss <loss>=1.22387033701\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:40:59 INFO 139662618720064] Epoch[73] Batch [5]#011Speed: 186.82 samples/sec#011loss=1.223870\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:01 INFO 139662618720064] processed a total of 622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3859.8310947418213, \"sum\": 3859.8310947418213, \"min\": 3859.8310947418213}}, \"EndTime\": 1601797261.210972, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797257.350614}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:01 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=161.142279565 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:01 INFO 139662618720064] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:01 INFO 139662618720064] #quality_metric: host=algo-1, epoch=73, train loss <loss>=1.24127488136\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:01 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:01 INFO 139662618720064] Epoch[74] Batch[0] avg_epoch_loss=1.144885\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:01 INFO 139662618720064] #quality_metric: host=algo-1, epoch=74, batch=0 train loss <loss>=1.14488518238\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:03 INFO 139662618720064] Epoch[74] Batch[5] avg_epoch_loss=1.211141\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:03 INFO 139662618720064] #quality_metric: host=algo-1, epoch=74, batch=5 train loss <loss>=1.21114142736\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:03 INFO 139662618720064] Epoch[74] Batch [5]#011Speed: 188.43 samples/sec#011loss=1.211141\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:05 INFO 139662618720064] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3865.9400939941406, \"sum\": 3865.9400939941406, \"min\": 3865.9400939941406}}, \"EndTime\": 1601797265.077513, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797261.211052}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:05 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=162.439028048 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:05 INFO 139662618720064] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:05 INFO 139662618720064] #quality_metric: host=algo-1, epoch=74, train loss <loss>=1.2402669549\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:05 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:05 INFO 139662618720064] Epoch[75] Batch[0] avg_epoch_loss=1.269718\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:05 INFO 139662618720064] #quality_metric: host=algo-1, epoch=75, batch=0 train loss <loss>=1.26971828938\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:07 INFO 139662618720064] Epoch[75] Batch[5] avg_epoch_loss=1.246636\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:07 INFO 139662618720064] #quality_metric: host=algo-1, epoch=75, batch=5 train loss <loss>=1.24663581451\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:07 INFO 139662618720064] Epoch[75] Batch [5]#011Speed: 189.48 samples/sec#011loss=1.246636\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:09 INFO 139662618720064] Epoch[75] Batch[10] avg_epoch_loss=1.166411\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:09 INFO 139662618720064] #quality_metric: host=algo-1, epoch=75, batch=10 train loss <loss>=1.07014203072\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:09 INFO 139662618720064] Epoch[75] Batch [10]#011Speed: 188.98 samples/sec#011loss=1.070142\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:09 INFO 139662618720064] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4187.69097328186, \"sum\": 4187.69097328186, \"min\": 4187.69097328186}}, \"EndTime\": 1601797269.265771, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797265.077599}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:09 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=157.361370515 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:09 INFO 139662618720064] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:09 INFO 139662618720064] #quality_metric: host=algo-1, epoch=75, train loss <loss>=1.16641136733\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:09 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:09 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_1dda4885-c9b4-4b3f-86d7-3ff5aeb180b0-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 146.1961269378662, \"sum\": 146.1961269378662, \"min\": 146.1961269378662}}, \"EndTime\": 1601797269.412598, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797269.265854}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:10 INFO 139662618720064] Epoch[76] Batch[0] avg_epoch_loss=1.217017\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:10 INFO 139662618720064] #quality_metric: host=algo-1, epoch=76, batch=0 train loss <loss>=1.21701741219\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:11 INFO 139662618720064] Epoch[76] Batch[5] avg_epoch_loss=1.278810\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:11 INFO 139662618720064] #quality_metric: host=algo-1, epoch=76, batch=5 train loss <loss>=1.27880966663\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:11 INFO 139662618720064] Epoch[76] Batch [5]#011Speed: 187.19 samples/sec#011loss=1.278810\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:13 INFO 139662618720064] Epoch[76] Batch[10] avg_epoch_loss=1.278829\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:13 INFO 139662618720064] #quality_metric: host=algo-1, epoch=76, batch=10 train loss <loss>=1.27885212898\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:13 INFO 139662618720064] Epoch[76] Batch [10]#011Speed: 190.66 samples/sec#011loss=1.278852\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:13 INFO 139662618720064] processed a total of 681 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4212.082147598267, \"sum\": 4212.082147598267, \"min\": 4212.082147598267}}, \"EndTime\": 1601797273.624829, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797269.412674}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:13 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=161.673164507 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:13 INFO 139662618720064] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:13 INFO 139662618720064] #quality_metric: host=algo-1, epoch=76, train loss <loss>=1.2788289677\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:13 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:14 INFO 139662618720064] Epoch[77] Batch[0] avg_epoch_loss=1.255189\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:14 INFO 139662618720064] #quality_metric: host=algo-1, epoch=77, batch=0 train loss <loss>=1.25518929958\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:16 INFO 139662618720064] Epoch[77] Batch[5] avg_epoch_loss=1.323780\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:16 INFO 139662618720064] #quality_metric: host=algo-1, epoch=77, batch=5 train loss <loss>=1.32377952337\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:16 INFO 139662618720064] Epoch[77] Batch [5]#011Speed: 187.83 samples/sec#011loss=1.323780\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:17 INFO 139662618720064] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3861.177921295166, \"sum\": 3861.177921295166, \"min\": 3861.177921295166}}, \"EndTime\": 1601797277.486514, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797273.624908}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:17 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=162.898385339 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:17 INFO 139662618720064] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:17 INFO 139662618720064] #quality_metric: host=algo-1, epoch=77, train loss <loss>=1.30593876839\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:17 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:18 INFO 139662618720064] Epoch[78] Batch[0] avg_epoch_loss=1.283387\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:18 INFO 139662618720064] #quality_metric: host=algo-1, epoch=78, batch=0 train loss <loss>=1.28338682652\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:20 INFO 139662618720064] Epoch[78] Batch[5] avg_epoch_loss=1.268650\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:20 INFO 139662618720064] #quality_metric: host=algo-1, epoch=78, batch=5 train loss <loss>=1.26865015427\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:20 INFO 139662618720064] Epoch[78] Batch [5]#011Speed: 187.75 samples/sec#011loss=1.268650\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:21 INFO 139662618720064] Epoch[78] Batch[10] avg_epoch_loss=1.263263\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:21 INFO 139662618720064] #quality_metric: host=algo-1, epoch=78, batch=10 train loss <loss>=1.25679802895\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:21 INFO 139662618720064] Epoch[78] Batch [10]#011Speed: 188.85 samples/sec#011loss=1.256798\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:21 INFO 139662618720064] processed a total of 667 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4264.4689083099365, \"sum\": 4264.4689083099365, \"min\": 4264.4689083099365}}, \"EndTime\": 1601797281.751581, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797277.486598}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:21 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=156.404248966 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:21 INFO 139662618720064] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:21 INFO 139662618720064] #quality_metric: host=algo-1, epoch=78, train loss <loss>=1.26326282458\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:21 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:22 INFO 139662618720064] Epoch[79] Batch[0] avg_epoch_loss=1.465678\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:22 INFO 139662618720064] #quality_metric: host=algo-1, epoch=79, batch=0 train loss <loss>=1.46567761898\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:24 INFO 139662618720064] Epoch[79] Batch[5] avg_epoch_loss=1.322422\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:24 INFO 139662618720064] #quality_metric: host=algo-1, epoch=79, batch=5 train loss <loss>=1.32242155075\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:24 INFO 139662618720064] Epoch[79] Batch [5]#011Speed: 188.33 samples/sec#011loss=1.322422\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:25 INFO 139662618720064] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3909.4879627227783, \"sum\": 3909.4879627227783, \"min\": 3909.4879627227783}}, \"EndTime\": 1601797285.661596, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797281.751661}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:25 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=162.931900841 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:25 INFO 139662618720064] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:25 INFO 139662618720064] #quality_metric: host=algo-1, epoch=79, train loss <loss>=1.33555185795\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:25 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:26 INFO 139662618720064] Epoch[80] Batch[0] avg_epoch_loss=1.216300\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:26 INFO 139662618720064] #quality_metric: host=algo-1, epoch=80, batch=0 train loss <loss>=1.21629977226\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:28 INFO 139662618720064] Epoch[80] Batch[5] avg_epoch_loss=1.218678\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:28 INFO 139662618720064] #quality_metric: host=algo-1, epoch=80, batch=5 train loss <loss>=1.21867821614\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:28 INFO 139662618720064] Epoch[80] Batch [5]#011Speed: 189.99 samples/sec#011loss=1.218678\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:29 INFO 139662618720064] processed a total of 615 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3811.5031719207764, \"sum\": 3811.5031719207764, \"min\": 3811.5031719207764}}, \"EndTime\": 1601797289.473671, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797285.661674}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:29 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=161.348294113 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:29 INFO 139662618720064] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:29 INFO 139662618720064] #quality_metric: host=algo-1, epoch=80, train loss <loss>=1.21907978058\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:29 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:30 INFO 139662618720064] Epoch[81] Batch[0] avg_epoch_loss=1.167909\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:30 INFO 139662618720064] #quality_metric: host=algo-1, epoch=81, batch=0 train loss <loss>=1.16790938377\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:32 INFO 139662618720064] Epoch[81] Batch[5] avg_epoch_loss=1.268860\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:32 INFO 139662618720064] #quality_metric: host=algo-1, epoch=81, batch=5 train loss <loss>=1.26885974407\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:32 INFO 139662618720064] Epoch[81] Batch [5]#011Speed: 189.16 samples/sec#011loss=1.268860\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:33 INFO 139662618720064] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3915.121078491211, \"sum\": 3915.121078491211, \"min\": 3915.121078491211}}, \"EndTime\": 1601797293.389354, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797289.473756}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:33 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=163.463666413 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:33 INFO 139662618720064] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:33 INFO 139662618720064] #quality_metric: host=algo-1, epoch=81, train loss <loss>=1.23442332745\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:33 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:34 INFO 139662618720064] Epoch[82] Batch[0] avg_epoch_loss=1.234018\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:34 INFO 139662618720064] #quality_metric: host=algo-1, epoch=82, batch=0 train loss <loss>=1.2340182066\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:35 INFO 139662618720064] Epoch[82] Batch[5] avg_epoch_loss=1.197538\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:35 INFO 139662618720064] #quality_metric: host=algo-1, epoch=82, batch=5 train loss <loss>=1.19753750165\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:35 INFO 139662618720064] Epoch[82] Batch [5]#011Speed: 187.17 samples/sec#011loss=1.197538\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:37 INFO 139662618720064] Epoch[82] Batch[10] avg_epoch_loss=1.164750\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:37 INFO 139662618720064] #quality_metric: host=algo-1, epoch=82, batch=10 train loss <loss>=1.12540409565\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:37 INFO 139662618720064] Epoch[82] Batch [10]#011Speed: 188.31 samples/sec#011loss=1.125404\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:37 INFO 139662618720064] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4216.185092926025, \"sum\": 4216.185092926025, \"min\": 4216.185092926025}}, \"EndTime\": 1601797297.606115, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797293.389438}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:37 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=152.977841357 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:37 INFO 139662618720064] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:37 INFO 139662618720064] #quality_metric: host=algo-1, epoch=82, train loss <loss>=1.16474958983\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:37 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:37 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_91f68758-cb53-435c-895e-109e4b151ac4-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 104.73799705505371, \"sum\": 104.73799705505371, \"min\": 104.73799705505371}}, \"EndTime\": 1601797297.711432, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797297.606184}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:38 INFO 139662618720064] Epoch[83] Batch[0] avg_epoch_loss=1.142138\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:38 INFO 139662618720064] #quality_metric: host=algo-1, epoch=83, batch=0 train loss <loss>=1.14213824272\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:40 INFO 139662618720064] Epoch[83] Batch[5] avg_epoch_loss=1.246778\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:40 INFO 139662618720064] #quality_metric: host=algo-1, epoch=83, batch=5 train loss <loss>=1.24677769343\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:40 INFO 139662618720064] Epoch[83] Batch [5]#011Speed: 183.86 samples/sec#011loss=1.246778\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:41 INFO 139662618720064] Epoch[83] Batch[10] avg_epoch_loss=1.275533\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:41 INFO 139662618720064] #quality_metric: host=algo-1, epoch=83, batch=10 train loss <loss>=1.31003911495\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:41 INFO 139662618720064] Epoch[83] Batch [10]#011Speed: 185.67 samples/sec#011loss=1.310039\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:41 INFO 139662618720064] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4254.676103591919, \"sum\": 4254.676103591919, \"min\": 4254.676103591919}}, \"EndTime\": 1601797301.966242, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797297.711506}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:41 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=154.649124182 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:41 INFO 139662618720064] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:41 INFO 139662618720064] #quality_metric: host=algo-1, epoch=83, train loss <loss>=1.27553288503\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:41 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:42 INFO 139662618720064] Epoch[84] Batch[0] avg_epoch_loss=1.123008\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:42 INFO 139662618720064] #quality_metric: host=algo-1, epoch=84, batch=0 train loss <loss>=1.12300765514\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:44 INFO 139662618720064] Epoch[84] Batch[5] avg_epoch_loss=1.157854\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:44 INFO 139662618720064] #quality_metric: host=algo-1, epoch=84, batch=5 train loss <loss>=1.15785449743\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:44 INFO 139662618720064] Epoch[84] Batch [5]#011Speed: 184.80 samples/sec#011loss=1.157854\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:46 INFO 139662618720064] Epoch[84] Batch[10] avg_epoch_loss=1.223075\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:46 INFO 139662618720064] #quality_metric: host=algo-1, epoch=84, batch=10 train loss <loss>=1.30134060383\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:46 INFO 139662618720064] Epoch[84] Batch [10]#011Speed: 187.78 samples/sec#011loss=1.301341\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:46 INFO 139662618720064] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4227.7021408081055, \"sum\": 4227.7021408081055, \"min\": 4227.7021408081055}}, \"EndTime\": 1601797306.194486, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797301.966322}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:46 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=152.324334286 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:46 INFO 139662618720064] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:46 INFO 139662618720064] #quality_metric: host=algo-1, epoch=84, train loss <loss>=1.22307545489\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:46 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:46 INFO 139662618720064] Epoch[85] Batch[0] avg_epoch_loss=1.211418\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:46 INFO 139662618720064] #quality_metric: host=algo-1, epoch=85, batch=0 train loss <loss>=1.21141815186\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:48 INFO 139662618720064] Epoch[85] Batch[5] avg_epoch_loss=1.255087\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:48 INFO 139662618720064] #quality_metric: host=algo-1, epoch=85, batch=5 train loss <loss>=1.25508664052\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:48 INFO 139662618720064] Epoch[85] Batch [5]#011Speed: 190.26 samples/sec#011loss=1.255087\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:50 INFO 139662618720064] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3876.338005065918, \"sum\": 3876.338005065918, \"min\": 3876.338005065918}}, \"EndTime\": 1601797310.071395, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797306.194566}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:50 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=163.808953286 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:50 INFO 139662618720064] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:50 INFO 139662618720064] #quality_metric: host=algo-1, epoch=85, train loss <loss>=1.2437489748\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:50 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:50 INFO 139662618720064] Epoch[86] Batch[0] avg_epoch_loss=1.287435\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:50 INFO 139662618720064] #quality_metric: host=algo-1, epoch=86, batch=0 train loss <loss>=1.28743517399\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:52 INFO 139662618720064] Epoch[86] Batch[5] avg_epoch_loss=1.240836\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:52 INFO 139662618720064] #quality_metric: host=algo-1, epoch=86, batch=5 train loss <loss>=1.24083594481\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:52 INFO 139662618720064] Epoch[86] Batch [5]#011Speed: 189.90 samples/sec#011loss=1.240836\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:54 INFO 139662618720064] Epoch[86] Batch[10] avg_epoch_loss=1.237150\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:54 INFO 139662618720064] #quality_metric: host=algo-1, epoch=86, batch=10 train loss <loss>=1.23272585869\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:54 INFO 139662618720064] Epoch[86] Batch [10]#011Speed: 185.46 samples/sec#011loss=1.232726\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:54 INFO 139662618720064] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4226.876020431519, \"sum\": 4226.876020431519, \"min\": 4226.876020431519}}, \"EndTime\": 1601797314.298841, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797310.071482}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:54 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=152.826521121 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:54 INFO 139662618720064] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:54 INFO 139662618720064] #quality_metric: host=algo-1, epoch=86, train loss <loss>=1.23714954203\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:54 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:55 INFO 139662618720064] Epoch[87] Batch[0] avg_epoch_loss=1.279850\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:55 INFO 139662618720064] #quality_metric: host=algo-1, epoch=87, batch=0 train loss <loss>=1.2798500061\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:56 INFO 139662618720064] Epoch[87] Batch[5] avg_epoch_loss=1.201132\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:56 INFO 139662618720064] #quality_metric: host=algo-1, epoch=87, batch=5 train loss <loss>=1.20113188028\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:56 INFO 139662618720064] Epoch[87] Batch [5]#011Speed: 188.35 samples/sec#011loss=1.201132\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:58 INFO 139662618720064] Epoch[87] Batch[10] avg_epoch_loss=1.209369\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:58 INFO 139662618720064] #quality_metric: host=algo-1, epoch=87, batch=10 train loss <loss>=1.21925303936\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:58 INFO 139662618720064] Epoch[87] Batch [10]#011Speed: 188.64 samples/sec#011loss=1.219253\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:58 INFO 139662618720064] processed a total of 669 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4241.440057754517, \"sum\": 4241.440057754517, \"min\": 4241.440057754517}}, \"EndTime\": 1601797318.540804, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797314.298921}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:58 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=157.72505956 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:58 INFO 139662618720064] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:58 INFO 139662618720064] #quality_metric: host=algo-1, epoch=87, train loss <loss>=1.20936877077\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:58 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:59 INFO 139662618720064] Epoch[88] Batch[0] avg_epoch_loss=1.297580\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:41:59 INFO 139662618720064] #quality_metric: host=algo-1, epoch=88, batch=0 train loss <loss>=1.29758048058\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:01 INFO 139662618720064] Epoch[88] Batch[5] avg_epoch_loss=1.207620\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:01 INFO 139662618720064] #quality_metric: host=algo-1, epoch=88, batch=5 train loss <loss>=1.20762006442\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:01 INFO 139662618720064] Epoch[88] Batch [5]#011Speed: 183.59 samples/sec#011loss=1.207620\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:02 INFO 139662618720064] Epoch[88] Batch[10] avg_epoch_loss=1.291852\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:02 INFO 139662618720064] #quality_metric: host=algo-1, epoch=88, batch=10 train loss <loss>=1.39293038845\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:02 INFO 139662618720064] Epoch[88] Batch [10]#011Speed: 186.67 samples/sec#011loss=1.392930\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:02 INFO 139662618720064] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4296.672105789185, \"sum\": 4296.672105789185, \"min\": 4296.672105789185}}, \"EndTime\": 1601797322.838, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797318.540883}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:02 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=150.810184767 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:02 INFO 139662618720064] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:02 INFO 139662618720064] #quality_metric: host=algo-1, epoch=88, train loss <loss>=1.29185202989\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:02 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:03 INFO 139662618720064] Epoch[89] Batch[0] avg_epoch_loss=1.041977\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:03 INFO 139662618720064] #quality_metric: host=algo-1, epoch=89, batch=0 train loss <loss>=1.04197716713\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:05 INFO 139662618720064] Epoch[89] Batch[5] avg_epoch_loss=1.201536\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:05 INFO 139662618720064] #quality_metric: host=algo-1, epoch=89, batch=5 train loss <loss>=1.20153590043\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:05 INFO 139662618720064] Epoch[89] Batch [5]#011Speed: 186.72 samples/sec#011loss=1.201536\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:06 INFO 139662618720064] processed a total of 617 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3888.828992843628, \"sum\": 3888.828992843628, \"min\": 3888.828992843628}}, \"EndTime\": 1601797326.727371, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797322.83808}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:06 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=158.655754085 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:06 INFO 139662618720064] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:06 INFO 139662618720064] #quality_metric: host=algo-1, epoch=89, train loss <loss>=1.15446496606\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:06 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:06 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_fd36c652-1f3a-4316-be63-aed226414c5f-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 105.12995719909668, \"sum\": 105.12995719909668, \"min\": 105.12995719909668}}, \"EndTime\": 1601797326.833093, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797326.727433}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:07 INFO 139662618720064] Epoch[90] Batch[0] avg_epoch_loss=1.420627\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:07 INFO 139662618720064] #quality_metric: host=algo-1, epoch=90, batch=0 train loss <loss>=1.42062711716\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:09 INFO 139662618720064] Epoch[90] Batch[5] avg_epoch_loss=1.214364\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:09 INFO 139662618720064] #quality_metric: host=algo-1, epoch=90, batch=5 train loss <loss>=1.21436442931\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:09 INFO 139662618720064] Epoch[90] Batch [5]#011Speed: 188.09 samples/sec#011loss=1.214364\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:10 INFO 139662618720064] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3884.9449157714844, \"sum\": 3884.9449157714844, \"min\": 3884.9449157714844}}, \"EndTime\": 1601797330.718169, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797326.833162}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:10 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=164.733577099 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:10 INFO 139662618720064] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:10 INFO 139662618720064] #quality_metric: host=algo-1, epoch=90, train loss <loss>=1.23353520632\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:10 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:11 INFO 139662618720064] Epoch[91] Batch[0] avg_epoch_loss=1.178635\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:11 INFO 139662618720064] #quality_metric: host=algo-1, epoch=91, batch=0 train loss <loss>=1.17863547802\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:13 INFO 139662618720064] Epoch[91] Batch[5] avg_epoch_loss=1.240173\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:13 INFO 139662618720064] #quality_metric: host=algo-1, epoch=91, batch=5 train loss <loss>=1.24017312129\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:13 INFO 139662618720064] Epoch[91] Batch [5]#011Speed: 189.61 samples/sec#011loss=1.240173\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:14 INFO 139662618720064] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3839.635133743286, \"sum\": 3839.635133743286, \"min\": 3839.635133743286}}, \"EndTime\": 1601797334.558416, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797330.71825}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:14 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=165.896657915 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:14 INFO 139662618720064] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:14 INFO 139662618720064] #quality_metric: host=algo-1, epoch=91, train loss <loss>=1.23388164043\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:14 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:15 INFO 139662618720064] Epoch[92] Batch[0] avg_epoch_loss=1.266951\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:15 INFO 139662618720064] #quality_metric: host=algo-1, epoch=92, batch=0 train loss <loss>=1.2669506073\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:17 INFO 139662618720064] Epoch[92] Batch[5] avg_epoch_loss=1.162084\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:17 INFO 139662618720064] #quality_metric: host=algo-1, epoch=92, batch=5 train loss <loss>=1.16208390395\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:17 INFO 139662618720064] Epoch[92] Batch [5]#011Speed: 188.71 samples/sec#011loss=1.162084\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:18 INFO 139662618720064] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3845.1359272003174, \"sum\": 3845.1359272003174, \"min\": 3845.1359272003174}}, \"EndTime\": 1601797338.404141, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797334.558485}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:18 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=166.438632869 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:18 INFO 139662618720064] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:18 INFO 139662618720064] #quality_metric: host=algo-1, epoch=92, train loss <loss>=1.1700330317\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:18 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:19 INFO 139662618720064] Epoch[93] Batch[0] avg_epoch_loss=0.989538\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:19 INFO 139662618720064] #quality_metric: host=algo-1, epoch=93, batch=0 train loss <loss>=0.989537715912\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:20 INFO 139662618720064] Epoch[93] Batch[5] avg_epoch_loss=1.179701\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:20 INFO 139662618720064] #quality_metric: host=algo-1, epoch=93, batch=5 train loss <loss>=1.17970079184\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:20 INFO 139662618720064] Epoch[93] Batch [5]#011Speed: 187.24 samples/sec#011loss=1.179701\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:22 INFO 139662618720064] Epoch[93] Batch[10] avg_epoch_loss=1.116063\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:22 INFO 139662618720064] #quality_metric: host=algo-1, epoch=93, batch=10 train loss <loss>=1.03969669938\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:22 INFO 139662618720064] Epoch[93] Batch [10]#011Speed: 189.01 samples/sec#011loss=1.039697\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:22 INFO 139662618720064] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4226.1059284210205, \"sum\": 4226.1059284210205, \"min\": 4226.1059284210205}}, \"EndTime\": 1601797342.630852, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797338.404226}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:22 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=154.983000645 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:22 INFO 139662618720064] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:22 INFO 139662618720064] #quality_metric: host=algo-1, epoch=93, train loss <loss>=1.11606256799\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:22 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:22 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_ca2aed1d-2ce0-4e07-a354-f68db5fa4c82-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 110.0318431854248, \"sum\": 110.0318431854248, \"min\": 110.0318431854248}}, \"EndTime\": 1601797342.741473, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797342.630936}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:23 INFO 139662618720064] Epoch[94] Batch[0] avg_epoch_loss=1.199014\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:23 INFO 139662618720064] #quality_metric: host=algo-1, epoch=94, batch=0 train loss <loss>=1.19901442528\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:25 INFO 139662618720064] Epoch[94] Batch[5] avg_epoch_loss=1.267304\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:25 INFO 139662618720064] #quality_metric: host=algo-1, epoch=94, batch=5 train loss <loss>=1.2673044006\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:25 INFO 139662618720064] Epoch[94] Batch [5]#011Speed: 186.30 samples/sec#011loss=1.267304\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:26 INFO 139662618720064] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3872.838020324707, \"sum\": 3872.838020324707, \"min\": 3872.838020324707}}, \"EndTime\": 1601797346.61444, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797342.741548}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:26 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=162.667368781 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:26 INFO 139662618720064] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:26 INFO 139662618720064] #quality_metric: host=algo-1, epoch=94, train loss <loss>=1.22880960703\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:26 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:27 INFO 139662618720064] Epoch[95] Batch[0] avg_epoch_loss=1.193488\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:27 INFO 139662618720064] #quality_metric: host=algo-1, epoch=95, batch=0 train loss <loss>=1.19348824024\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:29 INFO 139662618720064] Epoch[95] Batch[5] avg_epoch_loss=1.185038\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:29 INFO 139662618720064] #quality_metric: host=algo-1, epoch=95, batch=5 train loss <loss>=1.18503770232\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:29 INFO 139662618720064] Epoch[95] Batch [5]#011Speed: 188.61 samples/sec#011loss=1.185038\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:30 INFO 139662618720064] Epoch[95] Batch[10] avg_epoch_loss=1.276335\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:30 INFO 139662618720064] #quality_metric: host=algo-1, epoch=95, batch=10 train loss <loss>=1.38589129448\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:30 INFO 139662618720064] Epoch[95] Batch [10]#011Speed: 186.85 samples/sec#011loss=1.385891\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:30 INFO 139662618720064] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4216.128826141357, \"sum\": 4216.128826141357, \"min\": 4216.128826141357}}, \"EndTime\": 1601797350.831178, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797346.614505}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:30 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=152.031050074 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:30 INFO 139662618720064] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:30 INFO 139662618720064] #quality_metric: host=algo-1, epoch=95, train loss <loss>=1.27633478967\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:30 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:31 INFO 139662618720064] Epoch[96] Batch[0] avg_epoch_loss=1.198474\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:31 INFO 139662618720064] #quality_metric: host=algo-1, epoch=96, batch=0 train loss <loss>=1.19847404957\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:33 INFO 139662618720064] Epoch[96] Batch[5] avg_epoch_loss=1.179296\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:33 INFO 139662618720064] #quality_metric: host=algo-1, epoch=96, batch=5 train loss <loss>=1.17929633458\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:33 INFO 139662618720064] Epoch[96] Batch [5]#011Speed: 189.53 samples/sec#011loss=1.179296\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:34 INFO 139662618720064] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3863.394021987915, \"sum\": 3863.394021987915, \"min\": 3863.394021987915}}, \"EndTime\": 1601797354.695058, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797350.831255}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:34 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=162.028323237 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:34 INFO 139662618720064] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:34 INFO 139662618720064] #quality_metric: host=algo-1, epoch=96, train loss <loss>=1.19806805849\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:34 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:35 INFO 139662618720064] Epoch[97] Batch[0] avg_epoch_loss=1.069414\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:35 INFO 139662618720064] #quality_metric: host=algo-1, epoch=97, batch=0 train loss <loss>=1.06941413879\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:37 INFO 139662618720064] Epoch[97] Batch[5] avg_epoch_loss=1.235043\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:37 INFO 139662618720064] #quality_metric: host=algo-1, epoch=97, batch=5 train loss <loss>=1.23504306873\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:37 INFO 139662618720064] Epoch[97] Batch [5]#011Speed: 189.06 samples/sec#011loss=1.235043\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:38 INFO 139662618720064] Epoch[97] Batch[10] avg_epoch_loss=1.183046\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:38 INFO 139662618720064] #quality_metric: host=algo-1, epoch=97, batch=10 train loss <loss>=1.12064908743\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:38 INFO 139662618720064] Epoch[97] Batch [10]#011Speed: 188.96 samples/sec#011loss=1.120649\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:38 INFO 139662618720064] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4214.334011077881, \"sum\": 4214.334011077881, \"min\": 4214.334011077881}}, \"EndTime\": 1601797358.909961, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797354.695144}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:38 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=153.993853039 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:38 INFO 139662618720064] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:38 INFO 139662618720064] #quality_metric: host=algo-1, epoch=97, train loss <loss>=1.1830458045\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:38 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:39 INFO 139662618720064] Epoch[98] Batch[0] avg_epoch_loss=1.199692\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:39 INFO 139662618720064] #quality_metric: host=algo-1, epoch=98, batch=0 train loss <loss>=1.19969165325\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:41 INFO 139662618720064] Epoch[98] Batch[5] avg_epoch_loss=1.177178\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:41 INFO 139662618720064] #quality_metric: host=algo-1, epoch=98, batch=5 train loss <loss>=1.17717772722\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:41 INFO 139662618720064] Epoch[98] Batch [5]#011Speed: 181.19 samples/sec#011loss=1.177178\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:42 INFO 139662618720064] processed a total of 602 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3924.5450496673584, \"sum\": 3924.5450496673584, \"min\": 3924.5450496673584}}, \"EndTime\": 1601797362.835033, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797358.910041}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:42 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=153.388581477 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:42 INFO 139662618720064] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:42 INFO 139662618720064] #quality_metric: host=algo-1, epoch=98, train loss <loss>=1.23706559539\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:42 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:43 INFO 139662618720064] Epoch[99] Batch[0] avg_epoch_loss=1.193114\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:43 INFO 139662618720064] #quality_metric: host=algo-1, epoch=99, batch=0 train loss <loss>=1.19311356544\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:45 INFO 139662618720064] Epoch[99] Batch[5] avg_epoch_loss=1.169206\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:45 INFO 139662618720064] #quality_metric: host=algo-1, epoch=99, batch=5 train loss <loss>=1.16920624177\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:45 INFO 139662618720064] Epoch[99] Batch [5]#011Speed: 181.69 samples/sec#011loss=1.169206\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:47 INFO 139662618720064] Epoch[99] Batch[10] avg_epoch_loss=1.150115\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:47 INFO 139662618720064] #quality_metric: host=algo-1, epoch=99, batch=10 train loss <loss>=1.12720561028\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:47 INFO 139662618720064] Epoch[99] Batch [10]#011Speed: 188.39 samples/sec#011loss=1.127206\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:47 INFO 139662618720064] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4273.316860198975, \"sum\": 4273.316860198975, \"min\": 4273.316860198975}}, \"EndTime\": 1601797367.108903, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797362.835119}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:47 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=155.144510688 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:47 INFO 139662618720064] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:47 INFO 139662618720064] #quality_metric: host=algo-1, epoch=99, train loss <loss>=1.15011504563\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:47 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:47 INFO 139662618720064] Epoch[100] Batch[0] avg_epoch_loss=1.165595\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:47 INFO 139662618720064] #quality_metric: host=algo-1, epoch=100, batch=0 train loss <loss>=1.16559481621\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:49 INFO 139662618720064] Epoch[100] Batch[5] avg_epoch_loss=1.151414\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:49 INFO 139662618720064] #quality_metric: host=algo-1, epoch=100, batch=5 train loss <loss>=1.15141423543\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:49 INFO 139662618720064] Epoch[100] Batch [5]#011Speed: 190.24 samples/sec#011loss=1.151414\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:50 INFO 139662618720064] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3844.1450595855713, \"sum\": 3844.1450595855713, \"min\": 3844.1450595855713}}, \"EndTime\": 1601797370.953569, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797367.108982}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:50 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=161.539122243 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:50 INFO 139662618720064] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:50 INFO 139662618720064] #quality_metric: host=algo-1, epoch=100, train loss <loss>=1.16612838507\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:50 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:51 INFO 139662618720064] Epoch[101] Batch[0] avg_epoch_loss=1.173817\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:51 INFO 139662618720064] #quality_metric: host=algo-1, epoch=101, batch=0 train loss <loss>=1.17381691933\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:53 INFO 139662618720064] Epoch[101] Batch[5] avg_epoch_loss=1.164127\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:53 INFO 139662618720064] #quality_metric: host=algo-1, epoch=101, batch=5 train loss <loss>=1.16412748893\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:53 INFO 139662618720064] Epoch[101] Batch [5]#011Speed: 190.40 samples/sec#011loss=1.164127\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:54 INFO 139662618720064] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3822.5531578063965, \"sum\": 3822.5531578063965, \"min\": 3822.5531578063965}}, \"EndTime\": 1601797374.776679, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797370.953654}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:54 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=165.329294113 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:54 INFO 139662618720064] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:54 INFO 139662618720064] #quality_metric: host=algo-1, epoch=101, train loss <loss>=1.14659645557\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:54 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:55 INFO 139662618720064] Epoch[102] Batch[0] avg_epoch_loss=1.219099\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:55 INFO 139662618720064] #quality_metric: host=algo-1, epoch=102, batch=0 train loss <loss>=1.21909940243\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:57 INFO 139662618720064] Epoch[102] Batch[5] avg_epoch_loss=1.210971\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:57 INFO 139662618720064] #quality_metric: host=algo-1, epoch=102, batch=5 train loss <loss>=1.2109713157\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:57 INFO 139662618720064] Epoch[102] Batch [5]#011Speed: 188.38 samples/sec#011loss=1.210971\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:58 INFO 139662618720064] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3932.898998260498, \"sum\": 3932.898998260498, \"min\": 3932.898998260498}}, \"EndTime\": 1601797378.710169, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797374.77676}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:58 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=160.436300424 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:58 INFO 139662618720064] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:58 INFO 139662618720064] #quality_metric: host=algo-1, epoch=102, train loss <loss>=1.20959174633\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:58 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:59 INFO 139662618720064] Epoch[103] Batch[0] avg_epoch_loss=0.926149\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:42:59 INFO 139662618720064] #quality_metric: host=algo-1, epoch=103, batch=0 train loss <loss>=0.926148891449\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:01 INFO 139662618720064] Epoch[103] Batch[5] avg_epoch_loss=1.143199\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:01 INFO 139662618720064] #quality_metric: host=algo-1, epoch=103, batch=5 train loss <loss>=1.14319934448\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:01 INFO 139662618720064] Epoch[103] Batch [5]#011Speed: 186.72 samples/sec#011loss=1.143199\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:02 INFO 139662618720064] processed a total of 619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3910.623073577881, \"sum\": 3910.623073577881, \"min\": 3910.623073577881}}, \"EndTime\": 1601797382.62137, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797378.710255}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:02 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=158.281701678 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:02 INFO 139662618720064] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:02 INFO 139662618720064] #quality_metric: host=algo-1, epoch=103, train loss <loss>=1.10160194039\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:02 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:02 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_f7e13658-521a-45dd-a741-8d2be493b6b9-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 121.75107002258301, \"sum\": 121.75107002258301, \"min\": 121.75107002258301}}, \"EndTime\": 1601797382.743769, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797382.621456}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:03 INFO 139662618720064] Epoch[104] Batch[0] avg_epoch_loss=1.104660\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:03 INFO 139662618720064] #quality_metric: host=algo-1, epoch=104, batch=0 train loss <loss>=1.10465991497\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:05 INFO 139662618720064] Epoch[104] Batch[5] avg_epoch_loss=1.129347\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:05 INFO 139662618720064] #quality_metric: host=algo-1, epoch=104, batch=5 train loss <loss>=1.12934736411\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:05 INFO 139662618720064] Epoch[104] Batch [5]#011Speed: 188.99 samples/sec#011loss=1.129347\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:06 INFO 139662618720064] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3851.9599437713623, \"sum\": 3851.9599437713623, \"min\": 3851.9599437713623}}, \"EndTime\": 1601797386.595852, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797382.743827}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:06 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=161.211361222 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:06 INFO 139662618720064] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:06 INFO 139662618720064] #quality_metric: host=algo-1, epoch=104, train loss <loss>=1.13892017603\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:06 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:07 INFO 139662618720064] Epoch[105] Batch[0] avg_epoch_loss=1.085676\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:07 INFO 139662618720064] #quality_metric: host=algo-1, epoch=105, batch=0 train loss <loss>=1.08567631245\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:09 INFO 139662618720064] Epoch[105] Batch[5] avg_epoch_loss=1.100266\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:09 INFO 139662618720064] #quality_metric: host=algo-1, epoch=105, batch=5 train loss <loss>=1.10026572148\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:09 INFO 139662618720064] Epoch[105] Batch [5]#011Speed: 190.40 samples/sec#011loss=1.100266\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:10 INFO 139662618720064] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3872.7688789367676, \"sum\": 3872.7688789367676, \"min\": 3872.7688789367676}}, \"EndTime\": 1601797390.469185, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797386.595937}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:10 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=162.669011067 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:10 INFO 139662618720064] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:10 INFO 139662618720064] #quality_metric: host=algo-1, epoch=105, train loss <loss>=1.08914159536\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:10 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:10 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_b175795e-663b-43d3-afa2-b0cd0896bba9-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 144.97113227844238, \"sum\": 144.97113227844238, \"min\": 144.97113227844238}}, \"EndTime\": 1601797390.61486, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797390.46927}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:11 INFO 139662618720064] Epoch[106] Batch[0] avg_epoch_loss=1.290733\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:11 INFO 139662618720064] #quality_metric: host=algo-1, epoch=106, batch=0 train loss <loss>=1.29073297977\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:13 INFO 139662618720064] Epoch[106] Batch[5] avg_epoch_loss=1.158555\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:13 INFO 139662618720064] #quality_metric: host=algo-1, epoch=106, batch=5 train loss <loss>=1.15855515997\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:13 INFO 139662618720064] Epoch[106] Batch [5]#011Speed: 189.76 samples/sec#011loss=1.158555\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:14 INFO 139662618720064] processed a total of 607 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3845.828056335449, \"sum\": 3845.828056335449, \"min\": 3845.828056335449}}, \"EndTime\": 1601797394.460839, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797390.614942}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:14 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=157.828193376 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:14 INFO 139662618720064] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:14 INFO 139662618720064] #quality_metric: host=algo-1, epoch=106, train loss <loss>=1.16142415404\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:14 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:15 INFO 139662618720064] Epoch[107] Batch[0] avg_epoch_loss=1.143217\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:15 INFO 139662618720064] #quality_metric: host=algo-1, epoch=107, batch=0 train loss <loss>=1.14321660995\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:16 INFO 139662618720064] Epoch[107] Batch[5] avg_epoch_loss=1.231263\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:16 INFO 139662618720064] #quality_metric: host=algo-1, epoch=107, batch=5 train loss <loss>=1.23126274347\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:16 INFO 139662618720064] Epoch[107] Batch [5]#011Speed: 188.04 samples/sec#011loss=1.231263\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:18 INFO 139662618720064] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3875.0360012054443, \"sum\": 3875.0360012054443, \"min\": 3875.0360012054443}}, \"EndTime\": 1601797398.336466, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797394.460924}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:18 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=161.282661794 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:18 INFO 139662618720064] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:18 INFO 139662618720064] #quality_metric: host=algo-1, epoch=107, train loss <loss>=1.22967157364\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:18 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:19 INFO 139662618720064] Epoch[108] Batch[0] avg_epoch_loss=1.121077\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:19 INFO 139662618720064] #quality_metric: host=algo-1, epoch=108, batch=0 train loss <loss>=1.12107717991\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:20 INFO 139662618720064] Epoch[108] Batch[5] avg_epoch_loss=1.169637\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:20 INFO 139662618720064] #quality_metric: host=algo-1, epoch=108, batch=5 train loss <loss>=1.16963678598\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:20 INFO 139662618720064] Epoch[108] Batch [5]#011Speed: 187.00 samples/sec#011loss=1.169637\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:22 INFO 139662618720064] processed a total of 612 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3867.686986923218, \"sum\": 3867.686986923218, \"min\": 3867.686986923218}}, \"EndTime\": 1601797402.20474, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797398.336552}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:22 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=158.228909112 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:22 INFO 139662618720064] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:22 INFO 139662618720064] #quality_metric: host=algo-1, epoch=108, train loss <loss>=1.17637454271\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:22 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:23 INFO 139662618720064] Epoch[109] Batch[0] avg_epoch_loss=1.065532\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:23 INFO 139662618720064] #quality_metric: host=algo-1, epoch=109, batch=0 train loss <loss>=1.06553161144\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:24 INFO 139662618720064] Epoch[109] Batch[5] avg_epoch_loss=1.075173\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:24 INFO 139662618720064] #quality_metric: host=algo-1, epoch=109, batch=5 train loss <loss>=1.0751726826\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:24 INFO 139662618720064] Epoch[109] Batch [5]#011Speed: 187.59 samples/sec#011loss=1.075173\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:26 INFO 139662618720064] processed a total of 609 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3916.4209365844727, \"sum\": 3916.4209365844727, \"min\": 3916.4209365844727}}, \"EndTime\": 1601797406.121728, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797402.204827}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:26 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=155.494110161 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:26 INFO 139662618720064] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:26 INFO 139662618720064] #quality_metric: host=algo-1, epoch=109, train loss <loss>=1.12332649231\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:26 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:26 INFO 139662618720064] Epoch[110] Batch[0] avg_epoch_loss=1.063282\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:26 INFO 139662618720064] #quality_metric: host=algo-1, epoch=110, batch=0 train loss <loss>=1.06328248978\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:28 INFO 139662618720064] Epoch[110] Batch[5] avg_epoch_loss=1.096721\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:28 INFO 139662618720064] #quality_metric: host=algo-1, epoch=110, batch=5 train loss <loss>=1.09672073523\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:28 INFO 139662618720064] Epoch[110] Batch [5]#011Speed: 188.14 samples/sec#011loss=1.096721\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:30 INFO 139662618720064] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3889.1971111297607, \"sum\": 3889.1971111297607, \"min\": 3889.1971111297607}}, \"EndTime\": 1601797410.011555, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797406.121813}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:30 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=164.038067369 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:30 INFO 139662618720064] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:30 INFO 139662618720064] #quality_metric: host=algo-1, epoch=110, train loss <loss>=1.10800817013\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:30 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:30 INFO 139662618720064] Epoch[111] Batch[0] avg_epoch_loss=1.252607\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:30 INFO 139662618720064] #quality_metric: host=algo-1, epoch=111, batch=0 train loss <loss>=1.25260722637\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:32 INFO 139662618720064] Epoch[111] Batch[5] avg_epoch_loss=1.141086\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:32 INFO 139662618720064] #quality_metric: host=algo-1, epoch=111, batch=5 train loss <loss>=1.1410860618\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:32 INFO 139662618720064] Epoch[111] Batch [5]#011Speed: 189.21 samples/sec#011loss=1.141086\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:34 INFO 139662618720064] Epoch[111] Batch[10] avg_epoch_loss=1.088349\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:34 INFO 139662618720064] #quality_metric: host=algo-1, epoch=111, batch=10 train loss <loss>=1.0250649333\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:34 INFO 139662618720064] Epoch[111] Batch [10]#011Speed: 186.80 samples/sec#011loss=1.025065\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:34 INFO 139662618720064] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4269.851922988892, \"sum\": 4269.851922988892, \"min\": 4269.851922988892}}, \"EndTime\": 1601797414.282006, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797410.011659}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:34 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=154.567617091 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:34 INFO 139662618720064] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:34 INFO 139662618720064] #quality_metric: host=algo-1, epoch=111, train loss <loss>=1.08834918521\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:34 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:34 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_cf13cae5-3212-4786-bc73-e16ab4d3ec0d-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 102.56290435791016, \"sum\": 102.56290435791016, \"min\": 102.56290435791016}}, \"EndTime\": 1601797414.38519, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797414.282088}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:35 INFO 139662618720064] Epoch[112] Batch[0] avg_epoch_loss=1.222033\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:35 INFO 139662618720064] #quality_metric: host=algo-1, epoch=112, batch=0 train loss <loss>=1.222032547\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:36 INFO 139662618720064] Epoch[112] Batch[5] avg_epoch_loss=1.184576\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:36 INFO 139662618720064] #quality_metric: host=algo-1, epoch=112, batch=5 train loss <loss>=1.18457572659\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:36 INFO 139662618720064] Epoch[112] Batch [5]#011Speed: 186.56 samples/sec#011loss=1.184576\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:38 INFO 139662618720064] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3849.964141845703, \"sum\": 3849.964141845703, \"min\": 3849.964141845703}}, \"EndTime\": 1601797418.235279, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797414.385254}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:38 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=166.229920356 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:38 INFO 139662618720064] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:38 INFO 139662618720064] #quality_metric: host=algo-1, epoch=112, train loss <loss>=1.18390651345\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:38 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:39 INFO 139662618720064] Epoch[113] Batch[0] avg_epoch_loss=1.243746\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:39 INFO 139662618720064] #quality_metric: host=algo-1, epoch=113, batch=0 train loss <loss>=1.24374604225\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:40 INFO 139662618720064] Epoch[113] Batch[5] avg_epoch_loss=1.210814\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:40 INFO 139662618720064] #quality_metric: host=algo-1, epoch=113, batch=5 train loss <loss>=1.21081384023\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:40 INFO 139662618720064] Epoch[113] Batch [5]#011Speed: 186.89 samples/sec#011loss=1.210814\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:42 INFO 139662618720064] Epoch[113] Batch[10] avg_epoch_loss=1.118798\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:42 INFO 139662618720064] #quality_metric: host=algo-1, epoch=113, batch=10 train loss <loss>=1.00837824345\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:42 INFO 139662618720064] Epoch[113] Batch [10]#011Speed: 183.86 samples/sec#011loss=1.008378\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:42 INFO 139662618720064] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4244.011163711548, \"sum\": 4244.011163711548, \"min\": 4244.011163711548}}, \"EndTime\": 1601797422.479889, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797418.235363}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:42 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=153.152814376 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:42 INFO 139662618720064] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:42 INFO 139662618720064] #quality_metric: host=algo-1, epoch=113, train loss <loss>=1.11879765987\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:42 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:43 INFO 139662618720064] Epoch[114] Batch[0] avg_epoch_loss=1.040867\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:43 INFO 139662618720064] #quality_metric: host=algo-1, epoch=114, batch=0 train loss <loss>=1.04086685181\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:44 INFO 139662618720064] Epoch[114] Batch[5] avg_epoch_loss=1.057428\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:44 INFO 139662618720064] #quality_metric: host=algo-1, epoch=114, batch=5 train loss <loss>=1.05742794275\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:44 INFO 139662618720064] Epoch[114] Batch [5]#011Speed: 189.65 samples/sec#011loss=1.057428\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:46 INFO 139662618720064] Epoch[114] Batch[10] avg_epoch_loss=1.037848\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:46 INFO 139662618720064] #quality_metric: host=algo-1, epoch=114, batch=10 train loss <loss>=1.01435192823\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:46 INFO 139662618720064] Epoch[114] Batch [10]#011Speed: 187.41 samples/sec#011loss=1.014352\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:47 INFO 139662618720064] processed a total of 707 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4570.15585899353, \"sum\": 4570.15585899353, \"min\": 4570.15585899353}}, \"EndTime\": 1601797427.050539, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797422.479967}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:47 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=154.694985487 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:47 INFO 139662618720064] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:47 INFO 139662618720064] #quality_metric: host=algo-1, epoch=114, train loss <loss>=1.08667715887\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:47 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:47 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_ea448404-7c0d-48ea-a17f-303e8978b9f4-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 112.23411560058594, \"sum\": 112.23411560058594, \"min\": 112.23411560058594}}, \"EndTime\": 1601797427.163421, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797427.050625}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:47 INFO 139662618720064] Epoch[115] Batch[0] avg_epoch_loss=1.329261\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:47 INFO 139662618720064] #quality_metric: host=algo-1, epoch=115, batch=0 train loss <loss>=1.32926142216\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:49 INFO 139662618720064] Epoch[115] Batch[5] avg_epoch_loss=1.164107\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:49 INFO 139662618720064] #quality_metric: host=algo-1, epoch=115, batch=5 train loss <loss>=1.16410716375\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:49 INFO 139662618720064] Epoch[115] Batch [5]#011Speed: 188.61 samples/sec#011loss=1.164107\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:51 INFO 139662618720064] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3861.7019653320312, \"sum\": 3861.7019653320312, \"min\": 3861.7019653320312}}, \"EndTime\": 1601797431.025251, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797427.163494}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:51 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=161.323816588 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:51 INFO 139662618720064] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:51 INFO 139662618720064] #quality_metric: host=algo-1, epoch=115, train loss <loss>=1.16812964678\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:51 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:51 INFO 139662618720064] Epoch[116] Batch[0] avg_epoch_loss=1.208672\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:51 INFO 139662618720064] #quality_metric: host=algo-1, epoch=116, batch=0 train loss <loss>=1.20867228508\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:53 INFO 139662618720064] Epoch[116] Batch[5] avg_epoch_loss=1.060368\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:53 INFO 139662618720064] #quality_metric: host=algo-1, epoch=116, batch=5 train loss <loss>=1.06036846836\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:53 INFO 139662618720064] Epoch[116] Batch [5]#011Speed: 187.88 samples/sec#011loss=1.060368\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:54 INFO 139662618720064] processed a total of 579 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3824.8291015625, \"sum\": 3824.8291015625, \"min\": 3824.8291015625}}, \"EndTime\": 1601797434.850604, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797431.025313}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:54 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=151.374377603 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:54 INFO 139662618720064] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:54 INFO 139662618720064] #quality_metric: host=algo-1, epoch=116, train loss <loss>=1.17638958097\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:54 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:55 INFO 139662618720064] Epoch[117] Batch[0] avg_epoch_loss=1.129232\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:55 INFO 139662618720064] #quality_metric: host=algo-1, epoch=117, batch=0 train loss <loss>=1.12923240662\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:57 INFO 139662618720064] Epoch[117] Batch[5] avg_epoch_loss=1.163393\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:57 INFO 139662618720064] #quality_metric: host=algo-1, epoch=117, batch=5 train loss <loss>=1.16339279215\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:57 INFO 139662618720064] Epoch[117] Batch [5]#011Speed: 186.93 samples/sec#011loss=1.163393\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:58 INFO 139662618720064] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3883.3889961242676, \"sum\": 3883.3889961242676, \"min\": 3883.3889961242676}}, \"EndTime\": 1601797438.734588, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797434.850688}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:58 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=164.541663817 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:58 INFO 139662618720064] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:58 INFO 139662618720064] #quality_metric: host=algo-1, epoch=117, train loss <loss>=1.14900110364\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:58 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:59 INFO 139662618720064] Epoch[118] Batch[0] avg_epoch_loss=0.971170\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:43:59 INFO 139662618720064] #quality_metric: host=algo-1, epoch=118, batch=0 train loss <loss>=0.971169948578\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:01 INFO 139662618720064] Epoch[118] Batch[5] avg_epoch_loss=1.117888\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:01 INFO 139662618720064] #quality_metric: host=algo-1, epoch=118, batch=5 train loss <loss>=1.11788831155\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:01 INFO 139662618720064] Epoch[118] Batch [5]#011Speed: 183.99 samples/sec#011loss=1.117888\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:03 INFO 139662618720064] Epoch[118] Batch[10] avg_epoch_loss=1.089216\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:03 INFO 139662618720064] #quality_metric: host=algo-1, epoch=118, batch=10 train loss <loss>=1.05480940342\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:03 INFO 139662618720064] Epoch[118] Batch [10]#011Speed: 185.32 samples/sec#011loss=1.054809\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:03 INFO 139662618720064] processed a total of 681 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4289.350986480713, \"sum\": 4289.350986480713, \"min\": 4289.350986480713}}, \"EndTime\": 1601797443.024537, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797438.734674}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:03 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=158.760874134 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:03 INFO 139662618720064] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:03 INFO 139662618720064] #quality_metric: host=algo-1, epoch=118, train loss <loss>=1.08921608058\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:03 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:03 INFO 139662618720064] Epoch[119] Batch[0] avg_epoch_loss=1.230889\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:03 INFO 139662618720064] #quality_metric: host=algo-1, epoch=119, batch=0 train loss <loss>=1.23088920116\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:05 INFO 139662618720064] Epoch[119] Batch[5] avg_epoch_loss=1.277012\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:05 INFO 139662618720064] #quality_metric: host=algo-1, epoch=119, batch=5 train loss <loss>=1.27701175213\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:05 INFO 139662618720064] Epoch[119] Batch [5]#011Speed: 189.64 samples/sec#011loss=1.277012\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:06 INFO 139662618720064] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3874.330997467041, \"sum\": 3874.330997467041, \"min\": 3874.330997467041}}, \"EndTime\": 1601797446.89939, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797443.024616}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:06 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=164.926422968 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:06 INFO 139662618720064] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:06 INFO 139662618720064] #quality_metric: host=algo-1, epoch=119, train loss <loss>=1.25276598334\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:06 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:07 INFO 139662618720064] Epoch[120] Batch[0] avg_epoch_loss=1.177560\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:07 INFO 139662618720064] #quality_metric: host=algo-1, epoch=120, batch=0 train loss <loss>=1.17755973339\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:09 INFO 139662618720064] Epoch[120] Batch[5] avg_epoch_loss=1.173811\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:09 INFO 139662618720064] #quality_metric: host=algo-1, epoch=120, batch=5 train loss <loss>=1.17381060123\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:09 INFO 139662618720064] Epoch[120] Batch [5]#011Speed: 186.86 samples/sec#011loss=1.173811\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:10 INFO 139662618720064] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3918.2229042053223, \"sum\": 3918.2229042053223, \"min\": 3918.2229042053223}}, \"EndTime\": 1601797450.81818, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797446.899474}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:10 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=158.995496311 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:10 INFO 139662618720064] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:10 INFO 139662618720064] #quality_metric: host=algo-1, epoch=120, train loss <loss>=1.13714505434\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:10 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:11 INFO 139662618720064] Epoch[121] Batch[0] avg_epoch_loss=1.072407\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:11 INFO 139662618720064] #quality_metric: host=algo-1, epoch=121, batch=0 train loss <loss>=1.07240736485\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:13 INFO 139662618720064] Epoch[121] Batch[5] avg_epoch_loss=1.072482\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:13 INFO 139662618720064] #quality_metric: host=algo-1, epoch=121, batch=5 train loss <loss>=1.07248229782\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:13 INFO 139662618720064] Epoch[121] Batch [5]#011Speed: 190.08 samples/sec#011loss=1.072482\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:15 INFO 139662618720064] Epoch[121] Batch[10] avg_epoch_loss=1.134601\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:15 INFO 139662618720064] #quality_metric: host=algo-1, epoch=121, batch=10 train loss <loss>=1.20914336443\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:15 INFO 139662618720064] Epoch[121] Batch [10]#011Speed: 190.19 samples/sec#011loss=1.209143\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:15 INFO 139662618720064] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4212.5749588012695, \"sum\": 4212.5749588012695, \"min\": 4212.5749588012695}}, \"EndTime\": 1601797455.031361, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797450.818267}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:15 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=156.669522656 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:15 INFO 139662618720064] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:15 INFO 139662618720064] #quality_metric: host=algo-1, epoch=121, train loss <loss>=1.13460096446\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:15 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:15 INFO 139662618720064] Epoch[122] Batch[0] avg_epoch_loss=1.184309\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:15 INFO 139662618720064] #quality_metric: host=algo-1, epoch=122, batch=0 train loss <loss>=1.18430876732\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:17 INFO 139662618720064] Epoch[122] Batch[5] avg_epoch_loss=1.118861\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:17 INFO 139662618720064] #quality_metric: host=algo-1, epoch=122, batch=5 train loss <loss>=1.11886123816\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:17 INFO 139662618720064] Epoch[122] Batch [5]#011Speed: 180.99 samples/sec#011loss=1.118861\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:19 INFO 139662618720064] processed a total of 619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4014.4970417022705, \"sum\": 4014.4970417022705, \"min\": 4014.4970417022705}}, \"EndTime\": 1601797459.046338, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797455.031436}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:19 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=154.186409381 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:19 INFO 139662618720064] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:19 INFO 139662618720064] #quality_metric: host=algo-1, epoch=122, train loss <loss>=1.09828511477\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:19 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:19 INFO 139662618720064] Epoch[123] Batch[0] avg_epoch_loss=1.199810\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:19 INFO 139662618720064] #quality_metric: host=algo-1, epoch=123, batch=0 train loss <loss>=1.19981026649\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:21 INFO 139662618720064] Epoch[123] Batch[5] avg_epoch_loss=1.148852\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:21 INFO 139662618720064] #quality_metric: host=algo-1, epoch=123, batch=5 train loss <loss>=1.14885166287\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:21 INFO 139662618720064] Epoch[123] Batch [5]#011Speed: 186.82 samples/sec#011loss=1.148852\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:22 INFO 139662618720064] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3895.4241275787354, \"sum\": 3895.4241275787354, \"min\": 3895.4241275787354}}, \"EndTime\": 1601797462.942383, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797459.046423}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:22 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=162.749893385 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:22 INFO 139662618720064] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:22 INFO 139662618720064] #quality_metric: host=algo-1, epoch=123, train loss <loss>=1.12053464055\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:22 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:23 INFO 139662618720064] Epoch[124] Batch[0] avg_epoch_loss=1.054592\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:23 INFO 139662618720064] #quality_metric: host=algo-1, epoch=124, batch=0 train loss <loss>=1.05459177494\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:25 INFO 139662618720064] Epoch[124] Batch[5] avg_epoch_loss=1.073169\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:25 INFO 139662618720064] #quality_metric: host=algo-1, epoch=124, batch=5 train loss <loss>=1.0731694897\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:25 INFO 139662618720064] Epoch[124] Batch [5]#011Speed: 186.23 samples/sec#011loss=1.073169\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:26 INFO 139662618720064] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3918.9159870147705, \"sum\": 3918.9159870147705, \"min\": 3918.9159870147705}}, \"EndTime\": 1601797466.861913, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797462.942467}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:26 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=158.967987227 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:26 INFO 139662618720064] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:26 INFO 139662618720064] #quality_metric: host=algo-1, epoch=124, train loss <loss>=1.09624840021\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:26 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:27 INFO 139662618720064] Epoch[125] Batch[0] avg_epoch_loss=1.203848\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:27 INFO 139662618720064] #quality_metric: host=algo-1, epoch=125, batch=0 train loss <loss>=1.20384848118\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:29 INFO 139662618720064] Epoch[125] Batch[5] avg_epoch_loss=1.120466\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:29 INFO 139662618720064] #quality_metric: host=algo-1, epoch=125, batch=5 train loss <loss>=1.12046637138\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:29 INFO 139662618720064] Epoch[125] Batch [5]#011Speed: 188.92 samples/sec#011loss=1.120466\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:30 INFO 139662618720064] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3842.381000518799, \"sum\": 3842.381000518799, \"min\": 3842.381000518799}}, \"EndTime\": 1601797470.704825, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797466.861993}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:30 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=162.395162481 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:30 INFO 139662618720064] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:30 INFO 139662618720064] #quality_metric: host=algo-1, epoch=125, train loss <loss>=1.14986195564\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:30 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:31 INFO 139662618720064] Epoch[126] Batch[0] avg_epoch_loss=1.004787\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:31 INFO 139662618720064] #quality_metric: host=algo-1, epoch=126, batch=0 train loss <loss>=1.00478696823\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:33 INFO 139662618720064] Epoch[126] Batch[5] avg_epoch_loss=1.129846\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:33 INFO 139662618720064] #quality_metric: host=algo-1, epoch=126, batch=5 train loss <loss>=1.1298464934\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:33 INFO 139662618720064] Epoch[126] Batch [5]#011Speed: 189.23 samples/sec#011loss=1.129846\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:34 INFO 139662618720064] processed a total of 613 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3861.2759113311768, \"sum\": 3861.2759113311768, \"min\": 3861.2759113311768}}, \"EndTime\": 1601797474.566665, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797470.70489}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:34 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=158.750550108 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:34 INFO 139662618720064] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:34 INFO 139662618720064] #quality_metric: host=algo-1, epoch=126, train loss <loss>=1.06693181992\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:34 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:34 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_f5ddf122-1e44-465a-b2a1-cab8dabbfdb4-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 130.28192520141602, \"sum\": 130.28192520141602, \"min\": 130.28192520141602}}, \"EndTime\": 1601797474.697598, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797474.566751}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:35 INFO 139662618720064] Epoch[127] Batch[0] avg_epoch_loss=0.996999\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:35 INFO 139662618720064] #quality_metric: host=algo-1, epoch=127, batch=0 train loss <loss>=0.996998548508\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:37 INFO 139662618720064] Epoch[127] Batch[5] avg_epoch_loss=1.095337\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:37 INFO 139662618720064] #quality_metric: host=algo-1, epoch=127, batch=5 train loss <loss>=1.09533691406\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:37 INFO 139662618720064] Epoch[127] Batch [5]#011Speed: 183.88 samples/sec#011loss=1.095337\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:38 INFO 139662618720064] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3883.4309577941895, \"sum\": 3883.4309577941895, \"min\": 3883.4309577941895}}, \"EndTime\": 1601797478.581177, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797474.697675}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:38 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=159.647375468 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:38 INFO 139662618720064] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:38 INFO 139662618720064] #quality_metric: host=algo-1, epoch=127, train loss <loss>=1.06292014718\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:38 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:38 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_19a92690-2075-46a0-b96c-a5f7346bee85-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 131.03795051574707, \"sum\": 131.03795051574707, \"min\": 131.03795051574707}}, \"EndTime\": 1601797478.712972, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797478.581264}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:39 INFO 139662618720064] Epoch[128] Batch[0] avg_epoch_loss=1.143050\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:39 INFO 139662618720064] #quality_metric: host=algo-1, epoch=128, batch=0 train loss <loss>=1.143050313\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:41 INFO 139662618720064] Epoch[128] Batch[5] avg_epoch_loss=1.194095\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:41 INFO 139662618720064] #quality_metric: host=algo-1, epoch=128, batch=5 train loss <loss>=1.19409491618\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:41 INFO 139662618720064] Epoch[128] Batch [5]#011Speed: 188.62 samples/sec#011loss=1.194095\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:42 INFO 139662618720064] Epoch[128] Batch[10] avg_epoch_loss=1.124719\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:42 INFO 139662618720064] #quality_metric: host=algo-1, epoch=128, batch=10 train loss <loss>=1.04146723747\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:42 INFO 139662618720064] Epoch[128] Batch [10]#011Speed: 186.69 samples/sec#011loss=1.041467\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:42 INFO 139662618720064] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4211.25602722168, \"sum\": 4211.25602722168, \"min\": 4211.25602722168}}, \"EndTime\": 1601797482.924381, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797478.713053}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:42 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=156.243471857 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:42 INFO 139662618720064] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:42 INFO 139662618720064] #quality_metric: host=algo-1, epoch=128, train loss <loss>=1.12471869859\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:42 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:43 INFO 139662618720064] Epoch[129] Batch[0] avg_epoch_loss=1.045104\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:43 INFO 139662618720064] #quality_metric: host=algo-1, epoch=129, batch=0 train loss <loss>=1.04510438442\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:45 INFO 139662618720064] Epoch[129] Batch[5] avg_epoch_loss=1.103750\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:45 INFO 139662618720064] #quality_metric: host=algo-1, epoch=129, batch=5 train loss <loss>=1.10375041763\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:45 INFO 139662618720064] Epoch[129] Batch [5]#011Speed: 187.68 samples/sec#011loss=1.103750\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:47 INFO 139662618720064] Epoch[129] Batch[10] avg_epoch_loss=1.150257\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:47 INFO 139662618720064] #quality_metric: host=algo-1, epoch=129, batch=10 train loss <loss>=1.20606541634\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:47 INFO 139662618720064] Epoch[129] Batch [10]#011Speed: 187.61 samples/sec#011loss=1.206065\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:47 INFO 139662618720064] processed a total of 677 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4226.257085800171, \"sum\": 4226.257085800171, \"min\": 4226.257085800171}}, \"EndTime\": 1601797487.151155, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797482.92446}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:47 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=160.184479128 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:47 INFO 139662618720064] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:47 INFO 139662618720064] #quality_metric: host=algo-1, epoch=129, train loss <loss>=1.15025723522\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:47 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:47 INFO 139662618720064] Epoch[130] Batch[0] avg_epoch_loss=1.131717\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:47 INFO 139662618720064] #quality_metric: host=algo-1, epoch=130, batch=0 train loss <loss>=1.13171720505\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:49 INFO 139662618720064] Epoch[130] Batch[5] avg_epoch_loss=1.134347\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:49 INFO 139662618720064] #quality_metric: host=algo-1, epoch=130, batch=5 train loss <loss>=1.13434698184\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:49 INFO 139662618720064] Epoch[130] Batch [5]#011Speed: 190.02 samples/sec#011loss=1.134347\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:50 INFO 139662618720064] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3839.266061782837, \"sum\": 3839.266061782837, \"min\": 3839.266061782837}}, \"EndTime\": 1601797490.99096, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797487.151234}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:50 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=164.609265884 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:50 INFO 139662618720064] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:50 INFO 139662618720064] #quality_metric: host=algo-1, epoch=130, train loss <loss>=1.09370006919\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:50 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:51 INFO 139662618720064] Epoch[131] Batch[0] avg_epoch_loss=1.259523\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:51 INFO 139662618720064] #quality_metric: host=algo-1, epoch=131, batch=0 train loss <loss>=1.25952267647\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:53 INFO 139662618720064] Epoch[131] Batch[5] avg_epoch_loss=1.105701\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:53 INFO 139662618720064] #quality_metric: host=algo-1, epoch=131, batch=5 train loss <loss>=1.10570126772\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:53 INFO 139662618720064] Epoch[131] Batch [5]#011Speed: 189.45 samples/sec#011loss=1.105701\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:54 INFO 139662618720064] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3887.450933456421, \"sum\": 3887.450933456421, \"min\": 3887.450933456421}}, \"EndTime\": 1601797494.878989, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797490.991047}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:54 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=160.511287846 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:54 INFO 139662618720064] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:54 INFO 139662618720064] #quality_metric: host=algo-1, epoch=131, train loss <loss>=1.10627806187\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:54 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:55 INFO 139662618720064] Epoch[132] Batch[0] avg_epoch_loss=1.398719\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:55 INFO 139662618720064] #quality_metric: host=algo-1, epoch=132, batch=0 train loss <loss>=1.39871907234\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:57 INFO 139662618720064] Epoch[132] Batch[5] avg_epoch_loss=1.105912\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:57 INFO 139662618720064] #quality_metric: host=algo-1, epoch=132, batch=5 train loss <loss>=1.10591201981\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:57 INFO 139662618720064] Epoch[132] Batch [5]#011Speed: 182.92 samples/sec#011loss=1.105912\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:59 INFO 139662618720064] Epoch[132] Batch[10] avg_epoch_loss=1.119305\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:59 INFO 139662618720064] #quality_metric: host=algo-1, epoch=132, batch=10 train loss <loss>=1.13537750244\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:59 INFO 139662618720064] Epoch[132] Batch [10]#011Speed: 189.35 samples/sec#011loss=1.135378\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:59 INFO 139662618720064] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4240.308046340942, \"sum\": 4240.308046340942, \"min\": 4240.308046340942}}, \"EndTime\": 1601797499.119936, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797494.879074}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:59 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=151.635671924 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:59 INFO 139662618720064] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:59 INFO 139662618720064] #quality_metric: host=algo-1, epoch=132, train loss <loss>=1.11930542101\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:59 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:59 INFO 139662618720064] Epoch[133] Batch[0] avg_epoch_loss=0.976421\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:44:59 INFO 139662618720064] #quality_metric: host=algo-1, epoch=133, batch=0 train loss <loss>=0.976420581341\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:01 INFO 139662618720064] Epoch[133] Batch[5] avg_epoch_loss=1.100421\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:01 INFO 139662618720064] #quality_metric: host=algo-1, epoch=133, batch=5 train loss <loss>=1.10042149822\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:01 INFO 139662618720064] Epoch[133] Batch [5]#011Speed: 187.71 samples/sec#011loss=1.100421\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:03 INFO 139662618720064] Epoch[133] Batch[10] avg_epoch_loss=1.051971\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:03 INFO 139662618720064] #quality_metric: host=algo-1, epoch=133, batch=10 train loss <loss>=0.993830323219\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:03 INFO 139662618720064] Epoch[133] Batch [10]#011Speed: 185.82 samples/sec#011loss=0.993830\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:03 INFO 139662618720064] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4279.602766036987, \"sum\": 4279.602766036987, \"min\": 4279.602766036987}}, \"EndTime\": 1601797503.400046, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797499.120015}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:03 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=151.645364755 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:03 INFO 139662618720064] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:03 INFO 139662618720064] #quality_metric: host=algo-1, epoch=133, train loss <loss>=1.05197096413\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:03 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:03 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_6f83662a-be7e-4d93-8700-14fcc9ab8993-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 112.152099609375, \"sum\": 112.152099609375, \"min\": 112.152099609375}}, \"EndTime\": 1601797503.512763, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797503.400125}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:04 INFO 139662618720064] Epoch[134] Batch[0] avg_epoch_loss=1.263130\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:04 INFO 139662618720064] #quality_metric: host=algo-1, epoch=134, batch=0 train loss <loss>=1.26312994957\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:06 INFO 139662618720064] Epoch[134] Batch[5] avg_epoch_loss=1.119320\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:06 INFO 139662618720064] #quality_metric: host=algo-1, epoch=134, batch=5 train loss <loss>=1.1193202734\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:06 INFO 139662618720064] Epoch[134] Batch [5]#011Speed: 189.23 samples/sec#011loss=1.119320\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:07 INFO 139662618720064] Epoch[134] Batch[10] avg_epoch_loss=1.054030\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:07 INFO 139662618720064] #quality_metric: host=algo-1, epoch=134, batch=10 train loss <loss>=0.975681424141\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:07 INFO 139662618720064] Epoch[134] Batch [10]#011Speed: 189.68 samples/sec#011loss=0.975681\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:07 INFO 139662618720064] processed a total of 669 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4186.316013336182, \"sum\": 4186.316013336182, \"min\": 4186.316013336182}}, \"EndTime\": 1601797507.699221, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797503.512835}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:07 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=159.801836771 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:07 INFO 139662618720064] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:07 INFO 139662618720064] #quality_metric: host=algo-1, epoch=134, train loss <loss>=1.05402988737\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:07 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:08 INFO 139662618720064] Epoch[135] Batch[0] avg_epoch_loss=1.068151\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:08 INFO 139662618720064] #quality_metric: host=algo-1, epoch=135, batch=0 train loss <loss>=1.06815135479\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:10 INFO 139662618720064] Epoch[135] Batch[5] avg_epoch_loss=1.066829\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:10 INFO 139662618720064] #quality_metric: host=algo-1, epoch=135, batch=5 train loss <loss>=1.06682852904\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:10 INFO 139662618720064] Epoch[135] Batch [5]#011Speed: 189.96 samples/sec#011loss=1.066829\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:11 INFO 139662618720064] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3869.5449829101562, \"sum\": 3869.5449829101562, \"min\": 3869.5449829101562}}, \"EndTime\": 1601797511.569303, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797507.699301}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:11 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=160.995475395 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:11 INFO 139662618720064] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:11 INFO 139662618720064] #quality_metric: host=algo-1, epoch=135, train loss <loss>=1.06535903215\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:11 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:12 INFO 139662618720064] Epoch[136] Batch[0] avg_epoch_loss=1.056202\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:12 INFO 139662618720064] #quality_metric: host=algo-1, epoch=136, batch=0 train loss <loss>=1.05620193481\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:14 INFO 139662618720064] Epoch[136] Batch[5] avg_epoch_loss=1.142311\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:14 INFO 139662618720064] #quality_metric: host=algo-1, epoch=136, batch=5 train loss <loss>=1.14231057962\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:14 INFO 139662618720064] Epoch[136] Batch [5]#011Speed: 189.93 samples/sec#011loss=1.142311\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:15 INFO 139662618720064] Epoch[136] Batch[10] avg_epoch_loss=1.088626\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:15 INFO 139662618720064] #quality_metric: host=algo-1, epoch=136, batch=10 train loss <loss>=1.02420376539\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:15 INFO 139662618720064] Epoch[136] Batch [10]#011Speed: 186.85 samples/sec#011loss=1.024204\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:15 INFO 139662618720064] processed a total of 675 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4233.091831207275, \"sum\": 4233.091831207275, \"min\": 4233.091831207275}}, \"EndTime\": 1601797515.803012, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797511.569391}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:15 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=159.453389277 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:15 INFO 139662618720064] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:15 INFO 139662618720064] #quality_metric: host=algo-1, epoch=136, train loss <loss>=1.08862566406\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:15 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:16 INFO 139662618720064] Epoch[137] Batch[0] avg_epoch_loss=0.948414\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:16 INFO 139662618720064] #quality_metric: host=algo-1, epoch=137, batch=0 train loss <loss>=0.948414385319\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:18 INFO 139662618720064] Epoch[137] Batch[5] avg_epoch_loss=1.066382\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:18 INFO 139662618720064] #quality_metric: host=algo-1, epoch=137, batch=5 train loss <loss>=1.06638174256\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:18 INFO 139662618720064] Epoch[137] Batch [5]#011Speed: 189.04 samples/sec#011loss=1.066382\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:20 INFO 139662618720064] Epoch[137] Batch[10] avg_epoch_loss=1.002716\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:20 INFO 139662618720064] #quality_metric: host=algo-1, epoch=137, batch=10 train loss <loss>=0.926316595078\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:20 INFO 139662618720064] Epoch[137] Batch [10]#011Speed: 188.88 samples/sec#011loss=0.926317\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:20 INFO 139662618720064] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4202.798128128052, \"sum\": 4202.798128128052, \"min\": 4202.798128128052}}, \"EndTime\": 1601797520.006329, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797515.803092}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:20 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=154.892604394 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:20 INFO 139662618720064] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:20 INFO 139662618720064] #quality_metric: host=algo-1, epoch=137, train loss <loss>=1.00271576643\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:20 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:20 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_4ca4b9dd-baca-43e7-8425-810452802f46-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 108.78801345825195, \"sum\": 108.78801345825195, \"min\": 108.78801345825195}}, \"EndTime\": 1601797520.115691, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797520.006405}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:20 INFO 139662618720064] Epoch[138] Batch[0] avg_epoch_loss=1.491230\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:20 INFO 139662618720064] #quality_metric: host=algo-1, epoch=138, batch=0 train loss <loss>=1.49122977257\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:22 INFO 139662618720064] Epoch[138] Batch[5] avg_epoch_loss=1.335340\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:22 INFO 139662618720064] #quality_metric: host=algo-1, epoch=138, batch=5 train loss <loss>=1.33534026146\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:22 INFO 139662618720064] Epoch[138] Batch [5]#011Speed: 188.31 samples/sec#011loss=1.335340\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:23 INFO 139662618720064] processed a total of 603 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3874.4430541992188, \"sum\": 3874.4430541992188, \"min\": 3874.4430541992188}}, \"EndTime\": 1601797523.99029, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797520.115771}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:23 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=155.630129574 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:23 INFO 139662618720064] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:23 INFO 139662618720064] #quality_metric: host=algo-1, epoch=138, train loss <loss>=1.3365734458\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:23 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:24 INFO 139662618720064] Epoch[139] Batch[0] avg_epoch_loss=1.329301\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:24 INFO 139662618720064] #quality_metric: host=algo-1, epoch=139, batch=0 train loss <loss>=1.32930135727\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:26 INFO 139662618720064] Epoch[139] Batch[5] avg_epoch_loss=1.279820\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:26 INFO 139662618720064] #quality_metric: host=algo-1, epoch=139, batch=5 train loss <loss>=1.27982026339\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:26 INFO 139662618720064] Epoch[139] Batch [5]#011Speed: 187.04 samples/sec#011loss=1.279820\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:27 INFO 139662618720064] processed a total of 580 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3900.7389545440674, \"sum\": 3900.7389545440674, \"min\": 3900.7389545440674}}, \"EndTime\": 1601797527.891638, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797523.990374}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:27 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=148.684895482 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:27 INFO 139662618720064] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:27 INFO 139662618720064] #quality_metric: host=algo-1, epoch=139, train loss <loss>=1.31862411499\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:27 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:28 INFO 139662618720064] Epoch[140] Batch[0] avg_epoch_loss=1.251262\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:28 INFO 139662618720064] #quality_metric: host=algo-1, epoch=140, batch=0 train loss <loss>=1.25126206875\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:30 INFO 139662618720064] Epoch[140] Batch[5] avg_epoch_loss=1.233937\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:30 INFO 139662618720064] #quality_metric: host=algo-1, epoch=140, batch=5 train loss <loss>=1.23393678665\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:30 INFO 139662618720064] Epoch[140] Batch [5]#011Speed: 186.93 samples/sec#011loss=1.233937\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:32 INFO 139662618720064] Epoch[140] Batch[10] avg_epoch_loss=1.241079\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:32 INFO 139662618720064] #quality_metric: host=algo-1, epoch=140, batch=10 train loss <loss>=1.24965000153\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:32 INFO 139662618720064] Epoch[140] Batch [10]#011Speed: 187.06 samples/sec#011loss=1.249650\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:32 INFO 139662618720064] processed a total of 683 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4222.273111343384, \"sum\": 4222.273111343384, \"min\": 4222.273111343384}}, \"EndTime\": 1601797532.114524, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797527.891724}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:32 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=161.756504287 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:32 INFO 139662618720064] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:32 INFO 139662618720064] #quality_metric: host=algo-1, epoch=140, train loss <loss>=1.24107915705\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:32 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:32 INFO 139662618720064] Epoch[141] Batch[0] avg_epoch_loss=1.123071\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:32 INFO 139662618720064] #quality_metric: host=algo-1, epoch=141, batch=0 train loss <loss>=1.12307143211\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:34 INFO 139662618720064] Epoch[141] Batch[5] avg_epoch_loss=1.127392\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:34 INFO 139662618720064] #quality_metric: host=algo-1, epoch=141, batch=5 train loss <loss>=1.12739227215\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:34 INFO 139662618720064] Epoch[141] Batch [5]#011Speed: 187.40 samples/sec#011loss=1.127392\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:35 INFO 139662618720064] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3881.7059993743896, \"sum\": 3881.7059993743896, \"min\": 3881.7059993743896}}, \"EndTime\": 1601797535.99685, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797532.114608}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:35 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=163.582470314 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:35 INFO 139662618720064] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:35 INFO 139662618720064] #quality_metric: host=algo-1, epoch=141, train loss <loss>=1.14427326918\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:35 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:36 INFO 139662618720064] Epoch[142] Batch[0] avg_epoch_loss=0.986340\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:36 INFO 139662618720064] #quality_metric: host=algo-1, epoch=142, batch=0 train loss <loss>=0.986339569092\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:38 INFO 139662618720064] Epoch[142] Batch[5] avg_epoch_loss=1.083416\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:38 INFO 139662618720064] #quality_metric: host=algo-1, epoch=142, batch=5 train loss <loss>=1.08341577649\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:38 INFO 139662618720064] Epoch[142] Batch [5]#011Speed: 187.93 samples/sec#011loss=1.083416\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:40 INFO 139662618720064] Epoch[142] Batch[10] avg_epoch_loss=1.117460\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:40 INFO 139662618720064] #quality_metric: host=algo-1, epoch=142, batch=10 train loss <loss>=1.15831212997\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:40 INFO 139662618720064] Epoch[142] Batch [10]#011Speed: 187.87 samples/sec#011loss=1.158312\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:40 INFO 139662618720064] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4214.570045471191, \"sum\": 4214.570045471191, \"min\": 4214.570045471191}}, \"EndTime\": 1601797540.212049, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797535.996935}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:40 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=156.120652662 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:40 INFO 139662618720064] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:40 INFO 139662618720064] #quality_metric: host=algo-1, epoch=142, train loss <loss>=1.11745957353\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:40 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:41 INFO 139662618720064] Epoch[143] Batch[0] avg_epoch_loss=1.231838\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:41 INFO 139662618720064] #quality_metric: host=algo-1, epoch=143, batch=0 train loss <loss>=1.2318379879\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:42 INFO 139662618720064] Epoch[143] Batch[5] avg_epoch_loss=1.056748\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:42 INFO 139662618720064] #quality_metric: host=algo-1, epoch=143, batch=5 train loss <loss>=1.05674784382\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:42 INFO 139662618720064] Epoch[143] Batch [5]#011Speed: 187.47 samples/sec#011loss=1.056748\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:44 INFO 139662618720064] Epoch[143] Batch[10] avg_epoch_loss=1.028784\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:44 INFO 139662618720064] #quality_metric: host=algo-1, epoch=143, batch=10 train loss <loss>=0.995227348804\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:44 INFO 139662618720064] Epoch[143] Batch [10]#011Speed: 189.85 samples/sec#011loss=0.995227\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:44 INFO 139662618720064] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4197.783946990967, \"sum\": 4197.783946990967, \"min\": 4197.783946990967}}, \"EndTime\": 1601797544.410374, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797540.212129}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:44 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=155.077501439 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:44 INFO 139662618720064] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:44 INFO 139662618720064] #quality_metric: host=algo-1, epoch=143, train loss <loss>=1.02878398245\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:44 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:45 INFO 139662618720064] Epoch[144] Batch[0] avg_epoch_loss=1.126537\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:45 INFO 139662618720064] #quality_metric: host=algo-1, epoch=144, batch=0 train loss <loss>=1.12653660774\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:46 INFO 139662618720064] Epoch[144] Batch[5] avg_epoch_loss=1.098030\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:46 INFO 139662618720064] #quality_metric: host=algo-1, epoch=144, batch=5 train loss <loss>=1.09803014\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:46 INFO 139662618720064] Epoch[144] Batch [5]#011Speed: 187.49 samples/sec#011loss=1.098030\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:48 INFO 139662618720064] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3890.2058601379395, \"sum\": 3890.2058601379395, \"min\": 3890.2058601379395}}, \"EndTime\": 1601797548.301154, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797544.410454}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:48 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=163.739068809 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:48 INFO 139662618720064] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:48 INFO 139662618720064] #quality_metric: host=algo-1, epoch=144, train loss <loss>=1.13655117154\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:48 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:49 INFO 139662618720064] Epoch[145] Batch[0] avg_epoch_loss=1.001614\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:49 INFO 139662618720064] #quality_metric: host=algo-1, epoch=145, batch=0 train loss <loss>=1.00161385536\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:50 INFO 139662618720064] Epoch[145] Batch[5] avg_epoch_loss=1.154275\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:50 INFO 139662618720064] #quality_metric: host=algo-1, epoch=145, batch=5 train loss <loss>=1.15427460273\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:50 INFO 139662618720064] Epoch[145] Batch [5]#011Speed: 188.45 samples/sec#011loss=1.154275\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:52 INFO 139662618720064] Epoch[145] Batch[10] avg_epoch_loss=1.135415\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:52 INFO 139662618720064] #quality_metric: host=algo-1, epoch=145, batch=10 train loss <loss>=1.1127833128\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:52 INFO 139662618720064] Epoch[145] Batch [10]#011Speed: 189.79 samples/sec#011loss=1.112783\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:52 INFO 139662618720064] processed a total of 688 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4179.803848266602, \"sum\": 4179.803848266602, \"min\": 4179.803848266602}}, \"EndTime\": 1601797552.481534, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797548.301242}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:52 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=164.596528363 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:52 INFO 139662618720064] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:52 INFO 139662618720064] #quality_metric: host=algo-1, epoch=145, train loss <loss>=1.13541492549\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:52 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:53 INFO 139662618720064] Epoch[146] Batch[0] avg_epoch_loss=0.984641\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:53 INFO 139662618720064] #quality_metric: host=algo-1, epoch=146, batch=0 train loss <loss>=0.984640836716\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:55 INFO 139662618720064] Epoch[146] Batch[5] avg_epoch_loss=1.021247\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:55 INFO 139662618720064] #quality_metric: host=algo-1, epoch=146, batch=5 train loss <loss>=1.02124657234\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:55 INFO 139662618720064] Epoch[146] Batch [5]#011Speed: 187.89 samples/sec#011loss=1.021247\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:56 INFO 139662618720064] Epoch[146] Batch[10] avg_epoch_loss=1.001211\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:56 INFO 139662618720064] #quality_metric: host=algo-1, epoch=146, batch=10 train loss <loss>=0.977168166637\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:56 INFO 139662618720064] Epoch[146] Batch [10]#011Speed: 185.09 samples/sec#011loss=0.977168\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:56 INFO 139662618720064] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4271.310806274414, \"sum\": 4271.310806274414, \"min\": 4271.310806274414}}, \"EndTime\": 1601797556.753331, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797552.481611}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:56 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=154.983441461 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:56 INFO 139662618720064] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:56 INFO 139662618720064] #quality_metric: host=algo-1, epoch=146, train loss <loss>=1.00121093338\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:56 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:56 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_e851c6f1-78fe-4245-8955-4803fc4692c7-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 111.42492294311523, \"sum\": 111.42492294311523, \"min\": 111.42492294311523}}, \"EndTime\": 1601797556.865304, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797556.753408}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:57 INFO 139662618720064] Epoch[147] Batch[0] avg_epoch_loss=0.974870\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:57 INFO 139662618720064] #quality_metric: host=algo-1, epoch=147, batch=0 train loss <loss>=0.974870324135\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:59 INFO 139662618720064] Epoch[147] Batch[5] avg_epoch_loss=1.020448\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:59 INFO 139662618720064] #quality_metric: host=algo-1, epoch=147, batch=5 train loss <loss>=1.02044803898\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:45:59 INFO 139662618720064] Epoch[147] Batch [5]#011Speed: 187.62 samples/sec#011loss=1.020448\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:00 INFO 139662618720064] processed a total of 611 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3851.8450260162354, \"sum\": 3851.8450260162354, \"min\": 3851.8450260162354}}, \"EndTime\": 1601797560.717296, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797556.865384}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:00 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=158.621245811 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:00 INFO 139662618720064] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:00 INFO 139662618720064] #quality_metric: host=algo-1, epoch=147, train loss <loss>=1.02772843242\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:00 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:01 INFO 139662618720064] Epoch[148] Batch[0] avg_epoch_loss=0.966908\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:01 INFO 139662618720064] #quality_metric: host=algo-1, epoch=148, batch=0 train loss <loss>=0.966907680035\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:03 INFO 139662618720064] Epoch[148] Batch[5] avg_epoch_loss=1.063182\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:03 INFO 139662618720064] #quality_metric: host=algo-1, epoch=148, batch=5 train loss <loss>=1.06318168839\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:03 INFO 139662618720064] Epoch[148] Batch [5]#011Speed: 182.02 samples/sec#011loss=1.063182\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:04 INFO 139662618720064] Epoch[148] Batch[10] avg_epoch_loss=1.115447\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:04 INFO 139662618720064] #quality_metric: host=algo-1, epoch=148, batch=10 train loss <loss>=1.17816456556\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:04 INFO 139662618720064] Epoch[148] Batch [10]#011Speed: 189.52 samples/sec#011loss=1.178165\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:04 INFO 139662618720064] processed a total of 672 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4241.614818572998, \"sum\": 4241.614818572998, \"min\": 4241.614818572998}}, \"EndTime\": 1601797564.959433, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797560.717358}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:04 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=158.42569469 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:04 INFO 139662618720064] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:04 INFO 139662618720064] #quality_metric: host=algo-1, epoch=148, train loss <loss>=1.11544663256\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:04 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:05 INFO 139662618720064] Epoch[149] Batch[0] avg_epoch_loss=1.028898\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:05 INFO 139662618720064] #quality_metric: host=algo-1, epoch=149, batch=0 train loss <loss>=1.02889788151\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:07 INFO 139662618720064] Epoch[149] Batch[5] avg_epoch_loss=1.119598\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:07 INFO 139662618720064] #quality_metric: host=algo-1, epoch=149, batch=5 train loss <loss>=1.11959769328\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:07 INFO 139662618720064] Epoch[149] Batch [5]#011Speed: 188.40 samples/sec#011loss=1.119598\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:09 INFO 139662618720064] Epoch[149] Batch[10] avg_epoch_loss=1.210024\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:09 INFO 139662618720064] #quality_metric: host=algo-1, epoch=149, batch=10 train loss <loss>=1.31853507757\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:09 INFO 139662618720064] Epoch[149] Batch [10]#011Speed: 188.54 samples/sec#011loss=1.318535\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:09 INFO 139662618720064] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4202.1660804748535, \"sum\": 4202.1660804748535, \"min\": 4202.1660804748535}}, \"EndTime\": 1601797569.162137, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797564.959514}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:09 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=157.295338587 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:09 INFO 139662618720064] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:09 INFO 139662618720064] #quality_metric: host=algo-1, epoch=149, train loss <loss>=1.21002377705\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:09 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:09 INFO 139662618720064] Epoch[150] Batch[0] avg_epoch_loss=1.029328\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:09 INFO 139662618720064] #quality_metric: host=algo-1, epoch=150, batch=0 train loss <loss>=1.02932822704\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:11 INFO 139662618720064] Epoch[150] Batch[5] avg_epoch_loss=1.070267\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:11 INFO 139662618720064] #quality_metric: host=algo-1, epoch=150, batch=5 train loss <loss>=1.07026729981\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:11 INFO 139662618720064] Epoch[150] Batch [5]#011Speed: 187.63 samples/sec#011loss=1.070267\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:13 INFO 139662618720064] processed a total of 615 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3928.3430576324463, \"sum\": 3928.3430576324463, \"min\": 3928.3430576324463}}, \"EndTime\": 1601797573.091029, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797569.162219}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:13 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=156.549376988 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:13 INFO 139662618720064] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:13 INFO 139662618720064] #quality_metric: host=algo-1, epoch=150, train loss <loss>=1.07357442975\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:13 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:13 INFO 139662618720064] Epoch[151] Batch[0] avg_epoch_loss=1.057556\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:13 INFO 139662618720064] #quality_metric: host=algo-1, epoch=151, batch=0 train loss <loss>=1.05755591393\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:15 INFO 139662618720064] Epoch[151] Batch[5] avg_epoch_loss=1.079714\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:15 INFO 139662618720064] #quality_metric: host=algo-1, epoch=151, batch=5 train loss <loss>=1.07971362273\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:15 INFO 139662618720064] Epoch[151] Batch [5]#011Speed: 187.44 samples/sec#011loss=1.079714\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:17 INFO 139662618720064] Epoch[151] Batch[10] avg_epoch_loss=1.071122\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:17 INFO 139662618720064] #quality_metric: host=algo-1, epoch=151, batch=10 train loss <loss>=1.0608112812\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:17 INFO 139662618720064] Epoch[151] Batch [10]#011Speed: 185.86 samples/sec#011loss=1.060811\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:17 INFO 139662618720064] processed a total of 680 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4228.261947631836, \"sum\": 4228.261947631836, \"min\": 4228.261947631836}}, \"EndTime\": 1601797577.319869, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797573.091116}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:17 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=160.818554885 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:17 INFO 139662618720064] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:17 INFO 139662618720064] #quality_metric: host=algo-1, epoch=151, train loss <loss>=1.07112164931\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:17 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:18 INFO 139662618720064] Epoch[152] Batch[0] avg_epoch_loss=1.175914\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:18 INFO 139662618720064] #quality_metric: host=algo-1, epoch=152, batch=0 train loss <loss>=1.17591440678\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:19 INFO 139662618720064] Epoch[152] Batch[5] avg_epoch_loss=1.067505\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:19 INFO 139662618720064] #quality_metric: host=algo-1, epoch=152, batch=5 train loss <loss>=1.06750471393\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:19 INFO 139662618720064] Epoch[152] Batch [5]#011Speed: 187.71 samples/sec#011loss=1.067505\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:21 INFO 139662618720064] Epoch[152] Batch[10] avg_epoch_loss=1.028832\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:21 INFO 139662618720064] #quality_metric: host=algo-1, epoch=152, batch=10 train loss <loss>=0.98242367506\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:21 INFO 139662618720064] Epoch[152] Batch [10]#011Speed: 185.73 samples/sec#011loss=0.982424\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:21 INFO 139662618720064] processed a total of 685 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4227.155923843384, \"sum\": 4227.155923843384, \"min\": 4227.155923843384}}, \"EndTime\": 1601797581.547548, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797577.319937}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:21 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=162.04303734 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:21 INFO 139662618720064] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:21 INFO 139662618720064] #quality_metric: host=algo-1, epoch=152, train loss <loss>=1.02883151445\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:21 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:22 INFO 139662618720064] Epoch[153] Batch[0] avg_epoch_loss=1.177288\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:22 INFO 139662618720064] #quality_metric: host=algo-1, epoch=153, batch=0 train loss <loss>=1.17728793621\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:24 INFO 139662618720064] Epoch[153] Batch[5] avg_epoch_loss=1.160405\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:24 INFO 139662618720064] #quality_metric: host=algo-1, epoch=153, batch=5 train loss <loss>=1.16040509939\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:24 INFO 139662618720064] Epoch[153] Batch [5]#011Speed: 188.93 samples/sec#011loss=1.160405\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:25 INFO 139662618720064] Epoch[153] Batch[10] avg_epoch_loss=1.018425\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:25 INFO 139662618720064] #quality_metric: host=algo-1, epoch=153, batch=10 train loss <loss>=0.848048859835\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:25 INFO 139662618720064] Epoch[153] Batch [10]#011Speed: 187.44 samples/sec#011loss=0.848049\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:25 INFO 139662618720064] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4191.740989685059, \"sum\": 4191.740989685059, \"min\": 4191.740989685059}}, \"EndTime\": 1601797585.739818, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797581.547621}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:25 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=154.346495855 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:25 INFO 139662618720064] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:25 INFO 139662618720064] #quality_metric: host=algo-1, epoch=153, train loss <loss>=1.0184249905\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:25 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:26 INFO 139662618720064] Epoch[154] Batch[0] avg_epoch_loss=1.054497\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:26 INFO 139662618720064] #quality_metric: host=algo-1, epoch=154, batch=0 train loss <loss>=1.05449724197\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:28 INFO 139662618720064] Epoch[154] Batch[5] avg_epoch_loss=1.035015\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:28 INFO 139662618720064] #quality_metric: host=algo-1, epoch=154, batch=5 train loss <loss>=1.03501508633\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:28 INFO 139662618720064] Epoch[154] Batch [5]#011Speed: 189.07 samples/sec#011loss=1.035015\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:29 INFO 139662618720064] Epoch[154] Batch[10] avg_epoch_loss=1.063975\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:29 INFO 139662618720064] #quality_metric: host=algo-1, epoch=154, batch=10 train loss <loss>=1.09872641563\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:29 INFO 139662618720064] Epoch[154] Batch [10]#011Speed: 189.49 samples/sec#011loss=1.098726\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:29 INFO 139662618720064] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4171.460151672363, \"sum\": 4171.460151672363, \"min\": 4171.460151672363}}, \"EndTime\": 1601797589.911832, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797585.739901}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:29 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=156.056020534 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:29 INFO 139662618720064] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:29 INFO 139662618720064] #quality_metric: host=algo-1, epoch=154, train loss <loss>=1.06397478147\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:29 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:30 INFO 139662618720064] Epoch[155] Batch[0] avg_epoch_loss=1.050815\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:30 INFO 139662618720064] #quality_metric: host=algo-1, epoch=155, batch=0 train loss <loss>=1.0508146286\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:32 INFO 139662618720064] Epoch[155] Batch[5] avg_epoch_loss=1.045344\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:32 INFO 139662618720064] #quality_metric: host=algo-1, epoch=155, batch=5 train loss <loss>=1.04534438252\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:32 INFO 139662618720064] Epoch[155] Batch [5]#011Speed: 186.64 samples/sec#011loss=1.045344\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:34 INFO 139662618720064] Epoch[155] Batch[10] avg_epoch_loss=1.118348\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:34 INFO 139662618720064] #quality_metric: host=algo-1, epoch=155, batch=10 train loss <loss>=1.20595240593\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:34 INFO 139662618720064] Epoch[155] Batch [10]#011Speed: 188.32 samples/sec#011loss=1.205952\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:34 INFO 139662618720064] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4230.669021606445, \"sum\": 4230.669021606445, \"min\": 4230.669021606445}}, \"EndTime\": 1601797594.143048, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797589.911911}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:34 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=156.944908914 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:34 INFO 139662618720064] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:34 INFO 139662618720064] #quality_metric: host=algo-1, epoch=155, train loss <loss>=1.11834802953\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:34 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:34 INFO 139662618720064] Epoch[156] Batch[0] avg_epoch_loss=1.143412\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:34 INFO 139662618720064] #quality_metric: host=algo-1, epoch=156, batch=0 train loss <loss>=1.14341175556\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:36 INFO 139662618720064] Epoch[156] Batch[5] avg_epoch_loss=0.997229\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:36 INFO 139662618720064] #quality_metric: host=algo-1, epoch=156, batch=5 train loss <loss>=0.997228682041\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:36 INFO 139662618720064] Epoch[156] Batch [5]#011Speed: 184.61 samples/sec#011loss=0.997229\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:38 INFO 139662618720064] processed a total of 619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3882.1089267730713, \"sum\": 3882.1089267730713, \"min\": 3882.1089267730713}}, \"EndTime\": 1601797598.025693, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797594.143125}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:38 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=159.444402063 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:38 INFO 139662618720064] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:38 INFO 139662618720064] #quality_metric: host=algo-1, epoch=156, train loss <loss>=1.07464110255\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:38 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:38 INFO 139662618720064] Epoch[157] Batch[0] avg_epoch_loss=1.094444\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:38 INFO 139662618720064] #quality_metric: host=algo-1, epoch=157, batch=0 train loss <loss>=1.09444403648\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:40 INFO 139662618720064] Epoch[157] Batch[5] avg_epoch_loss=1.054270\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:40 INFO 139662618720064] #quality_metric: host=algo-1, epoch=157, batch=5 train loss <loss>=1.05426974098\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:40 INFO 139662618720064] Epoch[157] Batch [5]#011Speed: 190.24 samples/sec#011loss=1.054270\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:42 INFO 139662618720064] Epoch[157] Batch[10] avg_epoch_loss=0.996164\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:42 INFO 139662618720064] #quality_metric: host=algo-1, epoch=157, batch=10 train loss <loss>=0.926437819004\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:42 INFO 139662618720064] Epoch[157] Batch [10]#011Speed: 184.98 samples/sec#011loss=0.926438\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:42 INFO 139662618720064] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4226.21488571167, \"sum\": 4226.21488571167, \"min\": 4226.21488571167}}, \"EndTime\": 1601797602.252487, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797598.025777}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:42 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=153.561022028 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:42 INFO 139662618720064] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:42 INFO 139662618720064] #quality_metric: host=algo-1, epoch=157, train loss <loss>=0.996164321899\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:42 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:42 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_597161a6-7afc-4fd1-9f4b-a8bf16bd022e-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 110.80503463745117, \"sum\": 110.80503463745117, \"min\": 110.80503463745117}}, \"EndTime\": 1601797602.363865, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797602.252567}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:43 INFO 139662618720064] Epoch[158] Batch[0] avg_epoch_loss=1.117284\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:43 INFO 139662618720064] #quality_metric: host=algo-1, epoch=158, batch=0 train loss <loss>=1.11728358269\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:44 INFO 139662618720064] Epoch[158] Batch[5] avg_epoch_loss=1.003201\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:44 INFO 139662618720064] #quality_metric: host=algo-1, epoch=158, batch=5 train loss <loss>=1.00320064028\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:44 INFO 139662618720064] Epoch[158] Batch [5]#011Speed: 189.53 samples/sec#011loss=1.003201\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:46 INFO 139662618720064] Epoch[158] Batch[10] avg_epoch_loss=0.995330\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:46 INFO 139662618720064] #quality_metric: host=algo-1, epoch=158, batch=10 train loss <loss>=0.985885417461\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:46 INFO 139662618720064] Epoch[158] Batch [10]#011Speed: 189.33 samples/sec#011loss=0.985885\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:46 INFO 139662618720064] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4172.229051589966, \"sum\": 4172.229051589966, \"min\": 4172.229051589966}}, \"EndTime\": 1601797606.53624, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797602.363945}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:46 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=158.663576476 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:46 INFO 139662618720064] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:46 INFO 139662618720064] #quality_metric: host=algo-1, epoch=158, train loss <loss>=0.995330084454\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:46 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:46 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_541d802b-9519-4131-a3ca-4af49dfe73ee-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 116.47605895996094, \"sum\": 116.47605895996094, \"min\": 116.47605895996094}}, \"EndTime\": 1601797606.653292, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797606.536321}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:47 INFO 139662618720064] Epoch[159] Batch[0] avg_epoch_loss=1.376989\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:47 INFO 139662618720064] #quality_metric: host=algo-1, epoch=159, batch=0 train loss <loss>=1.37698948383\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:49 INFO 139662618720064] Epoch[159] Batch[5] avg_epoch_loss=1.191750\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:49 INFO 139662618720064] #quality_metric: host=algo-1, epoch=159, batch=5 train loss <loss>=1.19174975157\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:49 INFO 139662618720064] Epoch[159] Batch [5]#011Speed: 187.52 samples/sec#011loss=1.191750\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:50 INFO 139662618720064] Epoch[159] Batch[10] avg_epoch_loss=1.128674\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:50 INFO 139662618720064] #quality_metric: host=algo-1, epoch=159, batch=10 train loss <loss>=1.05298392773\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:50 INFO 139662618720064] Epoch[159] Batch [10]#011Speed: 189.47 samples/sec#011loss=1.052984\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:50 INFO 139662618720064] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4193.729877471924, \"sum\": 4193.729877471924, \"min\": 4193.729877471924}}, \"EndTime\": 1601797610.847143, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797606.653352}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:50 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=154.750477224 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:50 INFO 139662618720064] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:50 INFO 139662618720064] #quality_metric: host=algo-1, epoch=159, train loss <loss>=1.12867437709\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:50 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:51 INFO 139662618720064] Epoch[160] Batch[0] avg_epoch_loss=1.266397\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:51 INFO 139662618720064] #quality_metric: host=algo-1, epoch=160, batch=0 train loss <loss>=1.26639699936\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:53 INFO 139662618720064] Epoch[160] Batch[5] avg_epoch_loss=1.137953\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:53 INFO 139662618720064] #quality_metric: host=algo-1, epoch=160, batch=5 train loss <loss>=1.13795316219\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:53 INFO 139662618720064] Epoch[160] Batch [5]#011Speed: 186.74 samples/sec#011loss=1.137953\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:55 INFO 139662618720064] Epoch[160] Batch[10] avg_epoch_loss=1.089861\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:55 INFO 139662618720064] #quality_metric: host=algo-1, epoch=160, batch=10 train loss <loss>=1.03215078712\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:55 INFO 139662618720064] Epoch[160] Batch [10]#011Speed: 188.81 samples/sec#011loss=1.032151\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:55 INFO 139662618720064] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4214.720964431763, \"sum\": 4214.720964431763, \"min\": 4214.720964431763}}, \"EndTime\": 1601797615.06241, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797610.847222}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:55 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=154.453337871 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:55 INFO 139662618720064] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:55 INFO 139662618720064] #quality_metric: host=algo-1, epoch=160, train loss <loss>=1.08986117352\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:55 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:55 INFO 139662618720064] Epoch[161] Batch[0] avg_epoch_loss=1.164199\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:55 INFO 139662618720064] #quality_metric: host=algo-1, epoch=161, batch=0 train loss <loss>=1.16419863701\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:57 INFO 139662618720064] Epoch[161] Batch[5] avg_epoch_loss=1.162015\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:57 INFO 139662618720064] #quality_metric: host=algo-1, epoch=161, batch=5 train loss <loss>=1.16201515992\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:57 INFO 139662618720064] Epoch[161] Batch [5]#011Speed: 184.90 samples/sec#011loss=1.162015\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:58 INFO 139662618720064] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3896.415948867798, \"sum\": 3896.415948867798, \"min\": 3896.415948867798}}, \"EndTime\": 1601797618.959392, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797615.062492}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:58 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=163.991556653 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:58 INFO 139662618720064] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:58 INFO 139662618720064] #quality_metric: host=algo-1, epoch=161, train loss <loss>=1.16103565693\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:58 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:59 INFO 139662618720064] Epoch[162] Batch[0] avg_epoch_loss=1.202042\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:46:59 INFO 139662618720064] #quality_metric: host=algo-1, epoch=162, batch=0 train loss <loss>=1.20204210281\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:01 INFO 139662618720064] Epoch[162] Batch[5] avg_epoch_loss=1.114600\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:01 INFO 139662618720064] #quality_metric: host=algo-1, epoch=162, batch=5 train loss <loss>=1.1145995458\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:01 INFO 139662618720064] Epoch[162] Batch [5]#011Speed: 189.33 samples/sec#011loss=1.114600\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:03 INFO 139662618720064] Epoch[162] Batch[10] avg_epoch_loss=1.076891\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:03 INFO 139662618720064] #quality_metric: host=algo-1, epoch=162, batch=10 train loss <loss>=1.03164176941\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:03 INFO 139662618720064] Epoch[162] Batch [10]#011Speed: 184.25 samples/sec#011loss=1.031642\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:03 INFO 139662618720064] processed a total of 676 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4272.51410484314, \"sum\": 4272.51410484314, \"min\": 4272.51410484314}}, \"EndTime\": 1601797623.232485, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797618.959477}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:03 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=158.216262839 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:03 INFO 139662618720064] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:03 INFO 139662618720064] #quality_metric: host=algo-1, epoch=162, train loss <loss>=1.07689146562\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:03 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:04 INFO 139662618720064] Epoch[163] Batch[0] avg_epoch_loss=1.003315\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:04 INFO 139662618720064] #quality_metric: host=algo-1, epoch=163, batch=0 train loss <loss>=1.00331497192\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:05 INFO 139662618720064] Epoch[163] Batch[5] avg_epoch_loss=1.037535\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:05 INFO 139662618720064] #quality_metric: host=algo-1, epoch=163, batch=5 train loss <loss>=1.03753507137\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:05 INFO 139662618720064] Epoch[163] Batch [5]#011Speed: 189.32 samples/sec#011loss=1.037535\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:07 INFO 139662618720064] Epoch[163] Batch[10] avg_epoch_loss=1.018345\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:07 INFO 139662618720064] #quality_metric: host=algo-1, epoch=163, batch=10 train loss <loss>=0.995316040516\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:07 INFO 139662618720064] Epoch[163] Batch [10]#011Speed: 187.56 samples/sec#011loss=0.995316\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:07 INFO 139662618720064] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4219.408988952637, \"sum\": 4219.408988952637, \"min\": 4219.408988952637}}, \"EndTime\": 1601797627.452413, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797623.232564}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:07 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=156.41555639 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:07 INFO 139662618720064] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:07 INFO 139662618720064] #quality_metric: host=algo-1, epoch=163, train loss <loss>=1.0183446028\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:07 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:08 INFO 139662618720064] Epoch[164] Batch[0] avg_epoch_loss=1.247819\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:08 INFO 139662618720064] #quality_metric: host=algo-1, epoch=164, batch=0 train loss <loss>=1.24781918526\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:09 INFO 139662618720064] Epoch[164] Batch[5] avg_epoch_loss=1.126595\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:09 INFO 139662618720064] #quality_metric: host=algo-1, epoch=164, batch=5 train loss <loss>=1.12659502029\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:09 INFO 139662618720064] Epoch[164] Batch [5]#011Speed: 187.29 samples/sec#011loss=1.126595\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:11 INFO 139662618720064] processed a total of 617 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3861.314058303833, \"sum\": 3861.314058303833, \"min\": 3861.314058303833}}, \"EndTime\": 1601797631.314276, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797627.452494}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:11 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=159.784913575 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:11 INFO 139662618720064] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:11 INFO 139662618720064] #quality_metric: host=algo-1, epoch=164, train loss <loss>=1.07395702004\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:11 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:12 INFO 139662618720064] Epoch[165] Batch[0] avg_epoch_loss=1.125888\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:12 INFO 139662618720064] #quality_metric: host=algo-1, epoch=165, batch=0 train loss <loss>=1.12588763237\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:13 INFO 139662618720064] Epoch[165] Batch[5] avg_epoch_loss=1.081605\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:13 INFO 139662618720064] #quality_metric: host=algo-1, epoch=165, batch=5 train loss <loss>=1.08160529534\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:13 INFO 139662618720064] Epoch[165] Batch [5]#011Speed: 184.96 samples/sec#011loss=1.081605\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:15 INFO 139662618720064] Epoch[165] Batch[10] avg_epoch_loss=1.162205\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:15 INFO 139662618720064] #quality_metric: host=algo-1, epoch=165, batch=10 train loss <loss>=1.25892558098\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:15 INFO 139662618720064] Epoch[165] Batch [10]#011Speed: 187.99 samples/sec#011loss=1.258926\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:15 INFO 139662618720064] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4247.529029846191, \"sum\": 4247.529029846191, \"min\": 4247.529029846191}}, \"EndTime\": 1601797635.56245, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797631.314362}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:15 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=153.261287162 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:15 INFO 139662618720064] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:15 INFO 139662618720064] #quality_metric: host=algo-1, epoch=165, train loss <loss>=1.16220542518\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:15 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:16 INFO 139662618720064] Epoch[166] Batch[0] avg_epoch_loss=1.177847\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:16 INFO 139662618720064] #quality_metric: host=algo-1, epoch=166, batch=0 train loss <loss>=1.17784714699\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:18 INFO 139662618720064] Epoch[166] Batch[5] avg_epoch_loss=1.075455\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:18 INFO 139662618720064] #quality_metric: host=algo-1, epoch=166, batch=5 train loss <loss>=1.07545472185\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:18 INFO 139662618720064] Epoch[166] Batch [5]#011Speed: 188.13 samples/sec#011loss=1.075455\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:19 INFO 139662618720064] Epoch[166] Batch[10] avg_epoch_loss=1.053509\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:19 INFO 139662618720064] #quality_metric: host=algo-1, epoch=166, batch=10 train loss <loss>=1.02717311382\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:19 INFO 139662618720064] Epoch[166] Batch [10]#011Speed: 188.74 samples/sec#011loss=1.027173\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:19 INFO 139662618720064] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4230.195999145508, \"sum\": 4230.195999145508, \"min\": 4230.195999145508}}, \"EndTime\": 1601797639.793201, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797635.56253}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:19 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=155.543973596 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:19 INFO 139662618720064] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:19 INFO 139662618720064] #quality_metric: host=algo-1, epoch=166, train loss <loss>=1.05350853638\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:19 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:20 INFO 139662618720064] Epoch[167] Batch[0] avg_epoch_loss=1.229420\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:20 INFO 139662618720064] #quality_metric: host=algo-1, epoch=167, batch=0 train loss <loss>=1.2294203043\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:22 INFO 139662618720064] Epoch[167] Batch[5] avg_epoch_loss=1.037221\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:22 INFO 139662618720064] #quality_metric: host=algo-1, epoch=167, batch=5 train loss <loss>=1.03722080588\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:22 INFO 139662618720064] Epoch[167] Batch [5]#011Speed: 189.47 samples/sec#011loss=1.037221\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:23 INFO 139662618720064] Epoch[167] Batch[10] avg_epoch_loss=0.972823\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:23 INFO 139662618720064] #quality_metric: host=algo-1, epoch=167, batch=10 train loss <loss>=0.895545488596\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:23 INFO 139662618720064] Epoch[167] Batch [10]#011Speed: 188.80 samples/sec#011loss=0.895545\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:23 INFO 139662618720064] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4200.258016586304, \"sum\": 4200.258016586304, \"min\": 4200.258016586304}}, \"EndTime\": 1601797643.993984, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797639.793279}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:23 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=157.366782643 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:23 INFO 139662618720064] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:23 INFO 139662618720064] #quality_metric: host=algo-1, epoch=167, train loss <loss>=0.972822934389\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:23 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:24 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_b2d83235-6c6a-4d29-ac87-f29d196b4894-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 112.90287971496582, \"sum\": 112.90287971496582, \"min\": 112.90287971496582}}, \"EndTime\": 1601797644.107475, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797643.994062}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:24 INFO 139662618720064] Epoch[168] Batch[0] avg_epoch_loss=1.213303\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:24 INFO 139662618720064] #quality_metric: host=algo-1, epoch=168, batch=0 train loss <loss>=1.2133026123\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:26 INFO 139662618720064] Epoch[168] Batch[5] avg_epoch_loss=1.104403\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:26 INFO 139662618720064] #quality_metric: host=algo-1, epoch=168, batch=5 train loss <loss>=1.10440327724\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:26 INFO 139662618720064] Epoch[168] Batch [5]#011Speed: 187.50 samples/sec#011loss=1.104403\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:28 INFO 139662618720064] Epoch[168] Batch[10] avg_epoch_loss=1.131260\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:28 INFO 139662618720064] #quality_metric: host=algo-1, epoch=168, batch=10 train loss <loss>=1.16348910332\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:28 INFO 139662618720064] Epoch[168] Batch [10]#011Speed: 185.99 samples/sec#011loss=1.163489\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:28 INFO 139662618720064] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4211.580991744995, \"sum\": 4211.580991744995, \"min\": 4211.580991744995}}, \"EndTime\": 1601797648.319205, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797644.107555}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:28 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=154.094870268 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:28 INFO 139662618720064] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:28 INFO 139662618720064] #quality_metric: host=algo-1, epoch=168, train loss <loss>=1.13126047091\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:28 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:29 INFO 139662618720064] Epoch[169] Batch[0] avg_epoch_loss=1.143270\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:29 INFO 139662618720064] #quality_metric: host=algo-1, epoch=169, batch=0 train loss <loss>=1.14327001572\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:30 INFO 139662618720064] Epoch[169] Batch[5] avg_epoch_loss=1.058299\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:30 INFO 139662618720064] #quality_metric: host=algo-1, epoch=169, batch=5 train loss <loss>=1.05829916398\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:30 INFO 139662618720064] Epoch[169] Batch [5]#011Speed: 188.64 samples/sec#011loss=1.058299\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:32 INFO 139662618720064] processed a total of 592 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3843.456029891968, \"sum\": 3843.456029891968, \"min\": 3843.456029891968}}, \"EndTime\": 1601797652.163132, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797648.319275}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:32 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=154.022995504 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:32 INFO 139662618720064] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:32 INFO 139662618720064] #quality_metric: host=algo-1, epoch=169, train loss <loss>=1.0407709837\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:32 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:32 INFO 139662618720064] Epoch[170] Batch[0] avg_epoch_loss=1.065796\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:32 INFO 139662618720064] #quality_metric: host=algo-1, epoch=170, batch=0 train loss <loss>=1.06579601765\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:34 INFO 139662618720064] Epoch[170] Batch[5] avg_epoch_loss=1.015833\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:34 INFO 139662618720064] #quality_metric: host=algo-1, epoch=170, batch=5 train loss <loss>=1.01583260298\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:34 INFO 139662618720064] Epoch[170] Batch [5]#011Speed: 188.02 samples/sec#011loss=1.015833\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:36 INFO 139662618720064] Epoch[170] Batch[10] avg_epoch_loss=0.997866\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:36 INFO 139662618720064] #quality_metric: host=algo-1, epoch=170, batch=10 train loss <loss>=0.976307022572\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:36 INFO 139662618720064] Epoch[170] Batch [10]#011Speed: 187.63 samples/sec#011loss=0.976307\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:36 INFO 139662618720064] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4214.053153991699, \"sum\": 4214.053153991699, \"min\": 4214.053153991699}}, \"EndTime\": 1601797656.377789, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797652.163217}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:36 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=153.29198115 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:36 INFO 139662618720064] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:36 INFO 139662618720064] #quality_metric: host=algo-1, epoch=170, train loss <loss>=0.997866430066\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:36 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:37 INFO 139662618720064] Epoch[171] Batch[0] avg_epoch_loss=1.240120\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:37 INFO 139662618720064] #quality_metric: host=algo-1, epoch=171, batch=0 train loss <loss>=1.24011969566\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:38 INFO 139662618720064] Epoch[171] Batch[5] avg_epoch_loss=1.155302\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:38 INFO 139662618720064] #quality_metric: host=algo-1, epoch=171, batch=5 train loss <loss>=1.15530178944\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:38 INFO 139662618720064] Epoch[171] Batch [5]#011Speed: 181.74 samples/sec#011loss=1.155302\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:40 INFO 139662618720064] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3890.429973602295, \"sum\": 3890.429973602295, \"min\": 3890.429973602295}}, \"EndTime\": 1601797660.268795, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797656.377875}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:40 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=160.131271478 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:40 INFO 139662618720064] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:40 INFO 139662618720064] #quality_metric: host=algo-1, epoch=171, train loss <loss>=1.11605680585\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:40 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:41 INFO 139662618720064] Epoch[172] Batch[0] avg_epoch_loss=0.669279\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:41 INFO 139662618720064] #quality_metric: host=algo-1, epoch=172, batch=0 train loss <loss>=0.669278621674\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:42 INFO 139662618720064] Epoch[172] Batch[5] avg_epoch_loss=0.981269\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:42 INFO 139662618720064] #quality_metric: host=algo-1, epoch=172, batch=5 train loss <loss>=0.981269200643\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:42 INFO 139662618720064] Epoch[172] Batch [5]#011Speed: 184.37 samples/sec#011loss=0.981269\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:44 INFO 139662618720064] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3909.9011421203613, \"sum\": 3909.9011421203613, \"min\": 3909.9011421203613}}, \"EndTime\": 1601797664.179267, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797660.268882}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:44 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=162.658642853 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:44 INFO 139662618720064] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:44 INFO 139662618720064] #quality_metric: host=algo-1, epoch=172, train loss <loss>=0.989416027069\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:44 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:44 INFO 139662618720064] Epoch[173] Batch[0] avg_epoch_loss=0.996826\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:44 INFO 139662618720064] #quality_metric: host=algo-1, epoch=173, batch=0 train loss <loss>=0.996825993061\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:46 INFO 139662618720064] Epoch[173] Batch[5] avg_epoch_loss=0.995304\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:46 INFO 139662618720064] #quality_metric: host=algo-1, epoch=173, batch=5 train loss <loss>=0.995304485162\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:46 INFO 139662618720064] Epoch[173] Batch [5]#011Speed: 188.16 samples/sec#011loss=0.995304\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:48 INFO 139662618720064] Epoch[173] Batch[10] avg_epoch_loss=0.956712\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:48 INFO 139662618720064] #quality_metric: host=algo-1, epoch=173, batch=10 train loss <loss>=0.910401172936\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:48 INFO 139662618720064] Epoch[173] Batch [10]#011Speed: 186.24 samples/sec#011loss=0.910401\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:48 INFO 139662618720064] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4205.079793930054, \"sum\": 4205.079793930054, \"min\": 4205.079793930054}}, \"EndTime\": 1601797668.384918, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797664.179352}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:48 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=153.856755753 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:48 INFO 139662618720064] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:48 INFO 139662618720064] #quality_metric: host=algo-1, epoch=173, train loss <loss>=0.956712070514\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:48 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:48 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_fc3989dc-2ddb-4cac-8d69-88d928bf7735-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 108.78610610961914, \"sum\": 108.78610610961914, \"min\": 108.78610610961914}}, \"EndTime\": 1601797668.494359, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797668.385005}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:49 INFO 139662618720064] Epoch[174] Batch[0] avg_epoch_loss=1.147631\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:49 INFO 139662618720064] #quality_metric: host=algo-1, epoch=174, batch=0 train loss <loss>=1.14763057232\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:50 INFO 139662618720064] Epoch[174] Batch[5] avg_epoch_loss=1.086793\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:50 INFO 139662618720064] #quality_metric: host=algo-1, epoch=174, batch=5 train loss <loss>=1.08679265777\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:50 INFO 139662618720064] Epoch[174] Batch [5]#011Speed: 188.31 samples/sec#011loss=1.086793\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:52 INFO 139662618720064] processed a total of 613 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3839.2741680145264, \"sum\": 3839.2741680145264, \"min\": 3839.2741680145264}}, \"EndTime\": 1601797672.333785, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797668.494442}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:52 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=159.660410966 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:52 INFO 139662618720064] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:52 INFO 139662618720064] #quality_metric: host=algo-1, epoch=174, train loss <loss>=1.10288388729\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:52 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:53 INFO 139662618720064] Epoch[175] Batch[0] avg_epoch_loss=0.962534\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:53 INFO 139662618720064] #quality_metric: host=algo-1, epoch=175, batch=0 train loss <loss>=0.962533712387\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:54 INFO 139662618720064] Epoch[175] Batch[5] avg_epoch_loss=1.024530\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:54 INFO 139662618720064] #quality_metric: host=algo-1, epoch=175, batch=5 train loss <loss>=1.02453031143\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:54 INFO 139662618720064] Epoch[175] Batch [5]#011Speed: 185.77 samples/sec#011loss=1.024530\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:56 INFO 139662618720064] Epoch[175] Batch[10] avg_epoch_loss=1.129804\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:56 INFO 139662618720064] #quality_metric: host=algo-1, epoch=175, batch=10 train loss <loss>=1.25613200665\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:56 INFO 139662618720064] Epoch[175] Batch [10]#011Speed: 187.35 samples/sec#011loss=1.256132\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:56 INFO 139662618720064] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4251.974105834961, \"sum\": 4251.974105834961, \"min\": 4251.974105834961}}, \"EndTime\": 1601797676.586324, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797672.333869}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:56 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=154.982870082 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:56 INFO 139662618720064] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:56 INFO 139662618720064] #quality_metric: host=algo-1, epoch=175, train loss <loss>=1.12980380925\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:56 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:57 INFO 139662618720064] Epoch[176] Batch[0] avg_epoch_loss=1.040915\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:57 INFO 139662618720064] #quality_metric: host=algo-1, epoch=176, batch=0 train loss <loss>=1.04091453552\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:59 INFO 139662618720064] Epoch[176] Batch[5] avg_epoch_loss=1.067953\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:59 INFO 139662618720064] #quality_metric: host=algo-1, epoch=176, batch=5 train loss <loss>=1.06795293093\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:47:59 INFO 139662618720064] Epoch[176] Batch [5]#011Speed: 186.32 samples/sec#011loss=1.067953\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:00 INFO 139662618720064] processed a total of 616 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3856.8239212036133, \"sum\": 3856.8239212036133, \"min\": 3856.8239212036133}}, \"EndTime\": 1601797680.44369, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797676.586391}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:00 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=159.711894765 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:00 INFO 139662618720064] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:00 INFO 139662618720064] #quality_metric: host=algo-1, epoch=176, train loss <loss>=1.07748554945\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:00 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:01 INFO 139662618720064] Epoch[177] Batch[0] avg_epoch_loss=0.975372\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:01 INFO 139662618720064] #quality_metric: host=algo-1, epoch=177, batch=0 train loss <loss>=0.975372433662\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:02 INFO 139662618720064] Epoch[177] Batch[5] avg_epoch_loss=1.114359\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:02 INFO 139662618720064] #quality_metric: host=algo-1, epoch=177, batch=5 train loss <loss>=1.11435939868\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:02 INFO 139662618720064] Epoch[177] Batch [5]#011Speed: 188.02 samples/sec#011loss=1.114359\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:04 INFO 139662618720064] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3854.472875595093, \"sum\": 3854.472875595093, \"min\": 3854.472875595093}}, \"EndTime\": 1601797684.298684, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797680.443771}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:04 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=163.181745932 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:04 INFO 139662618720064] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:04 INFO 139662618720064] #quality_metric: host=algo-1, epoch=177, train loss <loss>=1.07939245105\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:04 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:05 INFO 139662618720064] Epoch[178] Batch[0] avg_epoch_loss=1.079800\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:05 INFO 139662618720064] #quality_metric: host=algo-1, epoch=178, batch=0 train loss <loss>=1.07980012894\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:06 INFO 139662618720064] Epoch[178] Batch[5] avg_epoch_loss=1.058377\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:06 INFO 139662618720064] #quality_metric: host=algo-1, epoch=178, batch=5 train loss <loss>=1.0583768189\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:06 INFO 139662618720064] Epoch[178] Batch [5]#011Speed: 188.16 samples/sec#011loss=1.058377\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:08 INFO 139662618720064] Epoch[178] Batch[10] avg_epoch_loss=1.027428\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:08 INFO 139662618720064] #quality_metric: host=algo-1, epoch=178, batch=10 train loss <loss>=0.990289890766\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:08 INFO 139662618720064] Epoch[178] Batch [10]#011Speed: 187.59 samples/sec#011loss=0.990290\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:08 INFO 139662618720064] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4214.1149044036865, \"sum\": 4214.1149044036865, \"min\": 4214.1149044036865}}, \"EndTime\": 1601797688.513425, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797684.298769}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:08 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=152.103522882 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:08 INFO 139662618720064] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:08 INFO 139662618720064] #quality_metric: host=algo-1, epoch=178, train loss <loss>=1.0274282152\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:08 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:09 INFO 139662618720064] Epoch[179] Batch[0] avg_epoch_loss=1.067639\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:09 INFO 139662618720064] #quality_metric: host=algo-1, epoch=179, batch=0 train loss <loss>=1.06763875484\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:11 INFO 139662618720064] Epoch[179] Batch[5] avg_epoch_loss=1.043885\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:11 INFO 139662618720064] #quality_metric: host=algo-1, epoch=179, batch=5 train loss <loss>=1.04388482372\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:11 INFO 139662618720064] Epoch[179] Batch [5]#011Speed: 187.77 samples/sec#011loss=1.043885\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:12 INFO 139662618720064] Epoch[179] Batch[10] avg_epoch_loss=1.205465\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:12 INFO 139662618720064] #quality_metric: host=algo-1, epoch=179, batch=10 train loss <loss>=1.39936070442\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:12 INFO 139662618720064] Epoch[179] Batch [10]#011Speed: 183.40 samples/sec#011loss=1.399361\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:12 INFO 139662618720064] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4265.284061431885, \"sum\": 4265.284061431885, \"min\": 4265.284061431885}}, \"EndTime\": 1601797692.779235, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797688.513506}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:12 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=153.092069977 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:12 INFO 139662618720064] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:12 INFO 139662618720064] #quality_metric: host=algo-1, epoch=179, train loss <loss>=1.20546476949\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:12 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:13 INFO 139662618720064] Epoch[180] Batch[0] avg_epoch_loss=1.061921\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:13 INFO 139662618720064] #quality_metric: host=algo-1, epoch=180, batch=0 train loss <loss>=1.0619212389\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:15 INFO 139662618720064] Epoch[180] Batch[5] avg_epoch_loss=1.011702\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:15 INFO 139662618720064] #quality_metric: host=algo-1, epoch=180, batch=5 train loss <loss>=1.0117016832\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:15 INFO 139662618720064] Epoch[180] Batch [5]#011Speed: 188.86 samples/sec#011loss=1.011702\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:16 INFO 139662618720064] processed a total of 585 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3873.2240200042725, \"sum\": 3873.2240200042725, \"min\": 3873.2240200042725}}, \"EndTime\": 1601797696.653055, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797692.779317}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:16 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=151.032056062 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:16 INFO 139662618720064] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:16 INFO 139662618720064] #quality_metric: host=algo-1, epoch=180, train loss <loss>=1.12919149399\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:16 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:17 INFO 139662618720064] Epoch[181] Batch[0] avg_epoch_loss=1.029042\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:17 INFO 139662618720064] #quality_metric: host=algo-1, epoch=181, batch=0 train loss <loss>=1.02904236317\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:19 INFO 139662618720064] Epoch[181] Batch[5] avg_epoch_loss=0.990281\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:19 INFO 139662618720064] #quality_metric: host=algo-1, epoch=181, batch=5 train loss <loss>=0.990281025569\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:19 INFO 139662618720064] Epoch[181] Batch [5]#011Speed: 186.06 samples/sec#011loss=0.990281\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:20 INFO 139662618720064] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3890.9881114959717, \"sum\": 3890.9881114959717, \"min\": 3890.9881114959717}}, \"EndTime\": 1601797700.544649, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797696.653141}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:20 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=162.164903685 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:20 INFO 139662618720064] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:20 INFO 139662618720064] #quality_metric: host=algo-1, epoch=181, train loss <loss>=1.02945148945\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:20 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:21 INFO 139662618720064] Epoch[182] Batch[0] avg_epoch_loss=1.133665\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:21 INFO 139662618720064] #quality_metric: host=algo-1, epoch=182, batch=0 train loss <loss>=1.13366496563\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:23 INFO 139662618720064] Epoch[182] Batch[5] avg_epoch_loss=0.970097\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:23 INFO 139662618720064] #quality_metric: host=algo-1, epoch=182, batch=5 train loss <loss>=0.970096856356\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:23 INFO 139662618720064] Epoch[182] Batch [5]#011Speed: 182.85 samples/sec#011loss=0.970097\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:24 INFO 139662618720064] Epoch[182] Batch[10] avg_epoch_loss=0.940404\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:24 INFO 139662618720064] #quality_metric: host=algo-1, epoch=182, batch=10 train loss <loss>=0.904771733284\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:24 INFO 139662618720064] Epoch[182] Batch [10]#011Speed: 187.87 samples/sec#011loss=0.904772\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:24 INFO 139662618720064] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4245.660066604614, \"sum\": 4245.660066604614, \"min\": 4245.660066604614}}, \"EndTime\": 1601797704.79088, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797700.544723}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:24 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=155.684215698 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:24 INFO 139662618720064] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:24 INFO 139662618720064] #quality_metric: host=algo-1, epoch=182, train loss <loss>=0.940403618596\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:24 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:24 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_e41e67d4-44cc-419c-8454-61146d64b5fc-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 102.73194313049316, \"sum\": 102.73194313049316, \"min\": 102.73194313049316}}, \"EndTime\": 1601797704.89424, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797704.790951}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:25 INFO 139662618720064] Epoch[183] Batch[0] avg_epoch_loss=1.150416\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:25 INFO 139662618720064] #quality_metric: host=algo-1, epoch=183, batch=0 train loss <loss>=1.15041601658\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:27 INFO 139662618720064] Epoch[183] Batch[5] avg_epoch_loss=1.056266\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:27 INFO 139662618720064] #quality_metric: host=algo-1, epoch=183, batch=5 train loss <loss>=1.05626594027\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:27 INFO 139662618720064] Epoch[183] Batch [5]#011Speed: 187.87 samples/sec#011loss=1.056266\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:29 INFO 139662618720064] Epoch[183] Batch[10] avg_epoch_loss=1.003428\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:29 INFO 139662618720064] #quality_metric: host=algo-1, epoch=183, batch=10 train loss <loss>=0.940023285151\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:29 INFO 139662618720064] Epoch[183] Batch [10]#011Speed: 185.73 samples/sec#011loss=0.940023\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:29 INFO 139662618720064] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4220.331907272339, \"sum\": 4220.331907272339, \"min\": 4220.331907272339}}, \"EndTime\": 1601797709.114724, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797704.894327}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:29 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=153.774274935 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:29 INFO 139662618720064] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:29 INFO 139662618720064] #quality_metric: host=algo-1, epoch=183, train loss <loss>=1.00342836976\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:29 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:29 INFO 139662618720064] Epoch[184] Batch[0] avg_epoch_loss=1.186079\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:29 INFO 139662618720064] #quality_metric: host=algo-1, epoch=184, batch=0 train loss <loss>=1.18607878685\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:31 INFO 139662618720064] Epoch[184] Batch[5] avg_epoch_loss=1.239619\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:31 INFO 139662618720064] #quality_metric: host=algo-1, epoch=184, batch=5 train loss <loss>=1.23961907625\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:31 INFO 139662618720064] Epoch[184] Batch [5]#011Speed: 189.81 samples/sec#011loss=1.239619\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:32 INFO 139662618720064] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3861.8099689483643, \"sum\": 3861.8099689483643, \"min\": 3861.8099689483643}}, \"EndTime\": 1601797712.977083, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797709.114825}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:32 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=161.576448921 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:32 INFO 139662618720064] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:32 INFO 139662618720064] #quality_metric: host=algo-1, epoch=184, train loss <loss>=1.19935635328\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:32 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:33 INFO 139662618720064] Epoch[185] Batch[0] avg_epoch_loss=1.096893\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:33 INFO 139662618720064] #quality_metric: host=algo-1, epoch=185, batch=0 train loss <loss>=1.09689307213\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:35 INFO 139662618720064] Epoch[185] Batch[5] avg_epoch_loss=1.096975\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:35 INFO 139662618720064] #quality_metric: host=algo-1, epoch=185, batch=5 train loss <loss>=1.09697475036\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:35 INFO 139662618720064] Epoch[185] Batch [5]#011Speed: 185.87 samples/sec#011loss=1.096975\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:36 INFO 139662618720064] processed a total of 622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3885.335922241211, \"sum\": 3885.335922241211, \"min\": 3885.335922241211}}, \"EndTime\": 1601797716.862978, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797712.977182}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:36 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=160.083921214 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:36 INFO 139662618720064] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:36 INFO 139662618720064] #quality_metric: host=algo-1, epoch=185, train loss <loss>=1.12684737444\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:36 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:37 INFO 139662618720064] Epoch[186] Batch[0] avg_epoch_loss=0.959514\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:37 INFO 139662618720064] #quality_metric: host=algo-1, epoch=186, batch=0 train loss <loss>=0.95951384306\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:39 INFO 139662618720064] Epoch[186] Batch[5] avg_epoch_loss=1.044215\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:39 INFO 139662618720064] #quality_metric: host=algo-1, epoch=186, batch=5 train loss <loss>=1.04421467582\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:39 INFO 139662618720064] Epoch[186] Batch [5]#011Speed: 188.00 samples/sec#011loss=1.044215\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:41 INFO 139662618720064] Epoch[186] Batch[10] avg_epoch_loss=1.103202\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:41 INFO 139662618720064] #quality_metric: host=algo-1, epoch=186, batch=10 train loss <loss>=1.17398612499\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:41 INFO 139662618720064] Epoch[186] Batch [10]#011Speed: 189.35 samples/sec#011loss=1.173986\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:41 INFO 139662618720064] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4197.667837142944, \"sum\": 4197.667837142944, \"min\": 4197.667837142944}}, \"EndTime\": 1601797721.061216, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797716.863063}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:41 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=154.60519982 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:41 INFO 139662618720064] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:41 INFO 139662618720064] #quality_metric: host=algo-1, epoch=186, train loss <loss>=1.10320169817\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:41 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:41 INFO 139662618720064] Epoch[187] Batch[0] avg_epoch_loss=1.403545\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:41 INFO 139662618720064] #quality_metric: host=algo-1, epoch=187, batch=0 train loss <loss>=1.40354454517\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:43 INFO 139662618720064] Epoch[187] Batch[5] avg_epoch_loss=1.089968\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:43 INFO 139662618720064] #quality_metric: host=algo-1, epoch=187, batch=5 train loss <loss>=1.08996795615\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:43 INFO 139662618720064] Epoch[187] Batch [5]#011Speed: 185.04 samples/sec#011loss=1.089968\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:45 INFO 139662618720064] Epoch[187] Batch[10] avg_epoch_loss=1.061771\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:45 INFO 139662618720064] #quality_metric: host=algo-1, epoch=187, batch=10 train loss <loss>=1.02793540955\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:45 INFO 139662618720064] Epoch[187] Batch [10]#011Speed: 185.80 samples/sec#011loss=1.027935\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:45 INFO 139662618720064] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4256.745100021362, \"sum\": 4256.745100021362, \"min\": 4256.745100021362}}, \"EndTime\": 1601797725.318498, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797721.061296}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:45 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=150.815287755 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:45 INFO 139662618720064] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:45 INFO 139662618720064] #quality_metric: host=algo-1, epoch=187, train loss <loss>=1.06177134405\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:45 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:46 INFO 139662618720064] Epoch[188] Batch[0] avg_epoch_loss=0.893585\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:46 INFO 139662618720064] #quality_metric: host=algo-1, epoch=188, batch=0 train loss <loss>=0.893584787846\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:47 INFO 139662618720064] Epoch[188] Batch[5] avg_epoch_loss=0.968026\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:47 INFO 139662618720064] #quality_metric: host=algo-1, epoch=188, batch=5 train loss <loss>=0.968026091655\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:47 INFO 139662618720064] Epoch[188] Batch [5]#011Speed: 189.39 samples/sec#011loss=0.968026\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:49 INFO 139662618720064] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3900.730848312378, \"sum\": 3900.730848312378, \"min\": 3900.730848312378}}, \"EndTime\": 1601797729.219873, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797725.318577}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:49 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=162.784743096 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:49 INFO 139662618720064] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:49 INFO 139662618720064] #quality_metric: host=algo-1, epoch=188, train loss <loss>=0.951255822182\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:49 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:50 INFO 139662618720064] Epoch[189] Batch[0] avg_epoch_loss=0.946968\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:50 INFO 139662618720064] #quality_metric: host=algo-1, epoch=189, batch=0 train loss <loss>=0.946967840195\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:51 INFO 139662618720064] Epoch[189] Batch[5] avg_epoch_loss=0.951886\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:51 INFO 139662618720064] #quality_metric: host=algo-1, epoch=189, batch=5 train loss <loss>=0.951886236668\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:51 INFO 139662618720064] Epoch[189] Batch [5]#011Speed: 188.07 samples/sec#011loss=0.951886\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:53 INFO 139662618720064] processed a total of 608 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3882.491111755371, \"sum\": 3882.491111755371, \"min\": 3882.491111755371}}, \"EndTime\": 1601797733.102974, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797729.21996}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:53 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=156.595371412 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:53 INFO 139662618720064] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:53 INFO 139662618720064] #quality_metric: host=algo-1, epoch=189, train loss <loss>=0.983315896988\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:53 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:53 INFO 139662618720064] Epoch[190] Batch[0] avg_epoch_loss=0.858087\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:53 INFO 139662618720064] #quality_metric: host=algo-1, epoch=190, batch=0 train loss <loss>=0.858086705208\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:55 INFO 139662618720064] Epoch[190] Batch[5] avg_epoch_loss=1.073798\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:55 INFO 139662618720064] #quality_metric: host=algo-1, epoch=190, batch=5 train loss <loss>=1.07379777233\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:55 INFO 139662618720064] Epoch[190] Batch [5]#011Speed: 189.15 samples/sec#011loss=1.073798\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:56 INFO 139662618720064] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3841.761827468872, \"sum\": 3841.761827468872, \"min\": 3841.761827468872}}, \"EndTime\": 1601797736.945392, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797733.103059}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:56 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=161.378980712 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:56 INFO 139662618720064] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:56 INFO 139662618720064] #quality_metric: host=algo-1, epoch=190, train loss <loss>=1.11664384007\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:56 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:57 INFO 139662618720064] Epoch[191] Batch[0] avg_epoch_loss=1.153668\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:57 INFO 139662618720064] #quality_metric: host=algo-1, epoch=191, batch=0 train loss <loss>=1.153668046\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:59 INFO 139662618720064] Epoch[191] Batch[5] avg_epoch_loss=1.099604\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:59 INFO 139662618720064] #quality_metric: host=algo-1, epoch=191, batch=5 train loss <loss>=1.09960442781\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:48:59 INFO 139662618720064] Epoch[191] Batch [5]#011Speed: 188.52 samples/sec#011loss=1.099604\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:01 INFO 139662618720064] Epoch[191] Batch[10] avg_epoch_loss=0.968997\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:01 INFO 139662618720064] #quality_metric: host=algo-1, epoch=191, batch=10 train loss <loss>=0.812267816067\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:01 INFO 139662618720064] Epoch[191] Batch [10]#011Speed: 189.75 samples/sec#011loss=0.812268\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:01 INFO 139662618720064] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4198.490858078003, \"sum\": 4198.490858078003, \"min\": 4198.490858078003}}, \"EndTime\": 1601797741.144429, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797736.945473}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:01 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=156.242448574 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:01 INFO 139662618720064] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:01 INFO 139662618720064] #quality_metric: host=algo-1, epoch=191, train loss <loss>=0.96899687702\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:01 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:01 INFO 139662618720064] Epoch[192] Batch[0] avg_epoch_loss=1.212294\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:01 INFO 139662618720064] #quality_metric: host=algo-1, epoch=192, batch=0 train loss <loss>=1.21229374409\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:03 INFO 139662618720064] Epoch[192] Batch[5] avg_epoch_loss=1.064464\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:03 INFO 139662618720064] #quality_metric: host=algo-1, epoch=192, batch=5 train loss <loss>=1.06446377436\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:03 INFO 139662618720064] Epoch[192] Batch [5]#011Speed: 182.79 samples/sec#011loss=1.064464\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:05 INFO 139662618720064] processed a total of 609 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3918.17307472229, \"sum\": 3918.17307472229, \"min\": 3918.17307472229}}, \"EndTime\": 1601797745.063093, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797741.144505}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:05 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=155.424625452 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:05 INFO 139662618720064] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:05 INFO 139662618720064] #quality_metric: host=algo-1, epoch=192, train loss <loss>=1.08847495317\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:05 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:05 INFO 139662618720064] Epoch[193] Batch[0] avg_epoch_loss=0.972106\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:05 INFO 139662618720064] #quality_metric: host=algo-1, epoch=193, batch=0 train loss <loss>=0.972106456757\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:07 INFO 139662618720064] Epoch[193] Batch[5] avg_epoch_loss=1.054099\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:07 INFO 139662618720064] #quality_metric: host=algo-1, epoch=193, batch=5 train loss <loss>=1.05409866571\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:07 INFO 139662618720064] Epoch[193] Batch [5]#011Speed: 184.63 samples/sec#011loss=1.054099\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:09 INFO 139662618720064] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3949.8140811920166, \"sum\": 3949.8140811920166, \"min\": 3949.8140811920166}}, \"EndTime\": 1601797749.013472, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797745.063177}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:09 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=157.977084548 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:09 INFO 139662618720064] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:09 INFO 139662618720064] #quality_metric: host=algo-1, epoch=193, train loss <loss>=1.02414938807\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:09 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:09 INFO 139662618720064] Epoch[194] Batch[0] avg_epoch_loss=0.830683\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:09 INFO 139662618720064] #quality_metric: host=algo-1, epoch=194, batch=0 train loss <loss>=0.830682635307\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:11 INFO 139662618720064] Epoch[194] Batch[5] avg_epoch_loss=0.984060\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:11 INFO 139662618720064] #quality_metric: host=algo-1, epoch=194, batch=5 train loss <loss>=0.984059671561\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:11 INFO 139662618720064] Epoch[194] Batch [5]#011Speed: 190.35 samples/sec#011loss=0.984060\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:12 INFO 139662618720064] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3834.8681926727295, \"sum\": 3834.8681926727295, \"min\": 3834.8681926727295}}, \"EndTime\": 1601797752.848901, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797749.013558}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:12 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=162.712075217 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:12 INFO 139662618720064] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:12 INFO 139662618720064] #quality_metric: host=algo-1, epoch=194, train loss <loss>=0.994562667608\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:12 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:13 INFO 139662618720064] Epoch[195] Batch[0] avg_epoch_loss=1.058151\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:13 INFO 139662618720064] #quality_metric: host=algo-1, epoch=195, batch=0 train loss <loss>=1.05815088749\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:15 INFO 139662618720064] Epoch[195] Batch[5] avg_epoch_loss=1.097160\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:15 INFO 139662618720064] #quality_metric: host=algo-1, epoch=195, batch=5 train loss <loss>=1.09715979298\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:15 INFO 139662618720064] Epoch[195] Batch [5]#011Speed: 190.03 samples/sec#011loss=1.097160\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:17 INFO 139662618720064] Epoch[195] Batch[10] avg_epoch_loss=1.047870\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:17 INFO 139662618720064] #quality_metric: host=algo-1, epoch=195, batch=10 train loss <loss>=0.988722479343\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:17 INFO 139662618720064] Epoch[195] Batch [10]#011Speed: 188.71 samples/sec#011loss=0.988722\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:17 INFO 139662618720064] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4261.533975601196, \"sum\": 4261.533975601196, \"min\": 4261.533975601196}}, \"EndTime\": 1601797757.11101, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797752.848987}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:17 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=151.349758519 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:17 INFO 139662618720064] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:17 INFO 139662618720064] #quality_metric: host=algo-1, epoch=195, train loss <loss>=1.04787010496\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:17 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:17 INFO 139662618720064] Epoch[196] Batch[0] avg_epoch_loss=0.720012\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:17 INFO 139662618720064] #quality_metric: host=algo-1, epoch=196, batch=0 train loss <loss>=0.720012247562\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:19 INFO 139662618720064] Epoch[196] Batch[5] avg_epoch_loss=0.926421\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:19 INFO 139662618720064] #quality_metric: host=algo-1, epoch=196, batch=5 train loss <loss>=0.926420589288\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:19 INFO 139662618720064] Epoch[196] Batch [5]#011Speed: 186.28 samples/sec#011loss=0.926421\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:20 INFO 139662618720064] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3882.0149898529053, \"sum\": 3882.0149898529053, \"min\": 3882.0149898529053}}, \"EndTime\": 1601797760.993543, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797757.11109}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:20 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=159.705693324 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:20 INFO 139662618720064] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:20 INFO 139662618720064] #quality_metric: host=algo-1, epoch=196, train loss <loss>=0.908369541168\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:20 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:21 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_e46d96f1-d71d-4bb0-9830-47fba79d4963-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 111.74893379211426, \"sum\": 111.74893379211426, \"min\": 111.74893379211426}}, \"EndTime\": 1601797761.105958, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797760.993629}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:21 INFO 139662618720064] Epoch[197] Batch[0] avg_epoch_loss=0.952046\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:21 INFO 139662618720064] #quality_metric: host=algo-1, epoch=197, batch=0 train loss <loss>=0.952046096325\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:23 INFO 139662618720064] Epoch[197] Batch[5] avg_epoch_loss=1.023657\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:23 INFO 139662618720064] #quality_metric: host=algo-1, epoch=197, batch=5 train loss <loss>=1.02365686496\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:23 INFO 139662618720064] Epoch[197] Batch [5]#011Speed: 188.23 samples/sec#011loss=1.023657\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:24 INFO 139662618720064] processed a total of 612 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3845.78800201416, \"sum\": 3845.78800201416, \"min\": 3845.78800201416}}, \"EndTime\": 1601797764.95189, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797761.106035}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:24 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=159.130786267 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:24 INFO 139662618720064] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:24 INFO 139662618720064] #quality_metric: host=algo-1, epoch=197, train loss <loss>=0.990781676769\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:24 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:25 INFO 139662618720064] Epoch[198] Batch[0] avg_epoch_loss=0.957449\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:25 INFO 139662618720064] #quality_metric: host=algo-1, epoch=198, batch=0 train loss <loss>=0.957449376583\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:27 INFO 139662618720064] Epoch[198] Batch[5] avg_epoch_loss=1.025163\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:27 INFO 139662618720064] #quality_metric: host=algo-1, epoch=198, batch=5 train loss <loss>=1.02516313394\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:27 INFO 139662618720064] Epoch[198] Batch [5]#011Speed: 185.66 samples/sec#011loss=1.025163\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:29 INFO 139662618720064] Epoch[198] Batch[10] avg_epoch_loss=1.229347\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:29 INFO 139662618720064] #quality_metric: host=algo-1, epoch=198, batch=10 train loss <loss>=1.47436689138\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:29 INFO 139662618720064] Epoch[198] Batch [10]#011Speed: 185.78 samples/sec#011loss=1.474367\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:29 INFO 139662618720064] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4237.563848495483, \"sum\": 4237.563848495483, \"min\": 4237.563848495483}}, \"EndTime\": 1601797769.190051, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797764.951959}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:29 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=154.329980906 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:29 INFO 139662618720064] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:29 INFO 139662618720064] #quality_metric: host=algo-1, epoch=198, train loss <loss>=1.22934666005\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:29 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:29 INFO 139662618720064] Epoch[199] Batch[0] avg_epoch_loss=1.001689\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:29 INFO 139662618720064] #quality_metric: host=algo-1, epoch=199, batch=0 train loss <loss>=1.00168895721\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:31 INFO 139662618720064] Epoch[199] Batch[5] avg_epoch_loss=1.039058\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:31 INFO 139662618720064] #quality_metric: host=algo-1, epoch=199, batch=5 train loss <loss>=1.03905798992\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:31 INFO 139662618720064] Epoch[199] Batch [5]#011Speed: 187.83 samples/sec#011loss=1.039058\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:33 INFO 139662618720064] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3833.0678939819336, \"sum\": 3833.0678939819336, \"min\": 3833.0678939819336}}, \"EndTime\": 1601797773.023681, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797769.190117}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:33 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=163.310283058 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:33 INFO 139662618720064] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:33 INFO 139662618720064] #quality_metric: host=algo-1, epoch=199, train loss <loss>=1.03855986595\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:33 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:33 INFO 139662618720064] Epoch[200] Batch[0] avg_epoch_loss=1.237414\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:33 INFO 139662618720064] #quality_metric: host=algo-1, epoch=200, batch=0 train loss <loss>=1.23741447926\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:35 INFO 139662618720064] Epoch[200] Batch[5] avg_epoch_loss=1.157201\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:35 INFO 139662618720064] #quality_metric: host=algo-1, epoch=200, batch=5 train loss <loss>=1.15720085303\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:35 INFO 139662618720064] Epoch[200] Batch [5]#011Speed: 189.22 samples/sec#011loss=1.157201\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:36 INFO 139662618720064] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3862.114906311035, \"sum\": 3862.114906311035, \"min\": 3862.114906311035}}, \"EndTime\": 1601797776.886361, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797773.023766}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:36 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=164.9301927 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:36 INFO 139662618720064] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:36 INFO 139662618720064] #quality_metric: host=algo-1, epoch=200, train loss <loss>=1.12257335186\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:36 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:37 INFO 139662618720064] Epoch[201] Batch[0] avg_epoch_loss=1.003418\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:37 INFO 139662618720064] #quality_metric: host=algo-1, epoch=201, batch=0 train loss <loss>=1.00341761112\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:39 INFO 139662618720064] Epoch[201] Batch[5] avg_epoch_loss=1.092087\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:39 INFO 139662618720064] #quality_metric: host=algo-1, epoch=201, batch=5 train loss <loss>=1.09208655357\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:39 INFO 139662618720064] Epoch[201] Batch [5]#011Speed: 188.58 samples/sec#011loss=1.092087\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:40 INFO 139662618720064] processed a total of 602 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3851.719856262207, \"sum\": 3851.719856262207, \"min\": 3851.719856262207}}, \"EndTime\": 1601797780.738664, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797776.886445}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:40 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=156.288738496 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:40 INFO 139662618720064] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:40 INFO 139662618720064] #quality_metric: host=algo-1, epoch=201, train loss <loss>=1.15555422902\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:40 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:41 INFO 139662618720064] Epoch[202] Batch[0] avg_epoch_loss=1.042642\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:41 INFO 139662618720064] #quality_metric: host=algo-1, epoch=202, batch=0 train loss <loss>=1.0426415205\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:43 INFO 139662618720064] Epoch[202] Batch[5] avg_epoch_loss=0.994763\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:43 INFO 139662618720064] #quality_metric: host=algo-1, epoch=202, batch=5 train loss <loss>=0.994763006767\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:43 INFO 139662618720064] Epoch[202] Batch [5]#011Speed: 187.53 samples/sec#011loss=0.994763\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:44 INFO 139662618720064] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3862.592935562134, \"sum\": 3862.592935562134, \"min\": 3862.592935562134}}, \"EndTime\": 1601797784.601867, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797780.738748}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:44 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=163.356431147 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:44 INFO 139662618720064] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:44 INFO 139662618720064] #quality_metric: host=algo-1, epoch=202, train loss <loss>=0.970702856779\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:44 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:45 INFO 139662618720064] Epoch[203] Batch[0] avg_epoch_loss=0.841999\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:45 INFO 139662618720064] #quality_metric: host=algo-1, epoch=203, batch=0 train loss <loss>=0.841998875141\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:47 INFO 139662618720064] Epoch[203] Batch[5] avg_epoch_loss=0.994622\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:47 INFO 139662618720064] #quality_metric: host=algo-1, epoch=203, batch=5 train loss <loss>=0.994622250398\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:47 INFO 139662618720064] Epoch[203] Batch [5]#011Speed: 190.57 samples/sec#011loss=0.994622\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:48 INFO 139662618720064] Epoch[203] Batch[10] avg_epoch_loss=0.992569\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:48 INFO 139662618720064] #quality_metric: host=algo-1, epoch=203, batch=10 train loss <loss>=0.990106105804\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:48 INFO 139662618720064] Epoch[203] Batch [10]#011Speed: 188.91 samples/sec#011loss=0.990106\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:48 INFO 139662618720064] processed a total of 686 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4190.542936325073, \"sum\": 4190.542936325073, \"min\": 4190.542936325073}}, \"EndTime\": 1601797788.792958, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797784.601952}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:48 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=163.697560676 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:48 INFO 139662618720064] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:48 INFO 139662618720064] #quality_metric: host=algo-1, epoch=203, train loss <loss>=0.992569457401\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:48 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:49 INFO 139662618720064] Epoch[204] Batch[0] avg_epoch_loss=0.918534\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:49 INFO 139662618720064] #quality_metric: host=algo-1, epoch=204, batch=0 train loss <loss>=0.918533563614\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:51 INFO 139662618720064] Epoch[204] Batch[5] avg_epoch_loss=0.964827\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:51 INFO 139662618720064] #quality_metric: host=algo-1, epoch=204, batch=5 train loss <loss>=0.964827368657\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:51 INFO 139662618720064] Epoch[204] Batch [5]#011Speed: 190.96 samples/sec#011loss=0.964827\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:52 INFO 139662618720064] Epoch[204] Batch[10] avg_epoch_loss=0.935849\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:52 INFO 139662618720064] #quality_metric: host=algo-1, epoch=204, batch=10 train loss <loss>=0.901075172424\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:52 INFO 139662618720064] Epoch[204] Batch [10]#011Speed: 189.25 samples/sec#011loss=0.901075\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:52 INFO 139662618720064] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4180.011987686157, \"sum\": 4180.011987686157, \"min\": 4180.011987686157}}, \"EndTime\": 1601797792.973455, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797788.793034}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:52 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=157.650563232 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:52 INFO 139662618720064] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:52 INFO 139662618720064] #quality_metric: host=algo-1, epoch=204, train loss <loss>=0.935849097642\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:52 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:53 INFO 139662618720064] Epoch[205] Batch[0] avg_epoch_loss=0.907756\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:53 INFO 139662618720064] #quality_metric: host=algo-1, epoch=205, batch=0 train loss <loss>=0.907756328583\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:55 INFO 139662618720064] Epoch[205] Batch[5] avg_epoch_loss=0.999639\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:55 INFO 139662618720064] #quality_metric: host=algo-1, epoch=205, batch=5 train loss <loss>=0.999639262756\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:55 INFO 139662618720064] Epoch[205] Batch [5]#011Speed: 189.18 samples/sec#011loss=0.999639\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:57 INFO 139662618720064] Epoch[205] Batch[10] avg_epoch_loss=0.961896\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:57 INFO 139662618720064] #quality_metric: host=algo-1, epoch=205, batch=10 train loss <loss>=0.916603127122\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:57 INFO 139662618720064] Epoch[205] Batch [10]#011Speed: 185.39 samples/sec#011loss=0.916603\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:57 INFO 139662618720064] processed a total of 668 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4239.404201507568, \"sum\": 4239.404201507568, \"min\": 4239.404201507568}}, \"EndTime\": 1601797797.213385, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797792.973535}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:57 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=157.564818568 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:57 INFO 139662618720064] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:57 INFO 139662618720064] #quality_metric: host=algo-1, epoch=205, train loss <loss>=0.96189556474\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:57 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:58 INFO 139662618720064] Epoch[206] Batch[0] avg_epoch_loss=1.226702\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:58 INFO 139662618720064] #quality_metric: host=algo-1, epoch=206, batch=0 train loss <loss>=1.2267023325\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:59 INFO 139662618720064] Epoch[206] Batch[5] avg_epoch_loss=1.020616\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:59 INFO 139662618720064] #quality_metric: host=algo-1, epoch=206, batch=5 train loss <loss>=1.02061582605\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:49:59 INFO 139662618720064] Epoch[206] Batch [5]#011Speed: 190.04 samples/sec#011loss=1.020616\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:01 INFO 139662618720064] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3842.0498371124268, \"sum\": 3842.0498371124268, \"min\": 3842.0498371124268}}, \"EndTime\": 1601797801.055956, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797797.213466}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:01 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=163.969575412 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:01 INFO 139662618720064] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:01 INFO 139662618720064] #quality_metric: host=algo-1, epoch=206, train loss <loss>=1.03608669639\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:01 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:01 INFO 139662618720064] Epoch[207] Batch[0] avg_epoch_loss=1.013029\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:01 INFO 139662618720064] #quality_metric: host=algo-1, epoch=207, batch=0 train loss <loss>=1.01302874088\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:03 INFO 139662618720064] Epoch[207] Batch[5] avg_epoch_loss=1.010707\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:03 INFO 139662618720064] #quality_metric: host=algo-1, epoch=207, batch=5 train loss <loss>=1.01070715984\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:03 INFO 139662618720064] Epoch[207] Batch [5]#011Speed: 190.29 samples/sec#011loss=1.010707\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:05 INFO 139662618720064] Epoch[207] Batch[10] avg_epoch_loss=1.072563\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:05 INFO 139662618720064] #quality_metric: host=algo-1, epoch=207, batch=10 train loss <loss>=1.14678928852\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:05 INFO 139662618720064] Epoch[207] Batch [10]#011Speed: 187.88 samples/sec#011loss=1.146789\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:05 INFO 139662618720064] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4244.562864303589, \"sum\": 4244.562864303589, \"min\": 4244.562864303589}}, \"EndTime\": 1601797805.301086, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797801.056042}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:05 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=154.075178211 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:05 INFO 139662618720064] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:05 INFO 139662618720064] #quality_metric: host=algo-1, epoch=207, train loss <loss>=1.07256267288\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:05 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:06 INFO 139662618720064] Epoch[208] Batch[0] avg_epoch_loss=1.280944\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:06 INFO 139662618720064] #quality_metric: host=algo-1, epoch=208, batch=0 train loss <loss>=1.28094434738\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:07 INFO 139662618720064] Epoch[208] Batch[5] avg_epoch_loss=1.014763\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:07 INFO 139662618720064] #quality_metric: host=algo-1, epoch=208, batch=5 train loss <loss>=1.01476274927\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:07 INFO 139662618720064] Epoch[208] Batch [5]#011Speed: 190.58 samples/sec#011loss=1.014763\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:08 INFO 139662618720064] processed a total of 572 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3551.3978004455566, \"sum\": 3551.3978004455566, \"min\": 3551.3978004455566}}, \"EndTime\": 1601797808.852997, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797805.301165}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:08 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=161.057611848 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:08 INFO 139662618720064] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:08 INFO 139662618720064] #quality_metric: host=algo-1, epoch=208, train loss <loss>=1.03979229265\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:08 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:09 INFO 139662618720064] Epoch[209] Batch[0] avg_epoch_loss=0.955021\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:09 INFO 139662618720064] #quality_metric: host=algo-1, epoch=209, batch=0 train loss <loss>=0.955020785332\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:11 INFO 139662618720064] Epoch[209] Batch[5] avg_epoch_loss=0.979087\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:11 INFO 139662618720064] #quality_metric: host=algo-1, epoch=209, batch=5 train loss <loss>=0.979086846113\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:11 INFO 139662618720064] Epoch[209] Batch [5]#011Speed: 190.81 samples/sec#011loss=0.979087\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:13 INFO 139662618720064] Epoch[209] Batch[10] avg_epoch_loss=0.956947\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:13 INFO 139662618720064] #quality_metric: host=algo-1, epoch=209, batch=10 train loss <loss>=0.930380189419\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:13 INFO 139662618720064] Epoch[209] Batch [10]#011Speed: 188.93 samples/sec#011loss=0.930380\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:13 INFO 139662618720064] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4235.179901123047, \"sum\": 4235.179901123047, \"min\": 4235.179901123047}}, \"EndTime\": 1601797813.088734, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797808.853082}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:13 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=155.124782202 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:13 INFO 139662618720064] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:13 INFO 139662618720064] #quality_metric: host=algo-1, epoch=209, train loss <loss>=0.956947456707\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:13 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:13 INFO 139662618720064] Epoch[210] Batch[0] avg_epoch_loss=1.034757\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:13 INFO 139662618720064] #quality_metric: host=algo-1, epoch=210, batch=0 train loss <loss>=1.03475701809\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:15 INFO 139662618720064] Epoch[210] Batch[5] avg_epoch_loss=0.977481\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:15 INFO 139662618720064] #quality_metric: host=algo-1, epoch=210, batch=5 train loss <loss>=0.977480818828\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:15 INFO 139662618720064] Epoch[210] Batch [5]#011Speed: 190.14 samples/sec#011loss=0.977481\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:16 INFO 139662618720064] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3871.3178634643555, \"sum\": 3871.3178634643555, \"min\": 3871.3178634643555}}, \"EndTime\": 1601797816.960569, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797813.088813}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:16 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=161.696982238 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:16 INFO 139662618720064] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:16 INFO 139662618720064] #quality_metric: host=algo-1, epoch=210, train loss <loss>=0.970361691713\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:16 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:17 INFO 139662618720064] Epoch[211] Batch[0] avg_epoch_loss=1.038583\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:17 INFO 139662618720064] #quality_metric: host=algo-1, epoch=211, batch=0 train loss <loss>=1.03858280182\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:19 INFO 139662618720064] Epoch[211] Batch[5] avg_epoch_loss=1.012015\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:19 INFO 139662618720064] #quality_metric: host=algo-1, epoch=211, batch=5 train loss <loss>=1.01201477647\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:19 INFO 139662618720064] Epoch[211] Batch [5]#011Speed: 189.68 samples/sec#011loss=1.012015\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:20 INFO 139662618720064] processed a total of 614 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3854.142904281616, \"sum\": 3854.142904281616, \"min\": 3854.142904281616}}, \"EndTime\": 1601797820.815238, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797816.960651}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:20 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=159.304783827 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:20 INFO 139662618720064] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:20 INFO 139662618720064] #quality_metric: host=algo-1, epoch=211, train loss <loss>=0.955630648136\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:20 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:21 INFO 139662618720064] Epoch[212] Batch[0] avg_epoch_loss=1.014270\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:21 INFO 139662618720064] #quality_metric: host=algo-1, epoch=212, batch=0 train loss <loss>=1.01426959038\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:23 INFO 139662618720064] Epoch[212] Batch[5] avg_epoch_loss=1.014115\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:23 INFO 139662618720064] #quality_metric: host=algo-1, epoch=212, batch=5 train loss <loss>=1.01411484679\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:23 INFO 139662618720064] Epoch[212] Batch [5]#011Speed: 188.29 samples/sec#011loss=1.014115\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:25 INFO 139662618720064] Epoch[212] Batch[10] avg_epoch_loss=0.974703\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:25 INFO 139662618720064] #quality_metric: host=algo-1, epoch=212, batch=10 train loss <loss>=0.927408957481\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:25 INFO 139662618720064] Epoch[212] Batch [10]#011Speed: 186.54 samples/sec#011loss=0.927409\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:25 INFO 139662618720064] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4205.174207687378, \"sum\": 4205.174207687378, \"min\": 4205.174207687378}}, \"EndTime\": 1601797825.020991, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797820.815307}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:25 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=155.043040748 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:25 INFO 139662618720064] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:25 INFO 139662618720064] #quality_metric: host=algo-1, epoch=212, train loss <loss>=0.97470307892\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:25 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:25 INFO 139662618720064] Epoch[213] Batch[0] avg_epoch_loss=1.257099\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:25 INFO 139662618720064] #quality_metric: host=algo-1, epoch=213, batch=0 train loss <loss>=1.25709927082\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:27 INFO 139662618720064] Epoch[213] Batch[5] avg_epoch_loss=1.105423\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:27 INFO 139662618720064] #quality_metric: host=algo-1, epoch=213, batch=5 train loss <loss>=1.10542307297\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:27 INFO 139662618720064] Epoch[213] Batch [5]#011Speed: 187.80 samples/sec#011loss=1.105423\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:29 INFO 139662618720064] Epoch[213] Batch[10] avg_epoch_loss=1.039970\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:29 INFO 139662618720064] #quality_metric: host=algo-1, epoch=213, batch=10 train loss <loss>=0.961427032948\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:29 INFO 139662618720064] Epoch[213] Batch [10]#011Speed: 187.73 samples/sec#011loss=0.961427\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:29 INFO 139662618720064] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4197.880029678345, \"sum\": 4197.880029678345, \"min\": 4197.880029678345}}, \"EndTime\": 1601797829.219419, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797825.02106}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:29 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=158.17025371 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:29 INFO 139662618720064] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:29 INFO 139662618720064] #quality_metric: host=algo-1, epoch=213, train loss <loss>=1.03997032751\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:29 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:30 INFO 139662618720064] Epoch[214] Batch[0] avg_epoch_loss=1.102954\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:30 INFO 139662618720064] #quality_metric: host=algo-1, epoch=214, batch=0 train loss <loss>=1.10295367241\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:31 INFO 139662618720064] Epoch[214] Batch[5] avg_epoch_loss=1.004153\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:31 INFO 139662618720064] #quality_metric: host=algo-1, epoch=214, batch=5 train loss <loss>=1.00415338079\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:31 INFO 139662618720064] Epoch[214] Batch [5]#011Speed: 187.34 samples/sec#011loss=1.004153\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:33 INFO 139662618720064] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3842.4911499023438, \"sum\": 3842.4911499023438, \"min\": 3842.4911499023438}}, \"EndTime\": 1601797833.062472, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797829.219504}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:33 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=166.553116105 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:33 INFO 139662618720064] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:33 INFO 139662618720064] #quality_metric: host=algo-1, epoch=214, train loss <loss>=0.984209835529\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:33 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:33 INFO 139662618720064] Epoch[215] Batch[0] avg_epoch_loss=0.915343\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:33 INFO 139662618720064] #quality_metric: host=algo-1, epoch=215, batch=0 train loss <loss>=0.915342986584\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:35 INFO 139662618720064] Epoch[215] Batch[5] avg_epoch_loss=0.962029\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:35 INFO 139662618720064] #quality_metric: host=algo-1, epoch=215, batch=5 train loss <loss>=0.962029476961\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:35 INFO 139662618720064] Epoch[215] Batch [5]#011Speed: 190.09 samples/sec#011loss=0.962029\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:37 INFO 139662618720064] Epoch[215] Batch[10] avg_epoch_loss=0.964602\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:37 INFO 139662618720064] #quality_metric: host=algo-1, epoch=215, batch=10 train loss <loss>=0.967689681053\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:37 INFO 139662618720064] Epoch[215] Batch [10]#011Speed: 189.74 samples/sec#011loss=0.967690\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:37 INFO 139662618720064] processed a total of 674 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4186.927080154419, \"sum\": 4186.927080154419, \"min\": 4186.927080154419}}, \"EndTime\": 1601797837.250036, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797833.062559}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:37 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=160.97267424 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:37 INFO 139662618720064] #progress_metric: host=algo-1, completed 54 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:37 INFO 139662618720064] #quality_metric: host=algo-1, epoch=215, train loss <loss>=0.964602297003\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:37 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:38 INFO 139662618720064] Epoch[216] Batch[0] avg_epoch_loss=1.166983\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:38 INFO 139662618720064] #quality_metric: host=algo-1, epoch=216, batch=0 train loss <loss>=1.1669832468\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:39 INFO 139662618720064] Epoch[216] Batch[5] avg_epoch_loss=1.123741\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:39 INFO 139662618720064] #quality_metric: host=algo-1, epoch=216, batch=5 train loss <loss>=1.12374127905\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:39 INFO 139662618720064] Epoch[216] Batch [5]#011Speed: 190.54 samples/sec#011loss=1.123741\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:41 INFO 139662618720064] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3828.0391693115234, \"sum\": 3828.0391693115234, \"min\": 3828.0391693115234}}, \"EndTime\": 1601797841.078598, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797837.250117}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:41 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=164.830928407 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:41 INFO 139662618720064] #progress_metric: host=algo-1, completed 54 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:41 INFO 139662618720064] #quality_metric: host=algo-1, epoch=216, train loss <loss>=1.10701360106\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:41 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:41 INFO 139662618720064] Epoch[217] Batch[0] avg_epoch_loss=1.034986\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:41 INFO 139662618720064] #quality_metric: host=algo-1, epoch=217, batch=0 train loss <loss>=1.03498566151\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:43 INFO 139662618720064] Epoch[217] Batch[5] avg_epoch_loss=1.031743\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:43 INFO 139662618720064] #quality_metric: host=algo-1, epoch=217, batch=5 train loss <loss>=1.03174277147\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:43 INFO 139662618720064] Epoch[217] Batch [5]#011Speed: 188.10 samples/sec#011loss=1.031743\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:44 INFO 139662618720064] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3888.0879878997803, \"sum\": 3888.0879878997803, \"min\": 3888.0879878997803}}, \"EndTime\": 1601797844.9673, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797841.078683}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:44 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=160.999413613 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:44 INFO 139662618720064] #progress_metric: host=algo-1, completed 54 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:44 INFO 139662618720064] #quality_metric: host=algo-1, epoch=217, train loss <loss>=0.974860322475\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:44 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:45 INFO 139662618720064] Epoch[218] Batch[0] avg_epoch_loss=1.045344\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:45 INFO 139662618720064] #quality_metric: host=algo-1, epoch=218, batch=0 train loss <loss>=1.04534351826\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:47 INFO 139662618720064] Epoch[218] Batch[5] avg_epoch_loss=1.017589\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:47 INFO 139662618720064] #quality_metric: host=algo-1, epoch=218, batch=5 train loss <loss>=1.01758929094\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:47 INFO 139662618720064] Epoch[218] Batch [5]#011Speed: 190.33 samples/sec#011loss=1.017589\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:49 INFO 139662618720064] Epoch[218] Batch[10] avg_epoch_loss=1.223422\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:49 INFO 139662618720064] #quality_metric: host=algo-1, epoch=218, batch=10 train loss <loss>=1.4704204917\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:49 INFO 139662618720064] Epoch[218] Batch [10]#011Speed: 189.40 samples/sec#011loss=1.470420\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:49 INFO 139662618720064] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4182.145833969116, \"sum\": 4182.145833969116, \"min\": 4182.145833969116}}, \"EndTime\": 1601797849.150008, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797844.967385}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:49 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=153.744510832 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:49 INFO 139662618720064] #progress_metric: host=algo-1, completed 54 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:49 INFO 139662618720064] #quality_metric: host=algo-1, epoch=218, train loss <loss>=1.22342165492\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:49 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:49 INFO 139662618720064] Epoch[219] Batch[0] avg_epoch_loss=0.805876\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:49 INFO 139662618720064] #quality_metric: host=algo-1, epoch=219, batch=0 train loss <loss>=0.805876374245\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:51 INFO 139662618720064] Epoch[219] Batch[5] avg_epoch_loss=0.996165\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:51 INFO 139662618720064] #quality_metric: host=algo-1, epoch=219, batch=5 train loss <loss>=0.996164828539\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:51 INFO 139662618720064] Epoch[219] Batch [5]#011Speed: 189.14 samples/sec#011loss=0.996165\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:53 INFO 139662618720064] Epoch[219] Batch[10] avg_epoch_loss=1.009918\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:53 INFO 139662618720064] #quality_metric: host=algo-1, epoch=219, batch=10 train loss <loss>=1.02642121315\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:53 INFO 139662618720064] Epoch[219] Batch [10]#011Speed: 187.76 samples/sec#011loss=1.026421\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:53 INFO 139662618720064] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4198.239088058472, \"sum\": 4198.239088058472, \"min\": 4198.239088058472}}, \"EndTime\": 1601797853.34876, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797849.150087}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:53 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=154.107760704 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:53 INFO 139662618720064] #progress_metric: host=algo-1, completed 55 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:53 INFO 139662618720064] #quality_metric: host=algo-1, epoch=219, train loss <loss>=1.00991773063\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:53 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:54 INFO 139662618720064] Epoch[220] Batch[0] avg_epoch_loss=1.078479\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:54 INFO 139662618720064] #quality_metric: host=algo-1, epoch=220, batch=0 train loss <loss>=1.07847857475\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:55 INFO 139662618720064] Epoch[220] Batch[5] avg_epoch_loss=0.967103\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:55 INFO 139662618720064] #quality_metric: host=algo-1, epoch=220, batch=5 train loss <loss>=0.967103312413\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:55 INFO 139662618720064] Epoch[220] Batch [5]#011Speed: 189.06 samples/sec#011loss=0.967103\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:57 INFO 139662618720064] processed a total of 614 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3823.6098289489746, \"sum\": 3823.6098289489746, \"min\": 3823.6098289489746}}, \"EndTime\": 1601797857.172903, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797853.348839}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:57 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=160.575891282 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:57 INFO 139662618720064] #progress_metric: host=algo-1, completed 55 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:57 INFO 139662618720064] #quality_metric: host=algo-1, epoch=220, train loss <loss>=0.930718910694\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:57 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:57 INFO 139662618720064] Epoch[221] Batch[0] avg_epoch_loss=1.164644\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:57 INFO 139662618720064] #quality_metric: host=algo-1, epoch=221, batch=0 train loss <loss>=1.16464447975\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:59 INFO 139662618720064] Epoch[221] Batch[5] avg_epoch_loss=1.069768\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:59 INFO 139662618720064] #quality_metric: host=algo-1, epoch=221, batch=5 train loss <loss>=1.06976773341\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:50:59 INFO 139662618720064] Epoch[221] Batch [5]#011Speed: 187.17 samples/sec#011loss=1.069768\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:01 INFO 139662618720064] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3843.9700603485107, \"sum\": 3843.9700603485107, \"min\": 3843.9700603485107}}, \"EndTime\": 1601797861.01743, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797857.172989}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:01 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=166.489121987 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:01 INFO 139662618720064] #progress_metric: host=algo-1, completed 55 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:01 INFO 139662618720064] #quality_metric: host=algo-1, epoch=221, train loss <loss>=1.03877309561\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:01 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:01 INFO 139662618720064] Epoch[222] Batch[0] avg_epoch_loss=0.947540\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:01 INFO 139662618720064] #quality_metric: host=algo-1, epoch=222, batch=0 train loss <loss>=0.947540462017\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:03 INFO 139662618720064] Epoch[222] Batch[5] avg_epoch_loss=1.044940\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:03 INFO 139662618720064] #quality_metric: host=algo-1, epoch=222, batch=5 train loss <loss>=1.04493977626\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:03 INFO 139662618720064] Epoch[222] Batch [5]#011Speed: 188.68 samples/sec#011loss=1.044940\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:05 INFO 139662618720064] Epoch[222] Batch[10] avg_epoch_loss=1.239250\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:05 INFO 139662618720064] #quality_metric: host=algo-1, epoch=222, batch=10 train loss <loss>=1.47242319584\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:05 INFO 139662618720064] Epoch[222] Batch [10]#011Speed: 188.11 samples/sec#011loss=1.472423\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:05 INFO 139662618720064] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4209.683895111084, \"sum\": 4209.683895111084, \"min\": 4209.683895111084}}, \"EndTime\": 1601797865.227669, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797861.017514}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:05 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=153.688898021 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:05 INFO 139662618720064] #progress_metric: host=algo-1, completed 55 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:05 INFO 139662618720064] #quality_metric: host=algo-1, epoch=222, train loss <loss>=1.23925042152\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:05 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:06 INFO 139662618720064] Epoch[223] Batch[0] avg_epoch_loss=0.927538\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:06 INFO 139662618720064] #quality_metric: host=algo-1, epoch=223, batch=0 train loss <loss>=0.9275380373\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:07 INFO 139662618720064] Epoch[223] Batch[5] avg_epoch_loss=1.038236\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:07 INFO 139662618720064] #quality_metric: host=algo-1, epoch=223, batch=5 train loss <loss>=1.03823590279\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:07 INFO 139662618720064] Epoch[223] Batch [5]#011Speed: 188.60 samples/sec#011loss=1.038236\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:09 INFO 139662618720064] Epoch[223] Batch[10] avg_epoch_loss=0.943108\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:09 INFO 139662618720064] #quality_metric: host=algo-1, epoch=223, batch=10 train loss <loss>=0.828954148293\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:09 INFO 139662618720064] Epoch[223] Batch [10]#011Speed: 187.95 samples/sec#011loss=0.828954\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:09 INFO 139662618720064] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4213.370084762573, \"sum\": 4213.370084762573, \"min\": 4213.370084762573}}, \"EndTime\": 1601797869.44158, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797865.227749}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:09 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=155.453115305 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:09 INFO 139662618720064] #progress_metric: host=algo-1, completed 56 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:09 INFO 139662618720064] #quality_metric: host=algo-1, epoch=223, train loss <loss>=0.943107832562\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:09 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:10 INFO 139662618720064] Epoch[224] Batch[0] avg_epoch_loss=0.866116\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:10 INFO 139662618720064] #quality_metric: host=algo-1, epoch=224, batch=0 train loss <loss>=0.866116285324\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:11 INFO 139662618720064] Epoch[224] Batch[5] avg_epoch_loss=1.015896\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:11 INFO 139662618720064] #quality_metric: host=algo-1, epoch=224, batch=5 train loss <loss>=1.01589558522\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:11 INFO 139662618720064] Epoch[224] Batch [5]#011Speed: 187.82 samples/sec#011loss=1.015896\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:13 INFO 139662618720064] processed a total of 594 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3851.883888244629, \"sum\": 3851.883888244629, \"min\": 3851.883888244629}}, \"EndTime\": 1601797873.293991, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797869.441661}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:13 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=154.205359396 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:13 INFO 139662618720064] #progress_metric: host=algo-1, completed 56 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:13 INFO 139662618720064] #quality_metric: host=algo-1, epoch=224, train loss <loss>=1.02170011997\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:13 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:14 INFO 139662618720064] Epoch[225] Batch[0] avg_epoch_loss=1.392941\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:14 INFO 139662618720064] #quality_metric: host=algo-1, epoch=225, batch=0 train loss <loss>=1.39294064045\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:15 INFO 139662618720064] Epoch[225] Batch[5] avg_epoch_loss=1.149505\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:15 INFO 139662618720064] #quality_metric: host=algo-1, epoch=225, batch=5 train loss <loss>=1.14950495958\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:15 INFO 139662618720064] Epoch[225] Batch [5]#011Speed: 186.82 samples/sec#011loss=1.149505\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:17 INFO 139662618720064] Epoch[225] Batch[10] avg_epoch_loss=1.048665\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:17 INFO 139662618720064] #quality_metric: host=algo-1, epoch=225, batch=10 train loss <loss>=0.927655994892\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:17 INFO 139662618720064] Epoch[225] Batch [10]#011Speed: 189.94 samples/sec#011loss=0.927656\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:17 INFO 139662618720064] processed a total of 678 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4221.0729122161865, \"sum\": 4221.0729122161865, \"min\": 4221.0729122161865}}, \"EndTime\": 1601797877.515707, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797873.294072}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:17 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=160.618097283 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:17 INFO 139662618720064] #progress_metric: host=algo-1, completed 56 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:17 INFO 139662618720064] #quality_metric: host=algo-1, epoch=225, train loss <loss>=1.04866452109\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:17 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:18 INFO 139662618720064] Epoch[226] Batch[0] avg_epoch_loss=1.082202\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:18 INFO 139662618720064] #quality_metric: host=algo-1, epoch=226, batch=0 train loss <loss>=1.08220160007\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:20 INFO 139662618720064] Epoch[226] Batch[5] avg_epoch_loss=1.064861\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:20 INFO 139662618720064] #quality_metric: host=algo-1, epoch=226, batch=5 train loss <loss>=1.0648612082\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:20 INFO 139662618720064] Epoch[226] Batch [5]#011Speed: 183.89 samples/sec#011loss=1.064861\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:21 INFO 139662618720064] Epoch[226] Batch[10] avg_epoch_loss=0.934013\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:21 INFO 139662618720064] #quality_metric: host=algo-1, epoch=226, batch=10 train loss <loss>=0.77699624151\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:21 INFO 139662618720064] Epoch[226] Batch [10]#011Speed: 189.37 samples/sec#011loss=0.776996\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:21 INFO 139662618720064] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4241.818904876709, \"sum\": 4241.818904876709, \"min\": 4241.818904876709}}, \"EndTime\": 1601797881.75802, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797877.515787}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:21 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=152.524628826 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:21 INFO 139662618720064] #progress_metric: host=algo-1, completed 56 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:21 INFO 139662618720064] #quality_metric: host=algo-1, epoch=226, train loss <loss>=0.934013496068\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:21 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:22 INFO 139662618720064] Epoch[227] Batch[0] avg_epoch_loss=1.054241\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:22 INFO 139662618720064] #quality_metric: host=algo-1, epoch=227, batch=0 train loss <loss>=1.05424106121\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:24 INFO 139662618720064] Epoch[227] Batch[5] avg_epoch_loss=1.015078\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:24 INFO 139662618720064] #quality_metric: host=algo-1, epoch=227, batch=5 train loss <loss>=1.01507812738\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:24 INFO 139662618720064] Epoch[227] Batch [5]#011Speed: 188.28 samples/sec#011loss=1.015078\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:25 INFO 139662618720064] processed a total of 616 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3898.9410400390625, \"sum\": 3898.9410400390625, \"min\": 3898.9410400390625}}, \"EndTime\": 1601797885.657481, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797881.7581}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:25 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=157.986477579 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:25 INFO 139662618720064] #progress_metric: host=algo-1, completed 57 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:25 INFO 139662618720064] #quality_metric: host=algo-1, epoch=227, train loss <loss>=1.01944906116\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:25 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:26 INFO 139662618720064] Epoch[228] Batch[0] avg_epoch_loss=1.098917\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:26 INFO 139662618720064] #quality_metric: host=algo-1, epoch=228, batch=0 train loss <loss>=1.09891748428\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:28 INFO 139662618720064] Epoch[228] Batch[5] avg_epoch_loss=1.006985\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:28 INFO 139662618720064] #quality_metric: host=algo-1, epoch=228, batch=5 train loss <loss>=1.00698540608\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:28 INFO 139662618720064] Epoch[228] Batch [5]#011Speed: 189.04 samples/sec#011loss=1.006985\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:29 INFO 139662618720064] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3863.8288974761963, \"sum\": 3863.8288974761963, \"min\": 3863.8288974761963}}, \"EndTime\": 1601797889.521974, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797885.657567}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:29 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=165.115579723 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:29 INFO 139662618720064] #progress_metric: host=algo-1, completed 57 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:29 INFO 139662618720064] #quality_metric: host=algo-1, epoch=228, train loss <loss>=0.976687169075\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:29 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:30 INFO 139662618720064] Epoch[229] Batch[0] avg_epoch_loss=1.033964\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:30 INFO 139662618720064] #quality_metric: host=algo-1, epoch=229, batch=0 train loss <loss>=1.03396391869\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:32 INFO 139662618720064] Epoch[229] Batch[5] avg_epoch_loss=0.917382\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:32 INFO 139662618720064] #quality_metric: host=algo-1, epoch=229, batch=5 train loss <loss>=0.917381882668\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:32 INFO 139662618720064] Epoch[229] Batch [5]#011Speed: 188.37 samples/sec#011loss=0.917382\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:33 INFO 139662618720064] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3836.958169937134, \"sum\": 3836.958169937134, \"min\": 3836.958169937134}}, \"EndTime\": 1601797893.359525, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797889.522061}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:33 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=163.144637923 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:33 INFO 139662618720064] #progress_metric: host=algo-1, completed 57 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:33 INFO 139662618720064] #quality_metric: host=algo-1, epoch=229, train loss <loss>=0.90946546793\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:33 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:34 INFO 139662618720064] Epoch[230] Batch[0] avg_epoch_loss=0.801416\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:34 INFO 139662618720064] #quality_metric: host=algo-1, epoch=230, batch=0 train loss <loss>=0.801415741444\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:35 INFO 139662618720064] Epoch[230] Batch[5] avg_epoch_loss=0.923234\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:35 INFO 139662618720064] #quality_metric: host=algo-1, epoch=230, batch=5 train loss <loss>=0.923234343529\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:35 INFO 139662618720064] Epoch[230] Batch [5]#011Speed: 185.64 samples/sec#011loss=0.923234\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:37 INFO 139662618720064] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3881.263017654419, \"sum\": 3881.263017654419, \"min\": 3881.263017654419}}, \"EndTime\": 1601797897.241413, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797893.35961}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:37 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=161.540112502 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:37 INFO 139662618720064] #progress_metric: host=algo-1, completed 57 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:37 INFO 139662618720064] #quality_metric: host=algo-1, epoch=230, train loss <loss>=0.952119189501\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:37 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:38 INFO 139662618720064] Epoch[231] Batch[0] avg_epoch_loss=0.815556\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:38 INFO 139662618720064] #quality_metric: host=algo-1, epoch=231, batch=0 train loss <loss>=0.815556228161\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:39 INFO 139662618720064] Epoch[231] Batch[5] avg_epoch_loss=0.906896\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:39 INFO 139662618720064] #quality_metric: host=algo-1, epoch=231, batch=5 train loss <loss>=0.906895875931\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:39 INFO 139662618720064] Epoch[231] Batch [5]#011Speed: 186.20 samples/sec#011loss=0.906896\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:41 INFO 139662618720064] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3856.6958904266357, \"sum\": 3856.6958904266357, \"min\": 3856.6958904266357}}, \"EndTime\": 1601797901.098639, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797897.241495}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:41 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=164.38472494 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:41 INFO 139662618720064] #progress_metric: host=algo-1, completed 58 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:41 INFO 139662618720064] #quality_metric: host=algo-1, epoch=231, train loss <loss>=0.904027360678\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:41 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:41 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_08944727-bfc3-4508-aa52-672ca234782f-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 101.58109664916992, \"sum\": 101.58109664916992, \"min\": 101.58109664916992}}, \"EndTime\": 1601797901.200901, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797901.098711}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:41 INFO 139662618720064] Epoch[232] Batch[0] avg_epoch_loss=0.704691\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:41 INFO 139662618720064] #quality_metric: host=algo-1, epoch=232, batch=0 train loss <loss>=0.704690933228\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:43 INFO 139662618720064] Epoch[232] Batch[5] avg_epoch_loss=0.945711\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:43 INFO 139662618720064] #quality_metric: host=algo-1, epoch=232, batch=5 train loss <loss>=0.945710539818\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:43 INFO 139662618720064] Epoch[232] Batch [5]#011Speed: 188.95 samples/sec#011loss=0.945711\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:45 INFO 139662618720064] Epoch[232] Batch[10] avg_epoch_loss=0.898207\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:45 INFO 139662618720064] #quality_metric: host=algo-1, epoch=232, batch=10 train loss <loss>=0.841202771664\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:45 INFO 139662618720064] Epoch[232] Batch [10]#011Speed: 185.02 samples/sec#011loss=0.841203\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:45 INFO 139662618720064] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4207.341909408569, \"sum\": 4207.341909408569, \"min\": 4207.341909408569}}, \"EndTime\": 1601797905.408367, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797901.20096}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:45 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=157.814859933 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:45 INFO 139662618720064] #progress_metric: host=algo-1, completed 58 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:45 INFO 139662618720064] #quality_metric: host=algo-1, epoch=232, train loss <loss>=0.898207008839\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:45 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:45 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_7ff74d80-657b-4244-a4bc-16a9a130698b-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 112.77008056640625, \"sum\": 112.77008056640625, \"min\": 112.77008056640625}}, \"EndTime\": 1601797905.52173, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797905.408448}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:46 INFO 139662618720064] Epoch[233] Batch[0] avg_epoch_loss=1.024590\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:46 INFO 139662618720064] #quality_metric: host=algo-1, epoch=233, batch=0 train loss <loss>=1.02458977699\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:47 INFO 139662618720064] Epoch[233] Batch[5] avg_epoch_loss=1.044337\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:47 INFO 139662618720064] #quality_metric: host=algo-1, epoch=233, batch=5 train loss <loss>=1.04433674614\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:47 INFO 139662618720064] Epoch[233] Batch [5]#011Speed: 190.13 samples/sec#011loss=1.044337\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:49 INFO 139662618720064] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3839.1129970550537, \"sum\": 3839.1129970550537, \"min\": 3839.1129970550537}}, \"EndTime\": 1601797909.360977, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797905.521799}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:49 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=165.918344182 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:49 INFO 139662618720064] #progress_metric: host=algo-1, completed 58 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:49 INFO 139662618720064] #quality_metric: host=algo-1, epoch=233, train loss <loss>=1.02165077925\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:49 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:50 INFO 139662618720064] Epoch[234] Batch[0] avg_epoch_loss=0.786611\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:50 INFO 139662618720064] #quality_metric: host=algo-1, epoch=234, batch=0 train loss <loss>=0.786610543728\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:51 INFO 139662618720064] Epoch[234] Batch[5] avg_epoch_loss=0.894434\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:51 INFO 139662618720064] #quality_metric: host=algo-1, epoch=234, batch=5 train loss <loss>=0.894433617592\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:51 INFO 139662618720064] Epoch[234] Batch [5]#011Speed: 187.28 samples/sec#011loss=0.894434\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:53 INFO 139662618720064] Epoch[234] Batch[10] avg_epoch_loss=1.003823\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:53 INFO 139662618720064] #quality_metric: host=algo-1, epoch=234, batch=10 train loss <loss>=1.13509093523\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:53 INFO 139662618720064] Epoch[234] Batch [10]#011Speed: 190.15 samples/sec#011loss=1.135091\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:53 INFO 139662618720064] processed a total of 680 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4202.5158405303955, \"sum\": 4202.5158405303955, \"min\": 4202.5158405303955}}, \"EndTime\": 1601797913.564056, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797909.361062}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:53 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=161.80324771 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:53 INFO 139662618720064] #progress_metric: host=algo-1, completed 58 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:53 INFO 139662618720064] #quality_metric: host=algo-1, epoch=234, train loss <loss>=1.00382330743\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:53 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:54 INFO 139662618720064] Epoch[235] Batch[0] avg_epoch_loss=1.064305\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:54 INFO 139662618720064] #quality_metric: host=algo-1, epoch=235, batch=0 train loss <loss>=1.06430459023\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:56 INFO 139662618720064] Epoch[235] Batch[5] avg_epoch_loss=1.149817\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:56 INFO 139662618720064] #quality_metric: host=algo-1, epoch=235, batch=5 train loss <loss>=1.14981681108\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:56 INFO 139662618720064] Epoch[235] Batch [5]#011Speed: 188.81 samples/sec#011loss=1.149817\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:57 INFO 139662618720064] processed a total of 609 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3904.834985733032, \"sum\": 3904.834985733032, \"min\": 3904.834985733032}}, \"EndTime\": 1601797917.469434, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797913.564135}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:57 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=155.955496535 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:57 INFO 139662618720064] #progress_metric: host=algo-1, completed 59 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:57 INFO 139662618720064] #quality_metric: host=algo-1, epoch=235, train loss <loss>=1.10092975497\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:57 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:58 INFO 139662618720064] Epoch[236] Batch[0] avg_epoch_loss=0.757991\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:58 INFO 139662618720064] #quality_metric: host=algo-1, epoch=236, batch=0 train loss <loss>=0.757990837097\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:59 INFO 139662618720064] Epoch[236] Batch[5] avg_epoch_loss=1.077284\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:59 INFO 139662618720064] #quality_metric: host=algo-1, epoch=236, batch=5 train loss <loss>=1.07728397846\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:51:59 INFO 139662618720064] Epoch[236] Batch [5]#011Speed: 186.13 samples/sec#011loss=1.077284\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:01 INFO 139662618720064] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3870.5859184265137, \"sum\": 3870.5859184265137, \"min\": 3870.5859184265137}}, \"EndTime\": 1601797921.340596, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797917.469518}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:01 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=162.244640122 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:01 INFO 139662618720064] #progress_metric: host=algo-1, completed 59 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:01 INFO 139662618720064] #quality_metric: host=algo-1, epoch=236, train loss <loss>=1.01564584374\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:01 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:02 INFO 139662618720064] Epoch[237] Batch[0] avg_epoch_loss=1.034215\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:02 INFO 139662618720064] #quality_metric: host=algo-1, epoch=237, batch=0 train loss <loss>=1.03421461582\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:03 INFO 139662618720064] Epoch[237] Batch[5] avg_epoch_loss=1.034739\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:03 INFO 139662618720064] #quality_metric: host=algo-1, epoch=237, batch=5 train loss <loss>=1.03473895788\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:03 INFO 139662618720064] Epoch[237] Batch [5]#011Speed: 188.49 samples/sec#011loss=1.034739\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:05 INFO 139662618720064] Epoch[237] Batch[10] avg_epoch_loss=1.018241\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:05 INFO 139662618720064] #quality_metric: host=algo-1, epoch=237, batch=10 train loss <loss>=0.998444354534\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:05 INFO 139662618720064] Epoch[237] Batch [10]#011Speed: 185.15 samples/sec#011loss=0.998444\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:05 INFO 139662618720064] processed a total of 673 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4229.981184005737, \"sum\": 4229.981184005737, \"min\": 4229.981184005737}}, \"EndTime\": 1601797925.571138, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797921.340674}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:05 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=159.09786094 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:05 INFO 139662618720064] #progress_metric: host=algo-1, completed 59 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:05 INFO 139662618720064] #quality_metric: host=algo-1, epoch=237, train loss <loss>=1.01824141091\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:05 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:06 INFO 139662618720064] Epoch[238] Batch[0] avg_epoch_loss=0.951941\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:06 INFO 139662618720064] #quality_metric: host=algo-1, epoch=238, batch=0 train loss <loss>=0.95194119215\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:08 INFO 139662618720064] Epoch[238] Batch[5] avg_epoch_loss=1.056194\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:08 INFO 139662618720064] #quality_metric: host=algo-1, epoch=238, batch=5 train loss <loss>=1.05619350076\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:08 INFO 139662618720064] Epoch[238] Batch [5]#011Speed: 187.44 samples/sec#011loss=1.056194\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:09 INFO 139662618720064] Epoch[238] Batch[10] avg_epoch_loss=0.976587\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:09 INFO 139662618720064] #quality_metric: host=algo-1, epoch=238, batch=10 train loss <loss>=0.881059348583\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:09 INFO 139662618720064] Epoch[238] Batch [10]#011Speed: 187.11 samples/sec#011loss=0.881059\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:09 INFO 139662618720064] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4209.287881851196, \"sum\": 4209.287881851196, \"min\": 4209.287881851196}}, \"EndTime\": 1601797929.781007, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797925.571215}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:09 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=156.31677276 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:09 INFO 139662618720064] #progress_metric: host=algo-1, completed 59 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:09 INFO 139662618720064] #quality_metric: host=algo-1, epoch=238, train loss <loss>=0.976587067951\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:09 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:10 INFO 139662618720064] Epoch[239] Batch[0] avg_epoch_loss=1.031090\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:10 INFO 139662618720064] #quality_metric: host=algo-1, epoch=239, batch=0 train loss <loss>=1.03109002113\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:12 INFO 139662618720064] Epoch[239] Batch[5] avg_epoch_loss=0.901150\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:12 INFO 139662618720064] #quality_metric: host=algo-1, epoch=239, batch=5 train loss <loss>=0.901149551074\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:12 INFO 139662618720064] Epoch[239] Batch [5]#011Speed: 187.58 samples/sec#011loss=0.901150\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:14 INFO 139662618720064] Epoch[239] Batch[10] avg_epoch_loss=0.956462\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:14 INFO 139662618720064] #quality_metric: host=algo-1, epoch=239, batch=10 train loss <loss>=1.02283598185\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:14 INFO 139662618720064] Epoch[239] Batch [10]#011Speed: 183.53 samples/sec#011loss=1.022836\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:14 INFO 139662618720064] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4283.007860183716, \"sum\": 4283.007860183716, \"min\": 4283.007860183716}}, \"EndTime\": 1601797934.064502, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797929.781082}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:14 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=153.3929934 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:14 INFO 139662618720064] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:14 INFO 139662618720064] #quality_metric: host=algo-1, epoch=239, train loss <loss>=0.956461565061\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:14 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:14 INFO 139662618720064] Epoch[240] Batch[0] avg_epoch_loss=1.073582\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:14 INFO 139662618720064] #quality_metric: host=algo-1, epoch=240, batch=0 train loss <loss>=1.07358217239\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:16 INFO 139662618720064] Epoch[240] Batch[5] avg_epoch_loss=0.958483\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:16 INFO 139662618720064] #quality_metric: host=algo-1, epoch=240, batch=5 train loss <loss>=0.958483139674\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:16 INFO 139662618720064] Epoch[240] Batch [5]#011Speed: 190.01 samples/sec#011loss=0.958483\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:17 INFO 139662618720064] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3841.853141784668, \"sum\": 3841.853141784668, \"min\": 3841.853141784668}}, \"EndTime\": 1601797937.906954, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797934.064575}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:17 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=166.060302128 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:17 INFO 139662618720064] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:17 INFO 139662618720064] #quality_metric: host=algo-1, epoch=240, train loss <loss>=0.943470549583\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:17 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:18 INFO 139662618720064] Epoch[241] Batch[0] avg_epoch_loss=1.154186\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:18 INFO 139662618720064] #quality_metric: host=algo-1, epoch=241, batch=0 train loss <loss>=1.15418624878\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:20 INFO 139662618720064] Epoch[241] Batch[5] avg_epoch_loss=0.998227\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:20 INFO 139662618720064] #quality_metric: host=algo-1, epoch=241, batch=5 train loss <loss>=0.998226662477\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:20 INFO 139662618720064] Epoch[241] Batch [5]#011Speed: 183.30 samples/sec#011loss=0.998227\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:21 INFO 139662618720064] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3928.4019470214844, \"sum\": 3928.4019470214844, \"min\": 3928.4019470214844}}, \"EndTime\": 1601797941.835923, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797937.907038}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:21 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=161.128884807 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:21 INFO 139662618720064] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:21 INFO 139662618720064] #quality_metric: host=algo-1, epoch=241, train loss <loss>=1.01503701806\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:21 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:22 INFO 139662618720064] Epoch[242] Batch[0] avg_epoch_loss=0.793668\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:22 INFO 139662618720064] #quality_metric: host=algo-1, epoch=242, batch=0 train loss <loss>=0.793667554855\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:24 INFO 139662618720064] Epoch[242] Batch[5] avg_epoch_loss=1.003432\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:24 INFO 139662618720064] #quality_metric: host=algo-1, epoch=242, batch=5 train loss <loss>=1.00343238314\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:24 INFO 139662618720064] Epoch[242] Batch [5]#011Speed: 188.97 samples/sec#011loss=1.003432\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:25 INFO 139662618720064] processed a total of 598 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3869.7409629821777, \"sum\": 3869.7409629821777, \"min\": 3869.7409629821777}}, \"EndTime\": 1601797945.706321, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797941.836011}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:25 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=154.527309082 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:25 INFO 139662618720064] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:25 INFO 139662618720064] #quality_metric: host=algo-1, epoch=242, train loss <loss>=1.15928781033\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:25 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:26 INFO 139662618720064] Epoch[243] Batch[0] avg_epoch_loss=1.070764\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:26 INFO 139662618720064] #quality_metric: host=algo-1, epoch=243, batch=0 train loss <loss>=1.07076358795\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:28 INFO 139662618720064] Epoch[243] Batch[5] avg_epoch_loss=0.947864\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:28 INFO 139662618720064] #quality_metric: host=algo-1, epoch=243, batch=5 train loss <loss>=0.94786392649\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:28 INFO 139662618720064] Epoch[243] Batch [5]#011Speed: 186.40 samples/sec#011loss=0.947864\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:29 INFO 139662618720064] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3912.069797515869, \"sum\": 3912.069797515869, \"min\": 3912.069797515869}}, \"EndTime\": 1601797949.618988, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797945.706406}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:29 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=161.034870016 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:29 INFO 139662618720064] #progress_metric: host=algo-1, completed 61 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:29 INFO 139662618720064] #quality_metric: host=algo-1, epoch=243, train loss <loss>=0.939613741636\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:29 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:30 INFO 139662618720064] Epoch[244] Batch[0] avg_epoch_loss=1.122780\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:30 INFO 139662618720064] #quality_metric: host=algo-1, epoch=244, batch=0 train loss <loss>=1.12278008461\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:32 INFO 139662618720064] Epoch[244] Batch[5] avg_epoch_loss=0.991978\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:32 INFO 139662618720064] #quality_metric: host=algo-1, epoch=244, batch=5 train loss <loss>=0.991978456577\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:32 INFO 139662618720064] Epoch[244] Batch [5]#011Speed: 189.67 samples/sec#011loss=0.991978\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:33 INFO 139662618720064] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3841.356039047241, \"sum\": 3841.356039047241, \"min\": 3841.356039047241}}, \"EndTime\": 1601797953.460929, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797949.619072}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:33 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=166.602371859 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:33 INFO 139662618720064] #progress_metric: host=algo-1, completed 61 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:33 INFO 139662618720064] #quality_metric: host=algo-1, epoch=244, train loss <loss>=1.023189044\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:33 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:34 INFO 139662618720064] Epoch[245] Batch[0] avg_epoch_loss=1.106902\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:34 INFO 139662618720064] #quality_metric: host=algo-1, epoch=245, batch=0 train loss <loss>=1.10690236092\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:35 INFO 139662618720064] Epoch[245] Batch[5] avg_epoch_loss=1.040990\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:35 INFO 139662618720064] #quality_metric: host=algo-1, epoch=245, batch=5 train loss <loss>=1.04099029303\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:35 INFO 139662618720064] Epoch[245] Batch [5]#011Speed: 183.88 samples/sec#011loss=1.040990\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:37 INFO 139662618720064] processed a total of 615 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3893.9719200134277, \"sum\": 3893.9719200134277, \"min\": 3893.9719200134277}}, \"EndTime\": 1601797957.355461, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797953.461013}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:37 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=157.930535095 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:37 INFO 139662618720064] #progress_metric: host=algo-1, completed 61 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:37 INFO 139662618720064] #quality_metric: host=algo-1, epoch=245, train loss <loss>=1.01106852293\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:37 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:38 INFO 139662618720064] Epoch[246] Batch[0] avg_epoch_loss=0.900485\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:38 INFO 139662618720064] #quality_metric: host=algo-1, epoch=246, batch=0 train loss <loss>=0.900485277176\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:39 INFO 139662618720064] Epoch[246] Batch[5] avg_epoch_loss=0.854131\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:39 INFO 139662618720064] #quality_metric: host=algo-1, epoch=246, batch=5 train loss <loss>=0.854131480058\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:39 INFO 139662618720064] Epoch[246] Batch [5]#011Speed: 185.93 samples/sec#011loss=0.854131\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:41 INFO 139662618720064] Epoch[246] Batch[10] avg_epoch_loss=0.967345\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:41 INFO 139662618720064] #quality_metric: host=algo-1, epoch=246, batch=10 train loss <loss>=1.10320175886\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:41 INFO 139662618720064] Epoch[246] Batch [10]#011Speed: 185.80 samples/sec#011loss=1.103202\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:41 INFO 139662618720064] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4250.526189804077, \"sum\": 4250.526189804077, \"min\": 4250.526189804077}}, \"EndTime\": 1601797961.606576, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797957.355564}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:41 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=153.153041147 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:41 INFO 139662618720064] #progress_metric: host=algo-1, completed 61 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:41 INFO 139662618720064] #quality_metric: host=algo-1, epoch=246, train loss <loss>=0.967345243151\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:41 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:42 INFO 139662618720064] Epoch[247] Batch[0] avg_epoch_loss=0.896509\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:42 INFO 139662618720064] #quality_metric: host=algo-1, epoch=247, batch=0 train loss <loss>=0.896509349346\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:44 INFO 139662618720064] Epoch[247] Batch[5] avg_epoch_loss=0.977453\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:44 INFO 139662618720064] #quality_metric: host=algo-1, epoch=247, batch=5 train loss <loss>=0.977452894052\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:44 INFO 139662618720064] Epoch[247] Batch [5]#011Speed: 187.65 samples/sec#011loss=0.977453\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:45 INFO 139662618720064] processed a total of 594 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3898.030996322632, \"sum\": 3898.030996322632, \"min\": 3898.030996322632}}, \"EndTime\": 1601797965.505197, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797961.60666}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:45 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=152.379734083 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:45 INFO 139662618720064] #progress_metric: host=algo-1, completed 62 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:45 INFO 139662618720064] #quality_metric: host=algo-1, epoch=247, train loss <loss>=0.944955331087\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:45 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:46 INFO 139662618720064] Epoch[248] Batch[0] avg_epoch_loss=1.078641\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:46 INFO 139662618720064] #quality_metric: host=algo-1, epoch=248, batch=0 train loss <loss>=1.07864141464\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:47 INFO 139662618720064] Epoch[248] Batch[5] avg_epoch_loss=1.060732\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:47 INFO 139662618720064] #quality_metric: host=algo-1, epoch=248, batch=5 train loss <loss>=1.06073187788\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:47 INFO 139662618720064] Epoch[248] Batch [5]#011Speed: 188.60 samples/sec#011loss=1.060732\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:49 INFO 139662618720064] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3839.5020961761475, \"sum\": 3839.5020961761475, \"min\": 3839.5020961761475}}, \"EndTime\": 1601797969.345262, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797965.505282}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:49 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=166.162281887 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:49 INFO 139662618720064] #progress_metric: host=algo-1, completed 62 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:49 INFO 139662618720064] #quality_metric: host=algo-1, epoch=248, train loss <loss>=0.987936598063\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:49 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:50 INFO 139662618720064] Epoch[249] Batch[0] avg_epoch_loss=1.001439\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:50 INFO 139662618720064] #quality_metric: host=algo-1, epoch=249, batch=0 train loss <loss>=1.00143897533\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:51 INFO 139662618720064] Epoch[249] Batch[5] avg_epoch_loss=0.971703\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:51 INFO 139662618720064] #quality_metric: host=algo-1, epoch=249, batch=5 train loss <loss>=0.971702943246\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:51 INFO 139662618720064] Epoch[249] Batch [5]#011Speed: 189.52 samples/sec#011loss=0.971703\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:52 INFO 139662618720064] processed a total of 576 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3541.7351722717285, \"sum\": 3541.7351722717285, \"min\": 3541.7351722717285}}, \"EndTime\": 1601797972.887593, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797969.345341}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:52 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=162.626324294 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:52 INFO 139662618720064] #progress_metric: host=algo-1, completed 62 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:52 INFO 139662618720064] #quality_metric: host=algo-1, epoch=249, train loss <loss>=0.967002120283\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:52 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:53 INFO 139662618720064] Epoch[250] Batch[0] avg_epoch_loss=0.934610\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:53 INFO 139662618720064] #quality_metric: host=algo-1, epoch=250, batch=0 train loss <loss>=0.934610366821\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:55 INFO 139662618720064] Epoch[250] Batch[5] avg_epoch_loss=1.000840\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:55 INFO 139662618720064] #quality_metric: host=algo-1, epoch=250, batch=5 train loss <loss>=1.00083997846\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:55 INFO 139662618720064] Epoch[250] Batch [5]#011Speed: 187.36 samples/sec#011loss=1.000840\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:57 INFO 139662618720064] Epoch[250] Batch[10] avg_epoch_loss=0.988887\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:57 INFO 139662618720064] #quality_metric: host=algo-1, epoch=250, batch=10 train loss <loss>=0.974544227123\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:57 INFO 139662618720064] Epoch[250] Batch [10]#011Speed: 189.24 samples/sec#011loss=0.974544\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:57 INFO 139662618720064] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4213.363885879517, \"sum\": 4213.363885879517, \"min\": 4213.363885879517}}, \"EndTime\": 1601797977.101521, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797972.887679}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:57 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=156.87741512 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:57 INFO 139662618720064] #progress_metric: host=algo-1, completed 62 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:57 INFO 139662618720064] #quality_metric: host=algo-1, epoch=250, train loss <loss>=0.988887364214\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:57 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:57 INFO 139662618720064] Epoch[251] Batch[0] avg_epoch_loss=1.109599\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:57 INFO 139662618720064] #quality_metric: host=algo-1, epoch=251, batch=0 train loss <loss>=1.10959947109\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:59 INFO 139662618720064] Epoch[251] Batch[5] avg_epoch_loss=0.981522\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:59 INFO 139662618720064] #quality_metric: host=algo-1, epoch=251, batch=5 train loss <loss>=0.981522123019\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:52:59 INFO 139662618720064] Epoch[251] Batch [5]#011Speed: 186.52 samples/sec#011loss=0.981522\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:01 INFO 139662618720064] Epoch[251] Batch[10] avg_epoch_loss=0.958176\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:01 INFO 139662618720064] #quality_metric: host=algo-1, epoch=251, batch=10 train loss <loss>=0.930160558224\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:01 INFO 139662618720064] Epoch[251] Batch [10]#011Speed: 185.93 samples/sec#011loss=0.930161\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:01 INFO 139662618720064] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4248.615026473999, \"sum\": 4248.615026473999, \"min\": 4248.615026473999}}, \"EndTime\": 1601797981.350698, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797977.1016}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:01 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=152.280801202 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:01 INFO 139662618720064] #progress_metric: host=algo-1, completed 63 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:01 INFO 139662618720064] #quality_metric: host=algo-1, epoch=251, train loss <loss>=0.958175957203\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:01 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:02 INFO 139662618720064] Epoch[252] Batch[0] avg_epoch_loss=1.109079\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:02 INFO 139662618720064] #quality_metric: host=algo-1, epoch=252, batch=0 train loss <loss>=1.10907876492\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:03 INFO 139662618720064] Epoch[252] Batch[5] avg_epoch_loss=1.021350\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:03 INFO 139662618720064] #quality_metric: host=algo-1, epoch=252, batch=5 train loss <loss>=1.02135013541\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:03 INFO 139662618720064] Epoch[252] Batch [5]#011Speed: 188.22 samples/sec#011loss=1.021350\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:05 INFO 139662618720064] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3864.081859588623, \"sum\": 3864.081859588623, \"min\": 3864.081859588623}}, \"EndTime\": 1601797985.215415, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797981.350775}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:05 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=164.847562389 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:05 INFO 139662618720064] #progress_metric: host=algo-1, completed 63 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:05 INFO 139662618720064] #quality_metric: host=algo-1, epoch=252, train loss <loss>=0.99785143733\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:05 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:06 INFO 139662618720064] Epoch[253] Batch[0] avg_epoch_loss=0.958081\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:06 INFO 139662618720064] #quality_metric: host=algo-1, epoch=253, batch=0 train loss <loss>=0.958081305027\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:07 INFO 139662618720064] Epoch[253] Batch[5] avg_epoch_loss=1.006330\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:07 INFO 139662618720064] #quality_metric: host=algo-1, epoch=253, batch=5 train loss <loss>=1.00633010268\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:07 INFO 139662618720064] Epoch[253] Batch [5]#011Speed: 187.18 samples/sec#011loss=1.006330\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:09 INFO 139662618720064] Epoch[253] Batch[10] avg_epoch_loss=0.985896\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:09 INFO 139662618720064] #quality_metric: host=algo-1, epoch=253, batch=10 train loss <loss>=0.961375463009\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:09 INFO 139662618720064] Epoch[253] Batch [10]#011Speed: 187.57 samples/sec#011loss=0.961375\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:09 INFO 139662618720064] processed a total of 682 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4212.322950363159, \"sum\": 4212.322950363159, \"min\": 4212.322950363159}}, \"EndTime\": 1601797989.428307, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797985.215476}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:09 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=161.900993757 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:09 INFO 139662618720064] #progress_metric: host=algo-1, completed 63 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:09 INFO 139662618720064] #quality_metric: host=algo-1, epoch=253, train loss <loss>=0.985896175558\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:09 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:10 INFO 139662618720064] Epoch[254] Batch[0] avg_epoch_loss=0.932468\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:10 INFO 139662618720064] #quality_metric: host=algo-1, epoch=254, batch=0 train loss <loss>=0.932467520237\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:11 INFO 139662618720064] Epoch[254] Batch[5] avg_epoch_loss=0.994858\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:11 INFO 139662618720064] #quality_metric: host=algo-1, epoch=254, batch=5 train loss <loss>=0.994857559601\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:11 INFO 139662618720064] Epoch[254] Batch [5]#011Speed: 186.79 samples/sec#011loss=0.994858\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:13 INFO 139662618720064] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3866.8549060821533, \"sum\": 3866.8549060821533, \"min\": 3866.8549060821533}}, \"EndTime\": 1601797993.295745, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797989.428392}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:13 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=162.400499701 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:13 INFO 139662618720064] #progress_metric: host=algo-1, completed 63 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:13 INFO 139662618720064] #quality_metric: host=algo-1, epoch=254, train loss <loss>=0.951993358135\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:13 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:14 INFO 139662618720064] Epoch[255] Batch[0] avg_epoch_loss=0.840222\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:14 INFO 139662618720064] #quality_metric: host=algo-1, epoch=255, batch=0 train loss <loss>=0.840221583843\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:15 INFO 139662618720064] Epoch[255] Batch[5] avg_epoch_loss=0.961480\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:15 INFO 139662618720064] #quality_metric: host=algo-1, epoch=255, batch=5 train loss <loss>=0.961480329434\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:15 INFO 139662618720064] Epoch[255] Batch [5]#011Speed: 185.25 samples/sec#011loss=0.961480\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:17 INFO 139662618720064] Epoch[255] Batch[10] avg_epoch_loss=0.921743\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:17 INFO 139662618720064] #quality_metric: host=algo-1, epoch=255, batch=10 train loss <loss>=0.874059176445\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:17 INFO 139662618720064] Epoch[255] Batch [10]#011Speed: 189.72 samples/sec#011loss=0.874059\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:17 INFO 139662618720064] processed a total of 667 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4241.663932800293, \"sum\": 4241.663932800293, \"min\": 4241.663932800293}}, \"EndTime\": 1601797997.537968, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797993.295831}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:17 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=157.245199754 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:17 INFO 139662618720064] #progress_metric: host=algo-1, completed 64 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:17 INFO 139662618720064] #quality_metric: host=algo-1, epoch=255, train loss <loss>=0.921743441712\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:17 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:18 INFO 139662618720064] Epoch[256] Batch[0] avg_epoch_loss=0.841402\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:18 INFO 139662618720064] #quality_metric: host=algo-1, epoch=256, batch=0 train loss <loss>=0.841402351856\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:20 INFO 139662618720064] Epoch[256] Batch[5] avg_epoch_loss=0.883796\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:20 INFO 139662618720064] #quality_metric: host=algo-1, epoch=256, batch=5 train loss <loss>=0.883796205123\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:20 INFO 139662618720064] Epoch[256] Batch [5]#011Speed: 187.47 samples/sec#011loss=0.883796\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:21 INFO 139662618720064] Epoch[256] Batch[10] avg_epoch_loss=0.953841\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:21 INFO 139662618720064] #quality_metric: host=algo-1, epoch=256, batch=10 train loss <loss>=1.03789428473\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:21 INFO 139662618720064] Epoch[256] Batch [10]#011Speed: 188.97 samples/sec#011loss=1.037894\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:21 INFO 139662618720064] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4195.822954177856, \"sum\": 4195.822954177856, \"min\": 4195.822954177856}}, \"EndTime\": 1601798001.734315, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601797997.538048}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:21 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=154.673256111 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:21 INFO 139662618720064] #progress_metric: host=algo-1, completed 64 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:21 INFO 139662618720064] #quality_metric: host=algo-1, epoch=256, train loss <loss>=0.953840786761\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:21 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:22 INFO 139662618720064] Epoch[257] Batch[0] avg_epoch_loss=0.903229\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:22 INFO 139662618720064] #quality_metric: host=algo-1, epoch=257, batch=0 train loss <loss>=0.903228640556\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:24 INFO 139662618720064] Epoch[257] Batch[5] avg_epoch_loss=0.974324\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:24 INFO 139662618720064] #quality_metric: host=algo-1, epoch=257, batch=5 train loss <loss>=0.974323729674\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:24 INFO 139662618720064] Epoch[257] Batch [5]#011Speed: 189.95 samples/sec#011loss=0.974324\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:25 INFO 139662618720064] processed a total of 607 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3864.4750118255615, \"sum\": 3864.4750118255615, \"min\": 3864.4750118255615}}, \"EndTime\": 1601798005.5993, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798001.734394}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:25 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=157.066826657 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:25 INFO 139662618720064] #progress_metric: host=algo-1, completed 64 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:25 INFO 139662618720064] #quality_metric: host=algo-1, epoch=257, train loss <loss>=1.0271648407\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:25 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:26 INFO 139662618720064] Epoch[258] Batch[0] avg_epoch_loss=0.954146\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:26 INFO 139662618720064] #quality_metric: host=algo-1, epoch=258, batch=0 train loss <loss>=0.954146325588\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:28 INFO 139662618720064] Epoch[258] Batch[5] avg_epoch_loss=0.987759\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:28 INFO 139662618720064] #quality_metric: host=algo-1, epoch=258, batch=5 train loss <loss>=0.98775913318\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:28 INFO 139662618720064] Epoch[258] Batch [5]#011Speed: 188.54 samples/sec#011loss=0.987759\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:29 INFO 139662618720064] Epoch[258] Batch[10] avg_epoch_loss=0.930047\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:29 INFO 139662618720064] #quality_metric: host=algo-1, epoch=258, batch=10 train loss <loss>=0.860791581869\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:29 INFO 139662618720064] Epoch[258] Batch [10]#011Speed: 188.74 samples/sec#011loss=0.860792\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:29 INFO 139662618720064] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4239.979982376099, \"sum\": 4239.979982376099, \"min\": 4239.979982376099}}, \"EndTime\": 1601798009.839806, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798005.599382}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:29 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=153.770065388 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:29 INFO 139662618720064] #progress_metric: host=algo-1, completed 64 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:29 INFO 139662618720064] #quality_metric: host=algo-1, epoch=258, train loss <loss>=0.930046609857\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:29 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:30 INFO 139662618720064] Epoch[259] Batch[0] avg_epoch_loss=0.965388\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:30 INFO 139662618720064] #quality_metric: host=algo-1, epoch=259, batch=0 train loss <loss>=0.965387701988\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:32 INFO 139662618720064] Epoch[259] Batch[5] avg_epoch_loss=0.948130\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:32 INFO 139662618720064] #quality_metric: host=algo-1, epoch=259, batch=5 train loss <loss>=0.948129524787\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:32 INFO 139662618720064] Epoch[259] Batch [5]#011Speed: 189.55 samples/sec#011loss=0.948130\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:33 INFO 139662618720064] processed a total of 613 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3873.249053955078, \"sum\": 3873.249053955078, \"min\": 3873.249053955078}}, \"EndTime\": 1601798013.713577, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798009.839884}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:33 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=158.259917942 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:33 INFO 139662618720064] #progress_metric: host=algo-1, completed 65 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:33 INFO 139662618720064] #quality_metric: host=algo-1, epoch=259, train loss <loss>=0.971425932646\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:33 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:34 INFO 139662618720064] Epoch[260] Batch[0] avg_epoch_loss=0.893310\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:34 INFO 139662618720064] #quality_metric: host=algo-1, epoch=260, batch=0 train loss <loss>=0.893309593201\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:36 INFO 139662618720064] Epoch[260] Batch[5] avg_epoch_loss=0.904547\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:36 INFO 139662618720064] #quality_metric: host=algo-1, epoch=260, batch=5 train loss <loss>=0.904547214508\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:36 INFO 139662618720064] Epoch[260] Batch [5]#011Speed: 186.39 samples/sec#011loss=0.904547\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:37 INFO 139662618720064] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3900.0251293182373, \"sum\": 3900.0251293182373, \"min\": 3900.0251293182373}}, \"EndTime\": 1601798017.614182, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798013.713663}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:37 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=164.097433859 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:37 INFO 139662618720064] #progress_metric: host=algo-1, completed 65 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:37 INFO 139662618720064] #quality_metric: host=algo-1, epoch=260, train loss <loss>=0.8813575387\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:37 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:37 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_0617906b-ccc0-4c07-bc95-c8b380a48e32-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 106.11891746520996, \"sum\": 106.11891746520996, \"min\": 106.11891746520996}}, \"EndTime\": 1601798017.720924, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798017.614244}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:38 INFO 139662618720064] Epoch[261] Batch[0] avg_epoch_loss=1.035452\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:38 INFO 139662618720064] #quality_metric: host=algo-1, epoch=261, batch=0 train loss <loss>=1.03545248508\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:40 INFO 139662618720064] Epoch[261] Batch[5] avg_epoch_loss=0.975837\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:40 INFO 139662618720064] #quality_metric: host=algo-1, epoch=261, batch=5 train loss <loss>=0.975836664438\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:40 INFO 139662618720064] Epoch[261] Batch [5]#011Speed: 185.26 samples/sec#011loss=0.975837\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:41 INFO 139662618720064] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3870.8560466766357, \"sum\": 3870.8560466766357, \"min\": 3870.8560466766357}}, \"EndTime\": 1601798021.591892, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798017.720976}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:41 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=163.782854008 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:41 INFO 139662618720064] #progress_metric: host=algo-1, completed 65 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:41 INFO 139662618720064] #quality_metric: host=algo-1, epoch=261, train loss <loss>=0.953923279047\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:41 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:42 INFO 139662618720064] Epoch[262] Batch[0] avg_epoch_loss=1.038569\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:42 INFO 139662618720064] #quality_metric: host=algo-1, epoch=262, batch=0 train loss <loss>=1.03856945038\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:44 INFO 139662618720064] Epoch[262] Batch[5] avg_epoch_loss=0.973950\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:44 INFO 139662618720064] #quality_metric: host=algo-1, epoch=262, batch=5 train loss <loss>=0.973949998617\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:44 INFO 139662618720064] Epoch[262] Batch [5]#011Speed: 189.83 samples/sec#011loss=0.973950\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:45 INFO 139662618720064] processed a total of 601 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3914.3149852752686, \"sum\": 3914.3149852752686, \"min\": 3914.3149852752686}}, \"EndTime\": 1601798025.50679, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798021.591976}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:45 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=153.533237226 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:45 INFO 139662618720064] #progress_metric: host=algo-1, completed 65 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:45 INFO 139662618720064] #quality_metric: host=algo-1, epoch=262, train loss <loss>=1.00749860406\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:45 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:46 INFO 139662618720064] Epoch[263] Batch[0] avg_epoch_loss=0.914414\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:46 INFO 139662618720064] #quality_metric: host=algo-1, epoch=263, batch=0 train loss <loss>=0.914414048195\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:47 INFO 139662618720064] Epoch[263] Batch[5] avg_epoch_loss=0.872584\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:47 INFO 139662618720064] #quality_metric: host=algo-1, epoch=263, batch=5 train loss <loss>=0.872583776712\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:47 INFO 139662618720064] Epoch[263] Batch [5]#011Speed: 190.35 samples/sec#011loss=0.872584\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:49 INFO 139662618720064] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3823.3699798583984, \"sum\": 3823.3699798583984, \"min\": 3823.3699798583984}}, \"EndTime\": 1601798029.330747, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798025.506897}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:49 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=163.983825028 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:49 INFO 139662618720064] #progress_metric: host=algo-1, completed 66 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:49 INFO 139662618720064] #quality_metric: host=algo-1, epoch=263, train loss <loss>=0.929488837719\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:49 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:50 INFO 139662618720064] Epoch[264] Batch[0] avg_epoch_loss=0.900167\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:50 INFO 139662618720064] #quality_metric: host=algo-1, epoch=264, batch=0 train loss <loss>=0.90016746521\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:51 INFO 139662618720064] Epoch[264] Batch[5] avg_epoch_loss=0.924049\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:51 INFO 139662618720064] #quality_metric: host=algo-1, epoch=264, batch=5 train loss <loss>=0.924048562845\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:51 INFO 139662618720064] Epoch[264] Batch [5]#011Speed: 189.84 samples/sec#011loss=0.924049\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:53 INFO 139662618720064] Epoch[264] Batch[10] avg_epoch_loss=0.934343\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:53 INFO 139662618720064] #quality_metric: host=algo-1, epoch=264, batch=10 train loss <loss>=0.946696269512\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:53 INFO 139662618720064] Epoch[264] Batch [10]#011Speed: 189.60 samples/sec#011loss=0.946696\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:53 INFO 139662618720064] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4219.977855682373, \"sum\": 4219.977855682373, \"min\": 4219.977855682373}}, \"EndTime\": 1601798033.551353, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798029.330884}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:53 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=151.892275222 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:53 INFO 139662618720064] #progress_metric: host=algo-1, completed 66 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:53 INFO 139662618720064] #quality_metric: host=algo-1, epoch=264, train loss <loss>=0.934342974966\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:53 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:54 INFO 139662618720064] Epoch[265] Batch[0] avg_epoch_loss=0.880851\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:54 INFO 139662618720064] #quality_metric: host=algo-1, epoch=265, batch=0 train loss <loss>=0.880851089954\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:56 INFO 139662618720064] Epoch[265] Batch[5] avg_epoch_loss=0.958670\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:56 INFO 139662618720064] #quality_metric: host=algo-1, epoch=265, batch=5 train loss <loss>=0.95866972208\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:56 INFO 139662618720064] Epoch[265] Batch [5]#011Speed: 187.11 samples/sec#011loss=0.958670\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:57 INFO 139662618720064] Epoch[265] Batch[10] avg_epoch_loss=0.975425\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:57 INFO 139662618720064] #quality_metric: host=algo-1, epoch=265, batch=10 train loss <loss>=0.995531868935\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:57 INFO 139662618720064] Epoch[265] Batch [10]#011Speed: 188.03 samples/sec#011loss=0.995532\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:57 INFO 139662618720064] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4211.559057235718, \"sum\": 4211.559057235718, \"min\": 4211.559057235718}}, \"EndTime\": 1601798037.763432, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798033.551432}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:57 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=153.383010147 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:57 INFO 139662618720064] #progress_metric: host=algo-1, completed 66 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:57 INFO 139662618720064] #quality_metric: host=algo-1, epoch=265, train loss <loss>=0.975425243378\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:57 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:58 INFO 139662618720064] Epoch[266] Batch[0] avg_epoch_loss=1.069619\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:53:58 INFO 139662618720064] #quality_metric: host=algo-1, epoch=266, batch=0 train loss <loss>=1.06961929798\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:00 INFO 139662618720064] Epoch[266] Batch[5] avg_epoch_loss=0.933299\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:00 INFO 139662618720064] #quality_metric: host=algo-1, epoch=266, batch=5 train loss <loss>=0.933298965295\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:00 INFO 139662618720064] Epoch[266] Batch [5]#011Speed: 186.77 samples/sec#011loss=0.933299\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:01 INFO 139662618720064] processed a total of 619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3889.050006866455, \"sum\": 3889.050006866455, \"min\": 3889.050006866455}}, \"EndTime\": 1601798041.653003, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798037.763513}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:01 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=159.159555624 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:01 INFO 139662618720064] #progress_metric: host=algo-1, completed 66 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:01 INFO 139662618720064] #quality_metric: host=algo-1, epoch=266, train loss <loss>=1.00261605382\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:01 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:02 INFO 139662618720064] Epoch[267] Batch[0] avg_epoch_loss=0.885255\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:02 INFO 139662618720064] #quality_metric: host=algo-1, epoch=267, batch=0 train loss <loss>=0.885255217552\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:04 INFO 139662618720064] Epoch[267] Batch[5] avg_epoch_loss=0.967252\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:04 INFO 139662618720064] #quality_metric: host=algo-1, epoch=267, batch=5 train loss <loss>=0.967252403498\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:04 INFO 139662618720064] Epoch[267] Batch [5]#011Speed: 186.39 samples/sec#011loss=0.967252\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:05 INFO 139662618720064] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3903.7880897521973, \"sum\": 3903.7880897521973, \"min\": 3903.7880897521973}}, \"EndTime\": 1601798045.557395, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798041.65309}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:05 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=163.683025033 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:05 INFO 139662618720064] #progress_metric: host=algo-1, completed 67 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:05 INFO 139662618720064] #quality_metric: host=algo-1, epoch=267, train loss <loss>=0.950544971228\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:05 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:06 INFO 139662618720064] Epoch[268] Batch[0] avg_epoch_loss=1.227457\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:06 INFO 139662618720064] #quality_metric: host=algo-1, epoch=268, batch=0 train loss <loss>=1.22745656967\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:08 INFO 139662618720064] Epoch[268] Batch[5] avg_epoch_loss=1.041708\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:08 INFO 139662618720064] #quality_metric: host=algo-1, epoch=268, batch=5 train loss <loss>=1.04170779387\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:08 INFO 139662618720064] Epoch[268] Batch [5]#011Speed: 188.40 samples/sec#011loss=1.041708\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:09 INFO 139662618720064] Epoch[268] Batch[10] avg_epoch_loss=0.940020\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:09 INFO 139662618720064] #quality_metric: host=algo-1, epoch=268, batch=10 train loss <loss>=0.817994713783\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:09 INFO 139662618720064] Epoch[268] Batch [10]#011Speed: 187.98 samples/sec#011loss=0.817995\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:09 INFO 139662618720064] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4194.967985153198, \"sum\": 4194.967985153198, \"min\": 4194.967985153198}}, \"EndTime\": 1601798049.752915, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798045.557458}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:09 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=154.704998708 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:09 INFO 139662618720064] #progress_metric: host=algo-1, completed 67 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:09 INFO 139662618720064] #quality_metric: host=algo-1, epoch=268, train loss <loss>=0.940020030195\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:09 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:10 INFO 139662618720064] Epoch[269] Batch[0] avg_epoch_loss=1.201587\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:10 INFO 139662618720064] #quality_metric: host=algo-1, epoch=269, batch=0 train loss <loss>=1.20158660412\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:12 INFO 139662618720064] Epoch[269] Batch[5] avg_epoch_loss=1.029609\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:12 INFO 139662618720064] #quality_metric: host=algo-1, epoch=269, batch=5 train loss <loss>=1.02960935235\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:12 INFO 139662618720064] Epoch[269] Batch [5]#011Speed: 189.73 samples/sec#011loss=1.029609\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:13 INFO 139662618720064] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3838.813066482544, \"sum\": 3838.813066482544, \"min\": 3838.813066482544}}, \"EndTime\": 1601798053.592267, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798049.752984}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:13 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=163.847346593 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:13 INFO 139662618720064] #progress_metric: host=algo-1, completed 67 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:13 INFO 139662618720064] #quality_metric: host=algo-1, epoch=269, train loss <loss>=0.998991638422\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:13 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:14 INFO 139662618720064] Epoch[270] Batch[0] avg_epoch_loss=1.065528\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:14 INFO 139662618720064] #quality_metric: host=algo-1, epoch=270, batch=0 train loss <loss>=1.06552803516\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:16 INFO 139662618720064] Epoch[270] Batch[5] avg_epoch_loss=0.983846\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:16 INFO 139662618720064] #quality_metric: host=algo-1, epoch=270, batch=5 train loss <loss>=0.983845551809\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:16 INFO 139662618720064] Epoch[270] Batch [5]#011Speed: 177.03 samples/sec#011loss=0.983846\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:17 INFO 139662618720064] Epoch[270] Batch[10] avg_epoch_loss=1.009567\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:17 INFO 139662618720064] #quality_metric: host=algo-1, epoch=270, batch=10 train loss <loss>=1.04043228626\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:17 INFO 139662618720064] Epoch[270] Batch [10]#011Speed: 187.42 samples/sec#011loss=1.040432\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:17 INFO 139662618720064] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4321.866035461426, \"sum\": 4321.866035461426, \"min\": 4321.866035461426}}, \"EndTime\": 1601798057.914714, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798053.592351}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:17 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=149.931182262 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:17 INFO 139662618720064] #progress_metric: host=algo-1, completed 67 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:17 INFO 139662618720064] #quality_metric: host=algo-1, epoch=270, train loss <loss>=1.00956679474\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:17 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:18 INFO 139662618720064] Epoch[271] Batch[0] avg_epoch_loss=0.911306\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:18 INFO 139662618720064] #quality_metric: host=algo-1, epoch=271, batch=0 train loss <loss>=0.911306381226\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:20 INFO 139662618720064] Epoch[271] Batch[5] avg_epoch_loss=0.912861\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:20 INFO 139662618720064] #quality_metric: host=algo-1, epoch=271, batch=5 train loss <loss>=0.912861218055\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:20 INFO 139662618720064] Epoch[271] Batch [5]#011Speed: 186.60 samples/sec#011loss=0.912861\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:22 INFO 139662618720064] Epoch[271] Batch[10] avg_epoch_loss=1.057706\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:22 INFO 139662618720064] #quality_metric: host=algo-1, epoch=271, batch=10 train loss <loss>=1.23151935339\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:22 INFO 139662618720064] Epoch[271] Batch [10]#011Speed: 187.46 samples/sec#011loss=1.231519\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:22 INFO 139662618720064] processed a total of 670 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4246.075868606567, \"sum\": 4246.075868606567, \"min\": 4246.075868606567}}, \"EndTime\": 1601798062.161345, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798057.914792}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:22 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=157.78828745 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:22 INFO 139662618720064] #progress_metric: host=algo-1, completed 68 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:22 INFO 139662618720064] #quality_metric: host=algo-1, epoch=271, train loss <loss>=1.05770582503\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:22 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:22 INFO 139662618720064] Epoch[272] Batch[0] avg_epoch_loss=1.006237\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:22 INFO 139662618720064] #quality_metric: host=algo-1, epoch=272, batch=0 train loss <loss>=1.0062366724\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:24 INFO 139662618720064] Epoch[272] Batch[5] avg_epoch_loss=1.035900\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:24 INFO 139662618720064] #quality_metric: host=algo-1, epoch=272, batch=5 train loss <loss>=1.03589958946\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:24 INFO 139662618720064] Epoch[272] Batch [5]#011Speed: 189.88 samples/sec#011loss=1.035900\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:26 INFO 139662618720064] processed a total of 597 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3861.8438243865967, \"sum\": 3861.8438243865967, \"min\": 3861.8438243865967}}, \"EndTime\": 1601798066.023732, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798062.161426}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:26 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=154.584358628 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:26 INFO 139662618720064] #progress_metric: host=algo-1, completed 68 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:26 INFO 139662618720064] #quality_metric: host=algo-1, epoch=272, train loss <loss>=0.996098142862\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:26 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:26 INFO 139662618720064] Epoch[273] Batch[0] avg_epoch_loss=0.936105\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:26 INFO 139662618720064] #quality_metric: host=algo-1, epoch=273, batch=0 train loss <loss>=0.936105370522\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:28 INFO 139662618720064] Epoch[273] Batch[5] avg_epoch_loss=0.898671\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:28 INFO 139662618720064] #quality_metric: host=algo-1, epoch=273, batch=5 train loss <loss>=0.898671189944\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:28 INFO 139662618720064] Epoch[273] Batch [5]#011Speed: 188.87 samples/sec#011loss=0.898671\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:29 INFO 139662618720064] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3869.884967803955, \"sum\": 3869.884967803955, \"min\": 3869.884967803955}}, \"EndTime\": 1601798069.894186, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798066.023817}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:29 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=162.015079474 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:29 INFO 139662618720064] #progress_metric: host=algo-1, completed 68 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:29 INFO 139662618720064] #quality_metric: host=algo-1, epoch=273, train loss <loss>=0.916254246235\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:29 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:30 INFO 139662618720064] Epoch[274] Batch[0] avg_epoch_loss=0.788245\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:30 INFO 139662618720064] #quality_metric: host=algo-1, epoch=274, batch=0 train loss <loss>=0.788245081902\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:32 INFO 139662618720064] Epoch[274] Batch[5] avg_epoch_loss=0.926214\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:32 INFO 139662618720064] #quality_metric: host=algo-1, epoch=274, batch=5 train loss <loss>=0.926213910182\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:32 INFO 139662618720064] Epoch[274] Batch [5]#011Speed: 186.62 samples/sec#011loss=0.926214\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:33 INFO 139662618720064] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3909.2459678649902, \"sum\": 3909.2459678649902, \"min\": 3909.2459678649902}}, \"EndTime\": 1601798073.804097, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798069.89427}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:33 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=161.917677221 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:33 INFO 139662618720064] #progress_metric: host=algo-1, completed 68 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:33 INFO 139662618720064] #quality_metric: host=algo-1, epoch=274, train loss <loss>=0.952893179655\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:33 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:34 INFO 139662618720064] Epoch[275] Batch[0] avg_epoch_loss=0.970285\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:34 INFO 139662618720064] #quality_metric: host=algo-1, epoch=275, batch=0 train loss <loss>=0.97028529644\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:36 INFO 139662618720064] Epoch[275] Batch[5] avg_epoch_loss=1.021106\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:36 INFO 139662618720064] #quality_metric: host=algo-1, epoch=275, batch=5 train loss <loss>=1.02110587557\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:36 INFO 139662618720064] Epoch[275] Batch [5]#011Speed: 187.13 samples/sec#011loss=1.021106\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:37 INFO 139662618720064] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3892.590045928955, \"sum\": 3892.590045928955, \"min\": 3892.590045928955}}, \"EndTime\": 1601798077.69726, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798073.804183}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:37 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=163.639003554 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:37 INFO 139662618720064] #progress_metric: host=algo-1, completed 69 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:37 INFO 139662618720064] #quality_metric: host=algo-1, epoch=275, train loss <loss>=0.995431774855\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:37 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:38 INFO 139662618720064] Epoch[276] Batch[0] avg_epoch_loss=0.865492\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:38 INFO 139662618720064] #quality_metric: host=algo-1, epoch=276, batch=0 train loss <loss>=0.865492343903\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:40 INFO 139662618720064] Epoch[276] Batch[5] avg_epoch_loss=0.878917\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:40 INFO 139662618720064] #quality_metric: host=algo-1, epoch=276, batch=5 train loss <loss>=0.878917098045\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:40 INFO 139662618720064] Epoch[276] Batch [5]#011Speed: 189.25 samples/sec#011loss=0.878917\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:41 INFO 139662618720064] processed a total of 610 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3849.828004837036, \"sum\": 3849.828004837036, \"min\": 3849.828004837036}}, \"EndTime\": 1601798081.547654, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798077.697344}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:41 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=158.443662118 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:41 INFO 139662618720064] #progress_metric: host=algo-1, completed 69 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:41 INFO 139662618720064] #quality_metric: host=algo-1, epoch=276, train loss <loss>=0.860894101858\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:41 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:41 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_ccbf9152-1dc7-47ae-9108-f115b348fd0a-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 109.4810962677002, \"sum\": 109.4810962677002, \"min\": 109.4810962677002}}, \"EndTime\": 1601798081.657725, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798081.547735}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:42 INFO 139662618720064] Epoch[277] Batch[0] avg_epoch_loss=0.876381\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:42 INFO 139662618720064] #quality_metric: host=algo-1, epoch=277, batch=0 train loss <loss>=0.876380503178\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:44 INFO 139662618720064] Epoch[277] Batch[5] avg_epoch_loss=0.902452\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:44 INFO 139662618720064] #quality_metric: host=algo-1, epoch=277, batch=5 train loss <loss>=0.902452458938\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:44 INFO 139662618720064] Epoch[277] Batch [5]#011Speed: 188.89 samples/sec#011loss=0.902452\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:45 INFO 139662618720064] Epoch[277] Batch[10] avg_epoch_loss=0.930961\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:45 INFO 139662618720064] #quality_metric: host=algo-1, epoch=277, batch=10 train loss <loss>=0.965171551704\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:45 INFO 139662618720064] Epoch[277] Batch [10]#011Speed: 184.43 samples/sec#011loss=0.965172\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:45 INFO 139662618720064] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4217.704057693481, \"sum\": 4217.704057693481, \"min\": 4217.704057693481}}, \"EndTime\": 1601798085.875548, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798081.657783}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:45 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=155.293416453 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:45 INFO 139662618720064] #progress_metric: host=algo-1, completed 69 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:45 INFO 139662618720064] #quality_metric: host=algo-1, epoch=277, train loss <loss>=0.930961137468\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:45 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:46 INFO 139662618720064] Epoch[278] Batch[0] avg_epoch_loss=1.044642\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:46 INFO 139662618720064] #quality_metric: host=algo-1, epoch=278, batch=0 train loss <loss>=1.04464173317\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:48 INFO 139662618720064] Epoch[278] Batch[5] avg_epoch_loss=1.005089\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:48 INFO 139662618720064] #quality_metric: host=algo-1, epoch=278, batch=5 train loss <loss>=1.00508917371\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:48 INFO 139662618720064] Epoch[278] Batch [5]#011Speed: 187.17 samples/sec#011loss=1.005089\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:50 INFO 139662618720064] Epoch[278] Batch[10] avg_epoch_loss=0.875330\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:50 INFO 139662618720064] #quality_metric: host=algo-1, epoch=278, batch=10 train loss <loss>=0.719618296623\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:50 INFO 139662618720064] Epoch[278] Batch [10]#011Speed: 188.98 samples/sec#011loss=0.719618\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:50 INFO 139662618720064] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4196.666955947876, \"sum\": 4196.666955947876, \"min\": 4196.666955947876}}, \"EndTime\": 1601798090.072767, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798085.875625}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:50 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=153.689476511 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:50 INFO 139662618720064] #progress_metric: host=algo-1, completed 69 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:50 INFO 139662618720064] #quality_metric: host=algo-1, epoch=278, train loss <loss>=0.875329684127\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:50 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:50 INFO 139662618720064] Epoch[279] Batch[0] avg_epoch_loss=0.869819\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:50 INFO 139662618720064] #quality_metric: host=algo-1, epoch=279, batch=0 train loss <loss>=0.869818866253\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:52 INFO 139662618720064] Epoch[279] Batch[5] avg_epoch_loss=0.925242\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:52 INFO 139662618720064] #quality_metric: host=algo-1, epoch=279, batch=5 train loss <loss>=0.92524249355\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:52 INFO 139662618720064] Epoch[279] Batch [5]#011Speed: 188.08 samples/sec#011loss=0.925242\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:54 INFO 139662618720064] Epoch[279] Batch[10] avg_epoch_loss=0.944433\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:54 INFO 139662618720064] #quality_metric: host=algo-1, epoch=279, batch=10 train loss <loss>=0.967460775375\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:54 INFO 139662618720064] Epoch[279] Batch [10]#011Speed: 189.90 samples/sec#011loss=0.967461\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:54 INFO 139662618720064] processed a total of 692 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4248.353004455566, \"sum\": 4248.353004455566, \"min\": 4248.353004455566}}, \"EndTime\": 1601798094.321599, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798090.072837}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:54 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=162.882136963 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:54 INFO 139662618720064] #progress_metric: host=algo-1, completed 70 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:54 INFO 139662618720064] #quality_metric: host=algo-1, epoch=279, train loss <loss>=0.944432621652\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:54 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:55 INFO 139662618720064] Epoch[280] Batch[0] avg_epoch_loss=0.850206\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:55 INFO 139662618720064] #quality_metric: host=algo-1, epoch=280, batch=0 train loss <loss>=0.850206315517\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:56 INFO 139662618720064] Epoch[280] Batch[5] avg_epoch_loss=0.929142\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:56 INFO 139662618720064] #quality_metric: host=algo-1, epoch=280, batch=5 train loss <loss>=0.929141799609\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:56 INFO 139662618720064] Epoch[280] Batch [5]#011Speed: 185.12 samples/sec#011loss=0.929142\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:58 INFO 139662618720064] Epoch[280] Batch[10] avg_epoch_loss=1.160909\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:58 INFO 139662618720064] #quality_metric: host=algo-1, epoch=280, batch=10 train loss <loss>=1.43903011084\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:58 INFO 139662618720064] Epoch[280] Batch [10]#011Speed: 184.25 samples/sec#011loss=1.439030\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:58 INFO 139662618720064] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4275.660991668701, \"sum\": 4275.660991668701, \"min\": 4275.660991668701}}, \"EndTime\": 1601798098.597784, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798094.321678}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:58 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=153.188416901 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:58 INFO 139662618720064] #progress_metric: host=algo-1, completed 70 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:58 INFO 139662618720064] #quality_metric: host=algo-1, epoch=280, train loss <loss>=1.1609092138\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:58 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:59 INFO 139662618720064] Epoch[281] Batch[0] avg_epoch_loss=0.982260\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:54:59 INFO 139662618720064] #quality_metric: host=algo-1, epoch=281, batch=0 train loss <loss>=0.982260286808\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:01 INFO 139662618720064] Epoch[281] Batch[5] avg_epoch_loss=1.017137\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:01 INFO 139662618720064] #quality_metric: host=algo-1, epoch=281, batch=5 train loss <loss>=1.01713745793\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:01 INFO 139662618720064] Epoch[281] Batch [5]#011Speed: 189.47 samples/sec#011loss=1.017137\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:02 INFO 139662618720064] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3888.158082962036, \"sum\": 3888.158082962036, \"min\": 3888.158082962036}}, \"EndTime\": 1601798102.486452, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798098.597864}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:02 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=159.710645575 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:02 INFO 139662618720064] #progress_metric: host=algo-1, completed 70 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:02 INFO 139662618720064] #quality_metric: host=algo-1, epoch=281, train loss <loss>=1.14140323997\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:02 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:03 INFO 139662618720064] Epoch[282] Batch[0] avg_epoch_loss=1.471286\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:03 INFO 139662618720064] #quality_metric: host=algo-1, epoch=282, batch=0 train loss <loss>=1.47128617764\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:05 INFO 139662618720064] Epoch[282] Batch[5] avg_epoch_loss=1.286035\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:05 INFO 139662618720064] #quality_metric: host=algo-1, epoch=282, batch=5 train loss <loss>=1.28603470325\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:05 INFO 139662618720064] Epoch[282] Batch [5]#011Speed: 188.47 samples/sec#011loss=1.286035\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:06 INFO 139662618720064] Epoch[282] Batch[10] avg_epoch_loss=1.163366\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:06 INFO 139662618720064] #quality_metric: host=algo-1, epoch=282, batch=10 train loss <loss>=1.01616376638\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:06 INFO 139662618720064] Epoch[282] Batch [10]#011Speed: 188.43 samples/sec#011loss=1.016164\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:06 INFO 139662618720064] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4218.358039855957, \"sum\": 4218.358039855957, \"min\": 4218.358039855957}}, \"EndTime\": 1601798106.705411, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798102.486536}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:06 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=151.950504542 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:06 INFO 139662618720064] #progress_metric: host=algo-1, completed 70 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:06 INFO 139662618720064] #quality_metric: host=algo-1, epoch=282, train loss <loss>=1.16336609559\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:06 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:07 INFO 139662618720064] Epoch[283] Batch[0] avg_epoch_loss=1.131148\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:07 INFO 139662618720064] #quality_metric: host=algo-1, epoch=283, batch=0 train loss <loss>=1.13114798069\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:09 INFO 139662618720064] Epoch[283] Batch[5] avg_epoch_loss=1.214660\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:09 INFO 139662618720064] #quality_metric: host=algo-1, epoch=283, batch=5 train loss <loss>=1.21465975046\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:09 INFO 139662618720064] Epoch[283] Batch [5]#011Speed: 190.00 samples/sec#011loss=1.214660\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:10 INFO 139662618720064] processed a total of 612 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3886.7578506469727, \"sum\": 3886.7578506469727, \"min\": 3886.7578506469727}}, \"EndTime\": 1601798110.592697, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798106.705493}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:10 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=157.452641818 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:10 INFO 139662618720064] #progress_metric: host=algo-1, completed 71 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:10 INFO 139662618720064] #quality_metric: host=algo-1, epoch=283, train loss <loss>=1.15910657644\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:10 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:11 INFO 139662618720064] Epoch[284] Batch[0] avg_epoch_loss=1.010564\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:11 INFO 139662618720064] #quality_metric: host=algo-1, epoch=284, batch=0 train loss <loss>=1.01056432724\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:13 INFO 139662618720064] Epoch[284] Batch[5] avg_epoch_loss=1.108164\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:13 INFO 139662618720064] #quality_metric: host=algo-1, epoch=284, batch=5 train loss <loss>=1.10816353559\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:13 INFO 139662618720064] Epoch[284] Batch [5]#011Speed: 189.56 samples/sec#011loss=1.108164\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:14 INFO 139662618720064] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3854.2709350585938, \"sum\": 3854.2709350585938, \"min\": 3854.2709350585938}}, \"EndTime\": 1601798114.447537, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798110.592782}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:14 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=164.487423976 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:14 INFO 139662618720064] #progress_metric: host=algo-1, completed 71 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:14 INFO 139662618720064] #quality_metric: host=algo-1, epoch=284, train loss <loss>=1.07366526723\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:14 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:15 INFO 139662618720064] Epoch[285] Batch[0] avg_epoch_loss=1.228286\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:15 INFO 139662618720064] #quality_metric: host=algo-1, epoch=285, batch=0 train loss <loss>=1.22828567028\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:16 INFO 139662618720064] Epoch[285] Batch[5] avg_epoch_loss=1.089335\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:16 INFO 139662618720064] #quality_metric: host=algo-1, epoch=285, batch=5 train loss <loss>=1.08933462699\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:16 INFO 139662618720064] Epoch[285] Batch [5]#011Speed: 189.86 samples/sec#011loss=1.089335\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:18 INFO 139662618720064] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3882.2340965270996, \"sum\": 3882.2340965270996, \"min\": 3882.2340965270996}}, \"EndTime\": 1601798118.330332, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798114.447623}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:18 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=162.530257822 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:18 INFO 139662618720064] #progress_metric: host=algo-1, completed 71 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:18 INFO 139662618720064] #quality_metric: host=algo-1, epoch=285, train loss <loss>=1.07452397943\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:18 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:19 INFO 139662618720064] Epoch[286] Batch[0] avg_epoch_loss=1.077940\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:19 INFO 139662618720064] #quality_metric: host=algo-1, epoch=286, batch=0 train loss <loss>=1.07794046402\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:20 INFO 139662618720064] Epoch[286] Batch[5] avg_epoch_loss=0.952902\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:20 INFO 139662618720064] #quality_metric: host=algo-1, epoch=286, batch=5 train loss <loss>=0.952902267377\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:20 INFO 139662618720064] Epoch[286] Batch [5]#011Speed: 188.97 samples/sec#011loss=0.952902\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:22 INFO 139662618720064] Epoch[286] Batch[10] avg_epoch_loss=0.956516\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:22 INFO 139662618720064] #quality_metric: host=algo-1, epoch=286, batch=10 train loss <loss>=0.96085152626\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:22 INFO 139662618720064] Epoch[286] Batch [10]#011Speed: 188.22 samples/sec#011loss=0.960852\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:22 INFO 139662618720064] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4238.662004470825, \"sum\": 4238.662004470825, \"min\": 4238.662004470825}}, \"EndTime\": 1601798122.569558, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798118.330413}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:22 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=154.525593839 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:22 INFO 139662618720064] #progress_metric: host=algo-1, completed 71 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:22 INFO 139662618720064] #quality_metric: host=algo-1, epoch=286, train loss <loss>=0.956515566869\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:22 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:23 INFO 139662618720064] Epoch[287] Batch[0] avg_epoch_loss=1.015434\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:23 INFO 139662618720064] #quality_metric: host=algo-1, epoch=287, batch=0 train loss <loss>=1.0154337883\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:25 INFO 139662618720064] Epoch[287] Batch[5] avg_epoch_loss=0.932686\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:25 INFO 139662618720064] #quality_metric: host=algo-1, epoch=287, batch=5 train loss <loss>=0.932686120272\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:25 INFO 139662618720064] Epoch[287] Batch [5]#011Speed: 189.76 samples/sec#011loss=0.932686\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:26 INFO 139662618720064] Epoch[287] Batch[10] avg_epoch_loss=0.955323\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:26 INFO 139662618720064] #quality_metric: host=algo-1, epoch=287, batch=10 train loss <loss>=0.982488334179\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:26 INFO 139662618720064] Epoch[287] Batch [10]#011Speed: 189.15 samples/sec#011loss=0.982488\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:26 INFO 139662618720064] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4206.03609085083, \"sum\": 4206.03609085083, \"min\": 4206.03609085083}}, \"EndTime\": 1601798126.776123, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798122.569637}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:26 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=155.248683758 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:26 INFO 139662618720064] #progress_metric: host=algo-1, completed 72 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:26 INFO 139662618720064] #quality_metric: host=algo-1, epoch=287, train loss <loss>=0.95532349023\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:26 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:27 INFO 139662618720064] Epoch[288] Batch[0] avg_epoch_loss=0.852259\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:27 INFO 139662618720064] #quality_metric: host=algo-1, epoch=288, batch=0 train loss <loss>=0.85225880146\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:29 INFO 139662618720064] Epoch[288] Batch[5] avg_epoch_loss=0.992317\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:29 INFO 139662618720064] #quality_metric: host=algo-1, epoch=288, batch=5 train loss <loss>=0.992316703002\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:29 INFO 139662618720064] Epoch[288] Batch [5]#011Speed: 190.45 samples/sec#011loss=0.992317\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:30 INFO 139662618720064] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3859.7590923309326, \"sum\": 3859.7590923309326, \"min\": 3859.7590923309326}}, \"EndTime\": 1601798130.636401, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798126.776201}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:30 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=161.40377334 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:30 INFO 139662618720064] #progress_metric: host=algo-1, completed 72 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:30 INFO 139662618720064] #quality_metric: host=algo-1, epoch=288, train loss <loss>=1.01338355541\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:30 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:31 INFO 139662618720064] Epoch[289] Batch[0] avg_epoch_loss=0.912490\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:31 INFO 139662618720064] #quality_metric: host=algo-1, epoch=289, batch=0 train loss <loss>=0.912489950657\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:33 INFO 139662618720064] Epoch[289] Batch[5] avg_epoch_loss=0.908253\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:33 INFO 139662618720064] #quality_metric: host=algo-1, epoch=289, batch=5 train loss <loss>=0.908253252506\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:33 INFO 139662618720064] Epoch[289] Batch [5]#011Speed: 188.95 samples/sec#011loss=0.908253\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:34 INFO 139662618720064] Epoch[289] Batch[10] avg_epoch_loss=0.878297\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:34 INFO 139662618720064] #quality_metric: host=algo-1, epoch=289, batch=10 train loss <loss>=0.842350596189\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:34 INFO 139662618720064] Epoch[289] Batch [10]#011Speed: 188.04 samples/sec#011loss=0.842351\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:34 INFO 139662618720064] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4201.632976531982, \"sum\": 4201.632976531982, \"min\": 4201.632976531982}}, \"EndTime\": 1601798134.838624, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798130.636486}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:34 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=157.791359124 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:34 INFO 139662618720064] #progress_metric: host=algo-1, completed 72 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:34 INFO 139662618720064] #quality_metric: host=algo-1, epoch=289, train loss <loss>=0.878297499635\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:34 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:35 INFO 139662618720064] Epoch[290] Batch[0] avg_epoch_loss=1.197781\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:35 INFO 139662618720064] #quality_metric: host=algo-1, epoch=290, batch=0 train loss <loss>=1.19778096676\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:37 INFO 139662618720064] Epoch[290] Batch[5] avg_epoch_loss=0.903630\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:37 INFO 139662618720064] #quality_metric: host=algo-1, epoch=290, batch=5 train loss <loss>=0.903629899025\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:37 INFO 139662618720064] Epoch[290] Batch [5]#011Speed: 189.41 samples/sec#011loss=0.903630\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:38 INFO 139662618720064] processed a total of 616 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3909.536838531494, \"sum\": 3909.536838531494, \"min\": 3909.536838531494}}, \"EndTime\": 1601798138.748711, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798134.838704}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:38 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=157.557771521 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:38 INFO 139662618720064] #progress_metric: host=algo-1, completed 72 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:38 INFO 139662618720064] #quality_metric: host=algo-1, epoch=290, train loss <loss>=0.889412635565\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:38 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:39 INFO 139662618720064] Epoch[291] Batch[0] avg_epoch_loss=0.751604\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:39 INFO 139662618720064] #quality_metric: host=algo-1, epoch=291, batch=0 train loss <loss>=0.751603722572\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:41 INFO 139662618720064] Epoch[291] Batch[5] avg_epoch_loss=0.895256\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:41 INFO 139662618720064] #quality_metric: host=algo-1, epoch=291, batch=5 train loss <loss>=0.895255853732\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:41 INFO 139662618720064] Epoch[291] Batch [5]#011Speed: 189.07 samples/sec#011loss=0.895256\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:42 INFO 139662618720064] processed a total of 614 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3846.637964248657, \"sum\": 3846.637964248657, \"min\": 3846.637964248657}}, \"EndTime\": 1601798142.596034, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798138.748809}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:42 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=159.61471466 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:42 INFO 139662618720064] #progress_metric: host=algo-1, completed 73 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:42 INFO 139662618720064] #quality_metric: host=algo-1, epoch=291, train loss <loss>=0.886567103863\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:42 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:43 INFO 139662618720064] Epoch[292] Batch[0] avg_epoch_loss=0.981420\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:43 INFO 139662618720064] #quality_metric: host=algo-1, epoch=292, batch=0 train loss <loss>=0.981419622898\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:45 INFO 139662618720064] Epoch[292] Batch[5] avg_epoch_loss=0.989878\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:45 INFO 139662618720064] #quality_metric: host=algo-1, epoch=292, batch=5 train loss <loss>=0.989878445864\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:45 INFO 139662618720064] Epoch[292] Batch [5]#011Speed: 185.12 samples/sec#011loss=0.989878\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:46 INFO 139662618720064] Epoch[292] Batch[10] avg_epoch_loss=0.832706\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:46 INFO 139662618720064] #quality_metric: host=algo-1, epoch=292, batch=10 train loss <loss>=0.644098758698\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:46 INFO 139662618720064] Epoch[292] Batch [10]#011Speed: 189.36 samples/sec#011loss=0.644099\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:46 INFO 139662618720064] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4222.799062728882, \"sum\": 4222.799062728882, \"min\": 4222.799062728882}}, \"EndTime\": 1601798146.8194, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798142.59612}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:46 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=152.027543492 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:46 INFO 139662618720064] #progress_metric: host=algo-1, completed 73 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:46 INFO 139662618720064] #quality_metric: host=algo-1, epoch=292, train loss <loss>=0.832705860788\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:46 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:46 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_7452fa8e-1dc6-4870-aa1f-7cb0c89a7c36-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 121.65999412536621, \"sum\": 121.65999412536621, \"min\": 121.65999412536621}}, \"EndTime\": 1601798146.941628, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798146.819481}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:47 INFO 139662618720064] Epoch[293] Batch[0] avg_epoch_loss=0.818858\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:47 INFO 139662618720064] #quality_metric: host=algo-1, epoch=293, batch=0 train loss <loss>=0.818857729435\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:49 INFO 139662618720064] Epoch[293] Batch[5] avg_epoch_loss=0.946642\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:49 INFO 139662618720064] #quality_metric: host=algo-1, epoch=293, batch=5 train loss <loss>=0.946642468373\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:49 INFO 139662618720064] Epoch[293] Batch [5]#011Speed: 190.13 samples/sec#011loss=0.946642\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:50 INFO 139662618720064] processed a total of 618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3838.4861946105957, \"sum\": 3838.4861946105957, \"min\": 3838.4861946105957}}, \"EndTime\": 1601798150.78026, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798146.941704}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:50 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=160.995899886 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:50 INFO 139662618720064] #progress_metric: host=algo-1, completed 73 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:50 INFO 139662618720064] #quality_metric: host=algo-1, epoch=293, train loss <loss>=0.948891985416\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:50 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:51 INFO 139662618720064] Epoch[294] Batch[0] avg_epoch_loss=0.962659\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:51 INFO 139662618720064] #quality_metric: host=algo-1, epoch=294, batch=0 train loss <loss>=0.962658762932\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:53 INFO 139662618720064] Epoch[294] Batch[5] avg_epoch_loss=0.921139\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:53 INFO 139662618720064] #quality_metric: host=algo-1, epoch=294, batch=5 train loss <loss>=0.921138872703\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:53 INFO 139662618720064] Epoch[294] Batch [5]#011Speed: 187.27 samples/sec#011loss=0.921139\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:55 INFO 139662618720064] Epoch[294] Batch[10] avg_epoch_loss=0.875213\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:55 INFO 139662618720064] #quality_metric: host=algo-1, epoch=294, batch=10 train loss <loss>=0.820102196932\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:55 INFO 139662618720064] Epoch[294] Batch [10]#011Speed: 189.26 samples/sec#011loss=0.820102\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:55 INFO 139662618720064] processed a total of 668 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4238.821029663086, \"sum\": 4238.821029663086, \"min\": 4238.821029663086}}, \"EndTime\": 1601798155.019674, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798150.780343}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:55 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=157.586566433 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:55 INFO 139662618720064] #progress_metric: host=algo-1, completed 73 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:55 INFO 139662618720064] #quality_metric: host=algo-1, epoch=294, train loss <loss>=0.875213110989\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:55 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:55 INFO 139662618720064] Epoch[295] Batch[0] avg_epoch_loss=0.911290\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:55 INFO 139662618720064] #quality_metric: host=algo-1, epoch=295, batch=0 train loss <loss>=0.911290228367\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:57 INFO 139662618720064] Epoch[295] Batch[5] avg_epoch_loss=0.910870\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:57 INFO 139662618720064] #quality_metric: host=algo-1, epoch=295, batch=5 train loss <loss>=0.910869836807\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:57 INFO 139662618720064] Epoch[295] Batch [5]#011Speed: 188.33 samples/sec#011loss=0.910870\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:59 INFO 139662618720064] Epoch[295] Batch[10] avg_epoch_loss=0.893554\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:59 INFO 139662618720064] #quality_metric: host=algo-1, epoch=295, batch=10 train loss <loss>=0.87277547121\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:59 INFO 139662618720064] Epoch[295] Batch [10]#011Speed: 189.12 samples/sec#011loss=0.872775\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:59 INFO 139662618720064] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4198.196887969971, \"sum\": 4198.196887969971, \"min\": 4198.196887969971}}, \"EndTime\": 1601798159.218387, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798155.019754}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:59 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=156.014896458 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:59 INFO 139662618720064] #progress_metric: host=algo-1, completed 74 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:59 INFO 139662618720064] #quality_metric: host=algo-1, epoch=295, train loss <loss>=0.893554216081\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:55:59 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:00 INFO 139662618720064] Epoch[296] Batch[0] avg_epoch_loss=1.155552\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:00 INFO 139662618720064] #quality_metric: host=algo-1, epoch=296, batch=0 train loss <loss>=1.15555167198\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:01 INFO 139662618720064] Epoch[296] Batch[5] avg_epoch_loss=1.140845\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:01 INFO 139662618720064] #quality_metric: host=algo-1, epoch=296, batch=5 train loss <loss>=1.14084521929\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:01 INFO 139662618720064] Epoch[296] Batch [5]#011Speed: 187.59 samples/sec#011loss=1.140845\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:03 INFO 139662618720064] Epoch[296] Batch[10] avg_epoch_loss=1.059546\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:03 INFO 139662618720064] #quality_metric: host=algo-1, epoch=296, batch=10 train loss <loss>=0.961986625195\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:03 INFO 139662618720064] Epoch[296] Batch [10]#011Speed: 187.03 samples/sec#011loss=0.961987\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:03 INFO 139662618720064] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4213.866949081421, \"sum\": 4213.866949081421, \"min\": 4213.866949081421}}, \"EndTime\": 1601798163.432869, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798159.218468}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:03 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=155.197560087 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:03 INFO 139662618720064] #progress_metric: host=algo-1, completed 74 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:03 INFO 139662618720064] #quality_metric: host=algo-1, epoch=296, train loss <loss>=1.05954585834\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:03 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:04 INFO 139662618720064] Epoch[297] Batch[0] avg_epoch_loss=0.835842\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:04 INFO 139662618720064] #quality_metric: host=algo-1, epoch=297, batch=0 train loss <loss>=0.835841715336\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:05 INFO 139662618720064] Epoch[297] Batch[5] avg_epoch_loss=0.948847\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:05 INFO 139662618720064] #quality_metric: host=algo-1, epoch=297, batch=5 train loss <loss>=0.94884716471\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:05 INFO 139662618720064] Epoch[297] Batch [5]#011Speed: 188.31 samples/sec#011loss=0.948847\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:07 INFO 139662618720064] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3863.100051879883, \"sum\": 3863.100051879883, \"min\": 3863.100051879883}}, \"EndTime\": 1601798167.29648, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798163.432947}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:07 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=165.663880047 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:07 INFO 139662618720064] #progress_metric: host=algo-1, completed 74 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:07 INFO 139662618720064] #quality_metric: host=algo-1, epoch=297, train loss <loss>=0.940576308966\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:07 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:08 INFO 139662618720064] Epoch[298] Batch[0] avg_epoch_loss=0.901283\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:08 INFO 139662618720064] #quality_metric: host=algo-1, epoch=298, batch=0 train loss <loss>=0.901282548904\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:09 INFO 139662618720064] Epoch[298] Batch[5] avg_epoch_loss=0.919364\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:09 INFO 139662618720064] #quality_metric: host=algo-1, epoch=298, batch=5 train loss <loss>=0.919363637765\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:09 INFO 139662618720064] Epoch[298] Batch [5]#011Speed: 189.48 samples/sec#011loss=0.919364\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:11 INFO 139662618720064] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3857.49888420105, \"sum\": 3857.49888420105, \"min\": 3857.49888420105}}, \"EndTime\": 1601798171.154554, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798167.296584}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:11 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=163.313050111 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:11 INFO 139662618720064] #progress_metric: host=algo-1, completed 74 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:11 INFO 139662618720064] #quality_metric: host=algo-1, epoch=298, train loss <loss>=0.941797143221\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:11 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:11 INFO 139662618720064] Epoch[299] Batch[0] avg_epoch_loss=0.954358\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:11 INFO 139662618720064] #quality_metric: host=algo-1, epoch=299, batch=0 train loss <loss>=0.954358100891\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:13 INFO 139662618720064] Epoch[299] Batch[5] avg_epoch_loss=0.919368\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:13 INFO 139662618720064] #quality_metric: host=algo-1, epoch=299, batch=5 train loss <loss>=0.919368227323\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:13 INFO 139662618720064] Epoch[299] Batch [5]#011Speed: 189.12 samples/sec#011loss=0.919368\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:15 INFO 139662618720064] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3874.6728897094727, \"sum\": 3874.6728897094727, \"min\": 3874.6728897094727}}, \"EndTime\": 1601798175.029819, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798171.154637}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:15 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=161.556975409 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:15 INFO 139662618720064] #progress_metric: host=algo-1, completed 75 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:15 INFO 139662618720064] #quality_metric: host=algo-1, epoch=299, train loss <loss>=0.950638920069\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:15 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:15 INFO 139662618720064] Epoch[300] Batch[0] avg_epoch_loss=0.916432\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:15 INFO 139662618720064] #quality_metric: host=algo-1, epoch=300, batch=0 train loss <loss>=0.916432142258\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:17 INFO 139662618720064] Epoch[300] Batch[5] avg_epoch_loss=0.935413\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:17 INFO 139662618720064] #quality_metric: host=algo-1, epoch=300, batch=5 train loss <loss>=0.935412993034\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:17 INFO 139662618720064] Epoch[300] Batch [5]#011Speed: 184.66 samples/sec#011loss=0.935413\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:18 INFO 139662618720064] processed a total of 587 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3884.6678733825684, \"sum\": 3884.6678733825684, \"min\": 3884.6678733825684}}, \"EndTime\": 1601798178.91507, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798175.029906}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:18 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=151.102974132 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:18 INFO 139662618720064] #progress_metric: host=algo-1, completed 75 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:18 INFO 139662618720064] #quality_metric: host=algo-1, epoch=300, train loss <loss>=0.973427921534\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:18 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:19 INFO 139662618720064] Epoch[301] Batch[0] avg_epoch_loss=0.857907\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:19 INFO 139662618720064] #quality_metric: host=algo-1, epoch=301, batch=0 train loss <loss>=0.857906520367\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:21 INFO 139662618720064] Epoch[301] Batch[5] avg_epoch_loss=0.974381\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:21 INFO 139662618720064] #quality_metric: host=algo-1, epoch=301, batch=5 train loss <loss>=0.974381486575\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:21 INFO 139662618720064] Epoch[301] Batch [5]#011Speed: 184.45 samples/sec#011loss=0.974381\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:22 INFO 139662618720064] processed a total of 618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3876.6300678253174, \"sum\": 3876.6300678253174, \"min\": 3876.6300678253174}}, \"EndTime\": 1601798182.792254, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798178.915133}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:22 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=159.411594511 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:22 INFO 139662618720064] #progress_metric: host=algo-1, completed 75 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:22 INFO 139662618720064] #quality_metric: host=algo-1, epoch=301, train loss <loss>=0.925129795074\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:22 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:23 INFO 139662618720064] Epoch[302] Batch[0] avg_epoch_loss=1.087932\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:23 INFO 139662618720064] #quality_metric: host=algo-1, epoch=302, batch=0 train loss <loss>=1.087931633\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:25 INFO 139662618720064] Epoch[302] Batch[5] avg_epoch_loss=1.007385\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:25 INFO 139662618720064] #quality_metric: host=algo-1, epoch=302, batch=5 train loss <loss>=1.00738526384\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:25 INFO 139662618720064] Epoch[302] Batch [5]#011Speed: 190.65 samples/sec#011loss=1.007385\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:26 INFO 139662618720064] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3886.255979537964, \"sum\": 3886.255979537964, \"min\": 3886.255979537964}}, \"EndTime\": 1601798186.679074, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798182.792339}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:26 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=161.589835806 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:26 INFO 139662618720064] #progress_metric: host=algo-1, completed 75 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:26 INFO 139662618720064] #quality_metric: host=algo-1, epoch=302, train loss <loss>=0.97629570365\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:26 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:27 INFO 139662618720064] Epoch[303] Batch[0] avg_epoch_loss=0.823174\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:27 INFO 139662618720064] #quality_metric: host=algo-1, epoch=303, batch=0 train loss <loss>=0.8231741786\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:29 INFO 139662618720064] Epoch[303] Batch[5] avg_epoch_loss=0.880768\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:29 INFO 139662618720064] #quality_metric: host=algo-1, epoch=303, batch=5 train loss <loss>=0.880768318971\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:29 INFO 139662618720064] Epoch[303] Batch [5]#011Speed: 189.84 samples/sec#011loss=0.880768\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:30 INFO 139662618720064] processed a total of 597 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3842.65398979187, \"sum\": 3842.65398979187, \"min\": 3842.65398979187}}, \"EndTime\": 1601798190.522293, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798186.679159}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:30 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=155.356322144 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:30 INFO 139662618720064] #progress_metric: host=algo-1, completed 76 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:30 INFO 139662618720064] #quality_metric: host=algo-1, epoch=303, train loss <loss>=1.09448128939\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:30 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:31 INFO 139662618720064] Epoch[304] Batch[0] avg_epoch_loss=1.079005\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:31 INFO 139662618720064] #quality_metric: host=algo-1, epoch=304, batch=0 train loss <loss>=1.07900464535\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:33 INFO 139662618720064] Epoch[304] Batch[5] avg_epoch_loss=0.919119\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:33 INFO 139662618720064] #quality_metric: host=algo-1, epoch=304, batch=5 train loss <loss>=0.919119119644\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:33 INFO 139662618720064] Epoch[304] Batch [5]#011Speed: 186.54 samples/sec#011loss=0.919119\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:34 INFO 139662618720064] processed a total of 602 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3874.121904373169, \"sum\": 3874.121904373169, \"min\": 3874.121904373169}}, \"EndTime\": 1601798194.397003, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798190.522377}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:34 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=155.385068807 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:34 INFO 139662618720064] #progress_metric: host=algo-1, completed 76 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:34 INFO 139662618720064] #quality_metric: host=algo-1, epoch=304, train loss <loss>=0.874931824207\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:34 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:35 INFO 139662618720064] Epoch[305] Batch[0] avg_epoch_loss=0.939570\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:35 INFO 139662618720064] #quality_metric: host=algo-1, epoch=305, batch=0 train loss <loss>=0.939569592476\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:36 INFO 139662618720064] Epoch[305] Batch[5] avg_epoch_loss=0.939249\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:36 INFO 139662618720064] #quality_metric: host=algo-1, epoch=305, batch=5 train loss <loss>=0.93924883008\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:36 INFO 139662618720064] Epoch[305] Batch [5]#011Speed: 187.64 samples/sec#011loss=0.939249\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:38 INFO 139662618720064] Epoch[305] Batch[10] avg_epoch_loss=0.915356\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:38 INFO 139662618720064] #quality_metric: host=algo-1, epoch=305, batch=10 train loss <loss>=0.886685466766\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:38 INFO 139662618720064] Epoch[305] Batch [10]#011Speed: 188.88 samples/sec#011loss=0.886685\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:38 INFO 139662618720064] processed a total of 668 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4254.338026046753, \"sum\": 4254.338026046753, \"min\": 4254.338026046753}}, \"EndTime\": 1601798198.651909, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798194.397086}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:38 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=157.011767497 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:38 INFO 139662618720064] #progress_metric: host=algo-1, completed 76 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:38 INFO 139662618720064] #quality_metric: host=algo-1, epoch=305, train loss <loss>=0.91535639221\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:38 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:39 INFO 139662618720064] Epoch[306] Batch[0] avg_epoch_loss=1.080186\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:39 INFO 139662618720064] #quality_metric: host=algo-1, epoch=306, batch=0 train loss <loss>=1.08018565178\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:41 INFO 139662618720064] Epoch[306] Batch[5] avg_epoch_loss=0.991520\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:41 INFO 139662618720064] #quality_metric: host=algo-1, epoch=306, batch=5 train loss <loss>=0.991519987583\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:41 INFO 139662618720064] Epoch[306] Batch [5]#011Speed: 188.62 samples/sec#011loss=0.991520\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:42 INFO 139662618720064] Epoch[306] Batch[10] avg_epoch_loss=1.003186\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:42 INFO 139662618720064] #quality_metric: host=algo-1, epoch=306, batch=10 train loss <loss>=1.01718621254\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:42 INFO 139662618720064] Epoch[306] Batch [10]#011Speed: 187.75 samples/sec#011loss=1.017186\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:42 INFO 139662618720064] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4213.038921356201, \"sum\": 4213.038921356201, \"min\": 4213.038921356201}}, \"EndTime\": 1601798202.865473, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798198.65199}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:42 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=156.17753947 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:42 INFO 139662618720064] #progress_metric: host=algo-1, completed 76 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:42 INFO 139662618720064] #quality_metric: host=algo-1, epoch=306, train loss <loss>=1.00318645347\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:42 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:43 INFO 139662618720064] Epoch[307] Batch[0] avg_epoch_loss=0.910639\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:43 INFO 139662618720064] #quality_metric: host=algo-1, epoch=307, batch=0 train loss <loss>=0.910638749599\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:45 INFO 139662618720064] Epoch[307] Batch[5] avg_epoch_loss=0.842547\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:45 INFO 139662618720064] #quality_metric: host=algo-1, epoch=307, batch=5 train loss <loss>=0.842547466358\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:45 INFO 139662618720064] Epoch[307] Batch [5]#011Speed: 189.58 samples/sec#011loss=0.842547\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:47 INFO 139662618720064] Epoch[307] Batch[10] avg_epoch_loss=0.868532\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:47 INFO 139662618720064] #quality_metric: host=algo-1, epoch=307, batch=10 train loss <loss>=0.899714100361\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:47 INFO 139662618720064] Epoch[307] Batch [10]#011Speed: 182.47 samples/sec#011loss=0.899714\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:47 INFO 139662618720064] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4236.217975616455, \"sum\": 4236.217975616455, \"min\": 4236.217975616455}}, \"EndTime\": 1601798207.102189, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798202.86555}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:47 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=153.670349025 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:47 INFO 139662618720064] #progress_metric: host=algo-1, completed 77 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:47 INFO 139662618720064] #quality_metric: host=algo-1, epoch=307, train loss <loss>=0.868532299995\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:47 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:47 INFO 139662618720064] Epoch[308] Batch[0] avg_epoch_loss=0.881424\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:47 INFO 139662618720064] #quality_metric: host=algo-1, epoch=308, batch=0 train loss <loss>=0.881423592567\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:49 INFO 139662618720064] Epoch[308] Batch[5] avg_epoch_loss=0.986726\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:49 INFO 139662618720064] #quality_metric: host=algo-1, epoch=308, batch=5 train loss <loss>=0.986725568771\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:49 INFO 139662618720064] Epoch[308] Batch [5]#011Speed: 189.86 samples/sec#011loss=0.986726\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:51 INFO 139662618720064] Epoch[308] Batch[10] avg_epoch_loss=0.908025\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:51 INFO 139662618720064] #quality_metric: host=algo-1, epoch=308, batch=10 train loss <loss>=0.813583856821\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:51 INFO 139662618720064] Epoch[308] Batch [10]#011Speed: 187.40 samples/sec#011loss=0.813584\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:51 INFO 139662618720064] processed a total of 677 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4217.242956161499, \"sum\": 4217.242956161499, \"min\": 4217.242956161499}}, \"EndTime\": 1601798211.319998, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798207.102273}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:51 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=160.526210764 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:51 INFO 139662618720064] #progress_metric: host=algo-1, completed 77 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:51 INFO 139662618720064] #quality_metric: host=algo-1, epoch=308, train loss <loss>=0.908024790612\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:51 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:52 INFO 139662618720064] Epoch[309] Batch[0] avg_epoch_loss=0.877483\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:52 INFO 139662618720064] #quality_metric: host=algo-1, epoch=309, batch=0 train loss <loss>=0.87748259306\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:53 INFO 139662618720064] Epoch[309] Batch[5] avg_epoch_loss=0.944132\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:53 INFO 139662618720064] #quality_metric: host=algo-1, epoch=309, batch=5 train loss <loss>=0.944132139285\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:53 INFO 139662618720064] Epoch[309] Batch [5]#011Speed: 187.83 samples/sec#011loss=0.944132\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:55 INFO 139662618720064] Epoch[309] Batch[10] avg_epoch_loss=1.085272\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:55 INFO 139662618720064] #quality_metric: host=algo-1, epoch=309, batch=10 train loss <loss>=1.25463988781\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:55 INFO 139662618720064] Epoch[309] Batch [10]#011Speed: 189.56 samples/sec#011loss=1.254640\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:55 INFO 139662618720064] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4214.817047119141, \"sum\": 4214.817047119141, \"min\": 4214.817047119141}}, \"EndTime\": 1601798215.535355, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798211.320076}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:55 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=154.925202311 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:55 INFO 139662618720064] #progress_metric: host=algo-1, completed 77 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:55 INFO 139662618720064] #quality_metric: host=algo-1, epoch=309, train loss <loss>=1.08527202498\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:55 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:56 INFO 139662618720064] Epoch[310] Batch[0] avg_epoch_loss=0.867341\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:56 INFO 139662618720064] #quality_metric: host=algo-1, epoch=310, batch=0 train loss <loss>=0.867341041565\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:58 INFO 139662618720064] Epoch[310] Batch[5] avg_epoch_loss=0.966140\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:58 INFO 139662618720064] #quality_metric: host=algo-1, epoch=310, batch=5 train loss <loss>=0.966140111287\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:58 INFO 139662618720064] Epoch[310] Batch [5]#011Speed: 185.93 samples/sec#011loss=0.966140\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:59 INFO 139662618720064] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3904.0539264678955, \"sum\": 3904.0539264678955, \"min\": 3904.0539264678955}}, \"EndTime\": 1601798219.43993, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798215.535435}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:59 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=159.828733422 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:59 INFO 139662618720064] #progress_metric: host=algo-1, completed 77 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:59 INFO 139662618720064] #quality_metric: host=algo-1, epoch=310, train loss <loss>=0.9816188097\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:56:59 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:00 INFO 139662618720064] Epoch[311] Batch[0] avg_epoch_loss=1.159481\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:00 INFO 139662618720064] #quality_metric: host=algo-1, epoch=311, batch=0 train loss <loss>=1.159481287\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:01 INFO 139662618720064] Epoch[311] Batch[5] avg_epoch_loss=1.027900\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:01 INFO 139662618720064] #quality_metric: host=algo-1, epoch=311, batch=5 train loss <loss>=1.02790048718\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:01 INFO 139662618720064] Epoch[311] Batch [5]#011Speed: 185.60 samples/sec#011loss=1.027900\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:03 INFO 139662618720064] Epoch[311] Batch[10] avg_epoch_loss=1.018247\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:03 INFO 139662618720064] #quality_metric: host=algo-1, epoch=311, batch=10 train loss <loss>=1.00666335821\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:03 INFO 139662618720064] Epoch[311] Batch [10]#011Speed: 186.47 samples/sec#011loss=1.006663\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:03 INFO 139662618720064] processed a total of 680 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4265.708923339844, \"sum\": 4265.708923339844, \"min\": 4265.708923339844}}, \"EndTime\": 1601798223.706216, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798219.440016}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:03 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=159.406818363 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:03 INFO 139662618720064] #progress_metric: host=algo-1, completed 78 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:03 INFO 139662618720064] #quality_metric: host=algo-1, epoch=311, train loss <loss>=1.01824724674\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:03 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:04 INFO 139662618720064] Epoch[312] Batch[0] avg_epoch_loss=1.098410\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:04 INFO 139662618720064] #quality_metric: host=algo-1, epoch=312, batch=0 train loss <loss>=1.09841012955\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:06 INFO 139662618720064] Epoch[312] Batch[5] avg_epoch_loss=0.960718\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:06 INFO 139662618720064] #quality_metric: host=algo-1, epoch=312, batch=5 train loss <loss>=0.960718164841\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:06 INFO 139662618720064] Epoch[312] Batch [5]#011Speed: 187.86 samples/sec#011loss=0.960718\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:07 INFO 139662618720064] Epoch[312] Batch[10] avg_epoch_loss=0.909803\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:07 INFO 139662618720064] #quality_metric: host=algo-1, epoch=312, batch=10 train loss <loss>=0.848705077171\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:07 INFO 139662618720064] Epoch[312] Batch [10]#011Speed: 185.98 samples/sec#011loss=0.848705\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:07 INFO 139662618720064] processed a total of 691 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4228.842973709106, \"sum\": 4228.842973709106, \"min\": 4228.842973709106}}, \"EndTime\": 1601798227.935601, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798223.70628}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:07 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=163.397145851 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:07 INFO 139662618720064] #progress_metric: host=algo-1, completed 78 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:07 INFO 139662618720064] #quality_metric: host=algo-1, epoch=312, train loss <loss>=0.909803124991\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:07 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:08 INFO 139662618720064] Epoch[313] Batch[0] avg_epoch_loss=0.925459\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:08 INFO 139662618720064] #quality_metric: host=algo-1, epoch=313, batch=0 train loss <loss>=0.925458788872\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:10 INFO 139662618720064] Epoch[313] Batch[5] avg_epoch_loss=0.932104\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:10 INFO 139662618720064] #quality_metric: host=algo-1, epoch=313, batch=5 train loss <loss>=0.932104488214\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:10 INFO 139662618720064] Epoch[313] Batch [5]#011Speed: 185.86 samples/sec#011loss=0.932104\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:11 INFO 139662618720064] processed a total of 617 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3920.820951461792, \"sum\": 3920.820951461792, \"min\": 3920.820951461792}}, \"EndTime\": 1601798231.856961, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798227.935679}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:11 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=157.359940906 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:11 INFO 139662618720064] #progress_metric: host=algo-1, completed 78 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:11 INFO 139662618720064] #quality_metric: host=algo-1, epoch=313, train loss <loss>=0.943289059401\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:11 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:12 INFO 139662618720064] Epoch[314] Batch[0] avg_epoch_loss=0.804800\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:12 INFO 139662618720064] #quality_metric: host=algo-1, epoch=314, batch=0 train loss <loss>=0.804800391197\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:14 INFO 139662618720064] Epoch[314] Batch[5] avg_epoch_loss=0.918722\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:14 INFO 139662618720064] #quality_metric: host=algo-1, epoch=314, batch=5 train loss <loss>=0.918721894423\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:14 INFO 139662618720064] Epoch[314] Batch [5]#011Speed: 188.69 samples/sec#011loss=0.918722\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:15 INFO 139662618720064] processed a total of 592 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3888.6661529541016, \"sum\": 3888.6661529541016, \"min\": 3888.6661529541016}}, \"EndTime\": 1601798235.746191, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798231.857046}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:15 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=152.232437369 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:15 INFO 139662618720064] #progress_metric: host=algo-1, completed 78 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:15 INFO 139662618720064] #quality_metric: host=algo-1, epoch=314, train loss <loss>=0.961386984587\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:15 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:16 INFO 139662618720064] Epoch[315] Batch[0] avg_epoch_loss=0.916448\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:16 INFO 139662618720064] #quality_metric: host=algo-1, epoch=315, batch=0 train loss <loss>=0.916447937489\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:18 INFO 139662618720064] Epoch[315] Batch[5] avg_epoch_loss=0.893862\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:18 INFO 139662618720064] #quality_metric: host=algo-1, epoch=315, batch=5 train loss <loss>=0.893862277269\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:18 INFO 139662618720064] Epoch[315] Batch [5]#011Speed: 187.83 samples/sec#011loss=0.893862\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:19 INFO 139662618720064] Epoch[315] Batch[10] avg_epoch_loss=0.833118\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:19 INFO 139662618720064] #quality_metric: host=algo-1, epoch=315, batch=10 train loss <loss>=0.760225638002\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:19 INFO 139662618720064] Epoch[315] Batch [10]#011Speed: 189.12 samples/sec#011loss=0.760226\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:19 INFO 139662618720064] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4204.154968261719, \"sum\": 4204.154968261719, \"min\": 4204.154968261719}}, \"EndTime\": 1601798239.950929, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798235.746275}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:19 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=154.604648578 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:19 INFO 139662618720064] #progress_metric: host=algo-1, completed 79 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:19 INFO 139662618720064] #quality_metric: host=algo-1, epoch=315, train loss <loss>=0.83311835033\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:19 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:20 INFO 139662618720064] Epoch[316] Batch[0] avg_epoch_loss=0.947645\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:20 INFO 139662618720064] #quality_metric: host=algo-1, epoch=316, batch=0 train loss <loss>=0.94764482975\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:22 INFO 139662618720064] Epoch[316] Batch[5] avg_epoch_loss=0.907695\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:22 INFO 139662618720064] #quality_metric: host=algo-1, epoch=316, batch=5 train loss <loss>=0.907695402702\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:22 INFO 139662618720064] Epoch[316] Batch [5]#011Speed: 186.30 samples/sec#011loss=0.907695\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:23 INFO 139662618720064] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3887.777090072632, \"sum\": 3887.777090072632, \"min\": 3887.777090072632}}, \"EndTime\": 1601798243.839215, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798239.951008}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:23 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=159.726208185 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:23 INFO 139662618720064] #progress_metric: host=algo-1, completed 79 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:23 INFO 139662618720064] #quality_metric: host=algo-1, epoch=316, train loss <loss>=0.918913781643\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:23 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:24 INFO 139662618720064] Epoch[317] Batch[0] avg_epoch_loss=0.996075\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:24 INFO 139662618720064] #quality_metric: host=algo-1, epoch=317, batch=0 train loss <loss>=0.99607527256\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:26 INFO 139662618720064] Epoch[317] Batch[5] avg_epoch_loss=0.923329\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:26 INFO 139662618720064] #quality_metric: host=algo-1, epoch=317, batch=5 train loss <loss>=0.923328727484\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:26 INFO 139662618720064] Epoch[317] Batch [5]#011Speed: 190.61 samples/sec#011loss=0.923329\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:28 INFO 139662618720064] Epoch[317] Batch[10] avg_epoch_loss=0.894426\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:28 INFO 139662618720064] #quality_metric: host=algo-1, epoch=317, batch=10 train loss <loss>=0.859742176533\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:28 INFO 139662618720064] Epoch[317] Batch [10]#011Speed: 186.91 samples/sec#011loss=0.859742\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:28 INFO 139662618720064] processed a total of 684 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4212.831020355225, \"sum\": 4212.831020355225, \"min\": 4212.831020355225}}, \"EndTime\": 1601798248.052594, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798243.839301}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:28 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=162.356580605 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:28 INFO 139662618720064] #progress_metric: host=algo-1, completed 79 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:28 INFO 139662618720064] #quality_metric: host=algo-1, epoch=317, train loss <loss>=0.894425749779\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:28 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:28 INFO 139662618720064] Epoch[318] Batch[0] avg_epoch_loss=1.128416\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:28 INFO 139662618720064] #quality_metric: host=algo-1, epoch=318, batch=0 train loss <loss>=1.12841594219\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:30 INFO 139662618720064] Epoch[318] Batch[5] avg_epoch_loss=0.997508\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:30 INFO 139662618720064] #quality_metric: host=algo-1, epoch=318, batch=5 train loss <loss>=0.99750778079\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:30 INFO 139662618720064] Epoch[318] Batch [5]#011Speed: 189.59 samples/sec#011loss=0.997508\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:32 INFO 139662618720064] Epoch[318] Batch[10] avg_epoch_loss=0.917572\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:32 INFO 139662618720064] #quality_metric: host=algo-1, epoch=318, batch=10 train loss <loss>=0.821648430824\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:32 INFO 139662618720064] Epoch[318] Batch [10]#011Speed: 188.40 samples/sec#011loss=0.821648\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:32 INFO 139662618720064] processed a total of 674 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4209.930896759033, \"sum\": 4209.930896759033, \"min\": 4209.930896759033}}, \"EndTime\": 1601798252.263044, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798248.052674}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:32 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=160.093115567 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:32 INFO 139662618720064] #progress_metric: host=algo-1, completed 79 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:32 INFO 139662618720064] #quality_metric: host=algo-1, epoch=318, train loss <loss>=0.917571712624\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:32 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:33 INFO 139662618720064] Epoch[319] Batch[0] avg_epoch_loss=1.024196\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:33 INFO 139662618720064] #quality_metric: host=algo-1, epoch=319, batch=0 train loss <loss>=1.02419638634\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:34 INFO 139662618720064] Epoch[319] Batch[5] avg_epoch_loss=0.889554\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:34 INFO 139662618720064] #quality_metric: host=algo-1, epoch=319, batch=5 train loss <loss>=0.889554262161\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:34 INFO 139662618720064] Epoch[319] Batch [5]#011Speed: 188.00 samples/sec#011loss=0.889554\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:36 INFO 139662618720064] Epoch[319] Batch[10] avg_epoch_loss=0.957883\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:36 INFO 139662618720064] #quality_metric: host=algo-1, epoch=319, batch=10 train loss <loss>=1.03987689018\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:36 INFO 139662618720064] Epoch[319] Batch [10]#011Speed: 188.05 samples/sec#011loss=1.039877\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:36 INFO 139662618720064] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4258.6541175842285, \"sum\": 4258.6541175842285, \"min\": 4258.6541175842285}}, \"EndTime\": 1601798256.52222, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798252.263123}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:36 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=151.921620804 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:36 INFO 139662618720064] #progress_metric: host=algo-1, completed 80 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:36 INFO 139662618720064] #quality_metric: host=algo-1, epoch=319, train loss <loss>=0.957882729444\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:36 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:37 INFO 139662618720064] Epoch[320] Batch[0] avg_epoch_loss=0.755845\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:37 INFO 139662618720064] #quality_metric: host=algo-1, epoch=320, batch=0 train loss <loss>=0.755844652653\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:39 INFO 139662618720064] Epoch[320] Batch[5] avg_epoch_loss=0.979645\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:39 INFO 139662618720064] #quality_metric: host=algo-1, epoch=320, batch=5 train loss <loss>=0.979645083348\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:39 INFO 139662618720064] Epoch[320] Batch [5]#011Speed: 188.12 samples/sec#011loss=0.979645\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:40 INFO 139662618720064] Epoch[320] Batch[10] avg_epoch_loss=0.994393\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:40 INFO 139662618720064] #quality_metric: host=algo-1, epoch=320, batch=10 train loss <loss>=1.01208992004\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:40 INFO 139662618720064] Epoch[320] Batch [10]#011Speed: 188.99 samples/sec#011loss=1.012090\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:40 INFO 139662618720064] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4189.516067504883, \"sum\": 4189.516067504883, \"min\": 4189.516067504883}}, \"EndTime\": 1601798260.712293, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798256.522299}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:40 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=152.996585196 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:40 INFO 139662618720064] #progress_metric: host=algo-1, completed 80 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:40 INFO 139662618720064] #quality_metric: host=algo-1, epoch=320, train loss <loss>=0.994392736392\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:40 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:41 INFO 139662618720064] Epoch[321] Batch[0] avg_epoch_loss=1.183612\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:41 INFO 139662618720064] #quality_metric: host=algo-1, epoch=321, batch=0 train loss <loss>=1.18361234665\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:43 INFO 139662618720064] Epoch[321] Batch[5] avg_epoch_loss=1.272955\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:43 INFO 139662618720064] #quality_metric: host=algo-1, epoch=321, batch=5 train loss <loss>=1.27295541763\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:43 INFO 139662618720064] Epoch[321] Batch [5]#011Speed: 187.27 samples/sec#011loss=1.272955\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:44 INFO 139662618720064] Epoch[321] Batch[10] avg_epoch_loss=1.199050\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:44 INFO 139662618720064] #quality_metric: host=algo-1, epoch=321, batch=10 train loss <loss>=1.11036448479\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:44 INFO 139662618720064] Epoch[321] Batch [10]#011Speed: 189.85 samples/sec#011loss=1.110364\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:44 INFO 139662618720064] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4204.291105270386, \"sum\": 4204.291105270386, \"min\": 4204.291105270386}}, \"EndTime\": 1601798264.917093, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798260.712372}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:44 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=155.313108896 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:44 INFO 139662618720064] #progress_metric: host=algo-1, completed 80 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:44 INFO 139662618720064] #quality_metric: host=algo-1, epoch=321, train loss <loss>=1.19905044816\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:44 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:45 INFO 139662618720064] Epoch[322] Batch[0] avg_epoch_loss=1.159241\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:45 INFO 139662618720064] #quality_metric: host=algo-1, epoch=322, batch=0 train loss <loss>=1.15924060345\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:47 INFO 139662618720064] Epoch[322] Batch[5] avg_epoch_loss=1.120265\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:47 INFO 139662618720064] #quality_metric: host=algo-1, epoch=322, batch=5 train loss <loss>=1.12026458979\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:47 INFO 139662618720064] Epoch[322] Batch [5]#011Speed: 184.77 samples/sec#011loss=1.120265\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:48 INFO 139662618720064] processed a total of 608 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3918.926954269409, \"sum\": 3918.926954269409, \"min\": 3918.926954269409}}, \"EndTime\": 1601798268.83654, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798264.917173}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:48 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=155.139280649 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:48 INFO 139662618720064] #progress_metric: host=algo-1, completed 80 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:48 INFO 139662618720064] #quality_metric: host=algo-1, epoch=322, train loss <loss>=1.06555873752\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:48 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:49 INFO 139662618720064] Epoch[323] Batch[0] avg_epoch_loss=1.084342\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:49 INFO 139662618720064] #quality_metric: host=algo-1, epoch=323, batch=0 train loss <loss>=1.08434212208\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:51 INFO 139662618720064] Epoch[323] Batch[5] avg_epoch_loss=1.004911\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:51 INFO 139662618720064] #quality_metric: host=algo-1, epoch=323, batch=5 train loss <loss>=1.00491127372\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:51 INFO 139662618720064] Epoch[323] Batch [5]#011Speed: 189.70 samples/sec#011loss=1.004911\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:52 INFO 139662618720064] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3841.804027557373, \"sum\": 3841.804027557373, \"min\": 3841.804027557373}}, \"EndTime\": 1601798272.678965, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798268.836628}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:52 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=165.281433863 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:52 INFO 139662618720064] #progress_metric: host=algo-1, completed 81 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:52 INFO 139662618720064] #quality_metric: host=algo-1, epoch=323, train loss <loss>=0.990150511265\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:52 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:53 INFO 139662618720064] Epoch[324] Batch[0] avg_epoch_loss=0.988918\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:53 INFO 139662618720064] #quality_metric: host=algo-1, epoch=324, batch=0 train loss <loss>=0.98891800642\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:55 INFO 139662618720064] Epoch[324] Batch[5] avg_epoch_loss=0.999208\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:55 INFO 139662618720064] #quality_metric: host=algo-1, epoch=324, batch=5 train loss <loss>=0.999208201965\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:55 INFO 139662618720064] Epoch[324] Batch [5]#011Speed: 188.65 samples/sec#011loss=0.999208\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:56 INFO 139662618720064] Epoch[324] Batch[10] avg_epoch_loss=1.204128\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:56 INFO 139662618720064] #quality_metric: host=algo-1, epoch=324, batch=10 train loss <loss>=1.45003176928\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:56 INFO 139662618720064] Epoch[324] Batch [10]#011Speed: 184.07 samples/sec#011loss=1.450032\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:56 INFO 139662618720064] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4284.966945648193, \"sum\": 4284.966945648193, \"min\": 4284.966945648193}}, \"EndTime\": 1601798276.964508, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798272.67905}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:56 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=150.988871774 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:56 INFO 139662618720064] #progress_metric: host=algo-1, completed 81 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:56 INFO 139662618720064] #quality_metric: host=algo-1, epoch=324, train loss <loss>=1.20412800529\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:56 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:57 INFO 139662618720064] Epoch[325] Batch[0] avg_epoch_loss=1.030170\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:57 INFO 139662618720064] #quality_metric: host=algo-1, epoch=325, batch=0 train loss <loss>=1.03017008305\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:59 INFO 139662618720064] Epoch[325] Batch[5] avg_epoch_loss=0.955140\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:59 INFO 139662618720064] #quality_metric: host=algo-1, epoch=325, batch=5 train loss <loss>=0.955139527718\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:57:59 INFO 139662618720064] Epoch[325] Batch [5]#011Speed: 186.11 samples/sec#011loss=0.955140\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:01 INFO 139662618720064] Epoch[325] Batch[10] avg_epoch_loss=0.948541\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:01 INFO 139662618720064] #quality_metric: host=algo-1, epoch=325, batch=10 train loss <loss>=0.940622675419\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:01 INFO 139662618720064] Epoch[325] Batch [10]#011Speed: 187.57 samples/sec#011loss=0.940623\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:01 INFO 139662618720064] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4218.891859054565, \"sum\": 4218.891859054565, \"min\": 4218.891859054565}}, \"EndTime\": 1601798281.183954, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798276.964584}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:01 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=157.620178505 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:01 INFO 139662618720064] #progress_metric: host=algo-1, completed 81 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:01 INFO 139662618720064] #quality_metric: host=algo-1, epoch=325, train loss <loss>=0.948540958491\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:01 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:01 INFO 139662618720064] Epoch[326] Batch[0] avg_epoch_loss=0.858045\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:01 INFO 139662618720064] #quality_metric: host=algo-1, epoch=326, batch=0 train loss <loss>=0.858045399189\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:03 INFO 139662618720064] Epoch[326] Batch[5] avg_epoch_loss=0.942705\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:03 INFO 139662618720064] #quality_metric: host=algo-1, epoch=326, batch=5 train loss <loss>=0.94270542264\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:03 INFO 139662618720064] Epoch[326] Batch [5]#011Speed: 184.71 samples/sec#011loss=0.942705\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:05 INFO 139662618720064] processed a total of 605 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3902.729034423828, \"sum\": 3902.729034423828, \"min\": 3902.729034423828}}, \"EndTime\": 1601798285.087238, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798281.184025}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:05 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=155.014805356 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:05 INFO 139662618720064] #progress_metric: host=algo-1, completed 81 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:05 INFO 139662618720064] #quality_metric: host=algo-1, epoch=326, train loss <loss>=0.911519032717\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:05 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:05 INFO 139662618720064] Epoch[327] Batch[0] avg_epoch_loss=0.915844\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:05 INFO 139662618720064] #quality_metric: host=algo-1, epoch=327, batch=0 train loss <loss>=0.915843904018\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:07 INFO 139662618720064] Epoch[327] Batch[5] avg_epoch_loss=0.946479\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:07 INFO 139662618720064] #quality_metric: host=algo-1, epoch=327, batch=5 train loss <loss>=0.946479469538\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:07 INFO 139662618720064] Epoch[327] Batch [5]#011Speed: 189.01 samples/sec#011loss=0.946479\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:08 INFO 139662618720064] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3868.0241107940674, \"sum\": 3868.0241107940674, \"min\": 3868.0241107940674}}, \"EndTime\": 1601798288.955817, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798285.087321}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:08 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=164.419684007 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:08 INFO 139662618720064] #progress_metric: host=algo-1, completed 82 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:08 INFO 139662618720064] #quality_metric: host=algo-1, epoch=327, train loss <loss>=0.93447971344\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:08 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:09 INFO 139662618720064] Epoch[328] Batch[0] avg_epoch_loss=0.630679\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:09 INFO 139662618720064] #quality_metric: host=algo-1, epoch=328, batch=0 train loss <loss>=0.630678594112\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:11 INFO 139662618720064] Epoch[328] Batch[5] avg_epoch_loss=0.780139\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:11 INFO 139662618720064] #quality_metric: host=algo-1, epoch=328, batch=5 train loss <loss>=0.78013887008\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:11 INFO 139662618720064] Epoch[328] Batch [5]#011Speed: 188.92 samples/sec#011loss=0.780139\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:12 INFO 139662618720064] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3895.869016647339, \"sum\": 3895.869016647339, \"min\": 3895.869016647339}}, \"EndTime\": 1601798292.852246, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798288.955902}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:12 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=159.137775513 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:12 INFO 139662618720064] #progress_metric: host=algo-1, completed 82 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:12 INFO 139662618720064] #quality_metric: host=algo-1, epoch=328, train loss <loss>=0.813710284233\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:12 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:12 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_35c43dec-0dce-41b1-b05d-0b25f49d64e2-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 109.97915267944336, \"sum\": 109.97915267944336, \"min\": 109.97915267944336}}, \"EndTime\": 1601798292.962864, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798292.852332}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:13 INFO 139662618720064] Epoch[329] Batch[0] avg_epoch_loss=1.117772\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:13 INFO 139662618720064] #quality_metric: host=algo-1, epoch=329, batch=0 train loss <loss>=1.11777245998\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:15 INFO 139662618720064] Epoch[329] Batch[5] avg_epoch_loss=0.969493\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:15 INFO 139662618720064] #quality_metric: host=algo-1, epoch=329, batch=5 train loss <loss>=0.969492932161\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:15 INFO 139662618720064] Epoch[329] Batch [5]#011Speed: 189.52 samples/sec#011loss=0.969493\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:17 INFO 139662618720064] Epoch[329] Batch[10] avg_epoch_loss=0.921627\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:17 INFO 139662618720064] #quality_metric: host=algo-1, epoch=329, batch=10 train loss <loss>=0.864186799526\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:17 INFO 139662618720064] Epoch[329] Batch [10]#011Speed: 185.40 samples/sec#011loss=0.864187\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:17 INFO 139662618720064] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4231.084108352661, \"sum\": 4231.084108352661, \"min\": 4231.084108352661}}, \"EndTime\": 1601798297.19407, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798292.962927}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:17 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=155.984083569 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:17 INFO 139662618720064] #progress_metric: host=algo-1, completed 82 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:17 INFO 139662618720064] #quality_metric: host=algo-1, epoch=329, train loss <loss>=0.921626508236\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:17 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:18 INFO 139662618720064] Epoch[330] Batch[0] avg_epoch_loss=0.912561\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:18 INFO 139662618720064] #quality_metric: host=algo-1, epoch=330, batch=0 train loss <loss>=0.912561416626\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:19 INFO 139662618720064] Epoch[330] Batch[5] avg_epoch_loss=0.844666\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:19 INFO 139662618720064] #quality_metric: host=algo-1, epoch=330, batch=5 train loss <loss>=0.84466573596\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:19 INFO 139662618720064] Epoch[330] Batch [5]#011Speed: 189.26 samples/sec#011loss=0.844666\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:21 INFO 139662618720064] processed a total of 606 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3864.6509647369385, \"sum\": 3864.6509647369385, \"min\": 3864.6509647369385}}, \"EndTime\": 1601798301.059245, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798297.194148}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:21 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=156.800686586 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:21 INFO 139662618720064] #progress_metric: host=algo-1, completed 82 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:21 INFO 139662618720064] #quality_metric: host=algo-1, epoch=330, train loss <loss>=0.802305394411\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:21 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:21 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_241fca2e-51f7-408b-8f05-96854639f7cf-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 115.58103561401367, \"sum\": 115.58103561401367, \"min\": 115.58103561401367}}, \"EndTime\": 1601798301.175491, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798301.059332}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:21 INFO 139662618720064] Epoch[331] Batch[0] avg_epoch_loss=0.881742\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:21 INFO 139662618720064] #quality_metric: host=algo-1, epoch=331, batch=0 train loss <loss>=0.881742238998\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:23 INFO 139662618720064] Epoch[331] Batch[5] avg_epoch_loss=0.895185\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:23 INFO 139662618720064] #quality_metric: host=algo-1, epoch=331, batch=5 train loss <loss>=0.895185351372\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:23 INFO 139662618720064] Epoch[331] Batch [5]#011Speed: 187.32 samples/sec#011loss=0.895185\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:25 INFO 139662618720064] processed a total of 604 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3845.189094543457, \"sum\": 3845.189094543457, \"min\": 3845.189094543457}}, \"EndTime\": 1601798305.020811, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798301.175559}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:25 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=157.074297687 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:25 INFO 139662618720064] #progress_metric: host=algo-1, completed 83 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:25 INFO 139662618720064] #quality_metric: host=algo-1, epoch=331, train loss <loss>=0.850464019179\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:25 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:25 INFO 139662618720064] Epoch[332] Batch[0] avg_epoch_loss=0.973340\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:25 INFO 139662618720064] #quality_metric: host=algo-1, epoch=332, batch=0 train loss <loss>=0.973339676857\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:27 INFO 139662618720064] Epoch[332] Batch[5] avg_epoch_loss=1.036022\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:27 INFO 139662618720064] #quality_metric: host=algo-1, epoch=332, batch=5 train loss <loss>=1.03602188826\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:27 INFO 139662618720064] Epoch[332] Batch [5]#011Speed: 184.31 samples/sec#011loss=1.036022\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:29 INFO 139662618720064] Epoch[332] Batch[10] avg_epoch_loss=0.940819\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:29 INFO 139662618720064] #quality_metric: host=algo-1, epoch=332, batch=10 train loss <loss>=0.826574981213\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:29 INFO 139662618720064] Epoch[332] Batch [10]#011Speed: 187.35 samples/sec#011loss=0.826575\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:29 INFO 139662618720064] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4245.723009109497, \"sum\": 4245.723009109497, \"min\": 4245.723009109497}}, \"EndTime\": 1601798309.267083, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798305.020896}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:29 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=152.619725115 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:29 INFO 139662618720064] #progress_metric: host=algo-1, completed 83 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:29 INFO 139662618720064] #quality_metric: host=algo-1, epoch=332, train loss <loss>=0.940818748691\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:29 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:30 INFO 139662618720064] Epoch[333] Batch[0] avg_epoch_loss=0.795669\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:30 INFO 139662618720064] #quality_metric: host=algo-1, epoch=333, batch=0 train loss <loss>=0.795668780804\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:31 INFO 139662618720064] Epoch[333] Batch[5] avg_epoch_loss=0.900397\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:31 INFO 139662618720064] #quality_metric: host=algo-1, epoch=333, batch=5 train loss <loss>=0.90039669474\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:31 INFO 139662618720064] Epoch[333] Batch [5]#011Speed: 187.48 samples/sec#011loss=0.900397\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:33 INFO 139662618720064] Epoch[333] Batch[10] avg_epoch_loss=1.017676\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:33 INFO 139662618720064] #quality_metric: host=algo-1, epoch=333, batch=10 train loss <loss>=1.15841008425\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:33 INFO 139662618720064] Epoch[333] Batch [10]#011Speed: 185.41 samples/sec#011loss=1.158410\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:33 INFO 139662618720064] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4229.842901229858, \"sum\": 4229.842901229858, \"min\": 4229.842901229858}}, \"EndTime\": 1601798313.497468, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798309.267163}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:33 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=156.266139909 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:33 INFO 139662618720064] #progress_metric: host=algo-1, completed 83 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:33 INFO 139662618720064] #quality_metric: host=algo-1, epoch=333, train loss <loss>=1.01767550815\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:33 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:34 INFO 139662618720064] Epoch[334] Batch[0] avg_epoch_loss=0.915108\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:34 INFO 139662618720064] #quality_metric: host=algo-1, epoch=334, batch=0 train loss <loss>=0.915108323097\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:35 INFO 139662618720064] Epoch[334] Batch[5] avg_epoch_loss=0.901069\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:35 INFO 139662618720064] #quality_metric: host=algo-1, epoch=334, batch=5 train loss <loss>=0.901069422563\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:35 INFO 139662618720064] Epoch[334] Batch [5]#011Speed: 189.44 samples/sec#011loss=0.901069\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:37 INFO 139662618720064] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3856.8341732025146, \"sum\": 3856.8341732025146, \"min\": 3856.8341732025146}}, \"EndTime\": 1601798317.354887, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798313.497548}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:37 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=165.674262336 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:37 INFO 139662618720064] #progress_metric: host=algo-1, completed 83 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:37 INFO 139662618720064] #quality_metric: host=algo-1, epoch=334, train loss <loss>=0.894911623001\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:37 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:38 INFO 139662618720064] Epoch[335] Batch[0] avg_epoch_loss=0.964098\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:38 INFO 139662618720064] #quality_metric: host=algo-1, epoch=335, batch=0 train loss <loss>=0.964098274708\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:39 INFO 139662618720064] Epoch[335] Batch[5] avg_epoch_loss=0.901788\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:39 INFO 139662618720064] #quality_metric: host=algo-1, epoch=335, batch=5 train loss <loss>=0.901788393656\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:39 INFO 139662618720064] Epoch[335] Batch [5]#011Speed: 188.83 samples/sec#011loss=0.901788\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:41 INFO 139662618720064] Epoch[335] Batch[10] avg_epoch_loss=0.890560\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:41 INFO 139662618720064] #quality_metric: host=algo-1, epoch=335, batch=10 train loss <loss>=0.877086853981\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:41 INFO 139662618720064] Epoch[335] Batch [10]#011Speed: 189.36 samples/sec#011loss=0.877087\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:41 INFO 139662618720064] processed a total of 675 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4191.113233566284, \"sum\": 4191.113233566284, \"min\": 4191.113233566284}}, \"EndTime\": 1601798321.546564, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798317.354976}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:41 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=161.050462461 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:41 INFO 139662618720064] #progress_metric: host=algo-1, completed 84 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:41 INFO 139662618720064] #quality_metric: host=algo-1, epoch=335, train loss <loss>=0.890560421077\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:41 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:42 INFO 139662618720064] Epoch[336] Batch[0] avg_epoch_loss=0.926779\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:42 INFO 139662618720064] #quality_metric: host=algo-1, epoch=336, batch=0 train loss <loss>=0.926778554916\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:44 INFO 139662618720064] Epoch[336] Batch[5] avg_epoch_loss=0.895604\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:44 INFO 139662618720064] #quality_metric: host=algo-1, epoch=336, batch=5 train loss <loss>=0.895603964726\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:44 INFO 139662618720064] Epoch[336] Batch [5]#011Speed: 187.63 samples/sec#011loss=0.895604\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:45 INFO 139662618720064] processed a total of 617 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3882.0769786834717, \"sum\": 3882.0769786834717, \"min\": 3882.0769786834717}}, \"EndTime\": 1601798325.429202, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798321.546644}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:45 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=158.930376328 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:45 INFO 139662618720064] #progress_metric: host=algo-1, completed 84 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:45 INFO 139662618720064] #quality_metric: host=algo-1, epoch=336, train loss <loss>=0.92298732996\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:45 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:46 INFO 139662618720064] Epoch[337] Batch[0] avg_epoch_loss=0.874516\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:46 INFO 139662618720064] #quality_metric: host=algo-1, epoch=337, batch=0 train loss <loss>=0.87451583147\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:48 INFO 139662618720064] Epoch[337] Batch[5] avg_epoch_loss=0.906386\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:48 INFO 139662618720064] #quality_metric: host=algo-1, epoch=337, batch=5 train loss <loss>=0.906385799249\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:48 INFO 139662618720064] Epoch[337] Batch [5]#011Speed: 185.59 samples/sec#011loss=0.906386\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:49 INFO 139662618720064] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3952.255964279175, \"sum\": 3952.255964279175, \"min\": 3952.255964279175}}, \"EndTime\": 1601798329.382033, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798325.429287}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:49 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=160.156628806 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:49 INFO 139662618720064] #progress_metric: host=algo-1, completed 84 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:49 INFO 139662618720064] #quality_metric: host=algo-1, epoch=337, train loss <loss>=0.896600759029\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:49 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:50 INFO 139662618720064] Epoch[338] Batch[0] avg_epoch_loss=0.866210\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:50 INFO 139662618720064] #quality_metric: host=algo-1, epoch=338, batch=0 train loss <loss>=0.866209685802\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:51 INFO 139662618720064] Epoch[338] Batch[5] avg_epoch_loss=0.860264\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:51 INFO 139662618720064] #quality_metric: host=algo-1, epoch=338, batch=5 train loss <loss>=0.860264062881\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:51 INFO 139662618720064] Epoch[338] Batch [5]#011Speed: 187.94 samples/sec#011loss=0.860264\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:53 INFO 139662618720064] Epoch[338] Batch[10] avg_epoch_loss=0.907981\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:53 INFO 139662618720064] #quality_metric: host=algo-1, epoch=338, batch=10 train loss <loss>=0.965241980553\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:53 INFO 139662618720064] Epoch[338] Batch [10]#011Speed: 185.22 samples/sec#011loss=0.965242\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:53 INFO 139662618720064] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4285.420894622803, \"sum\": 4285.420894622803, \"min\": 4285.420894622803}}, \"EndTime\": 1601798333.668027, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798329.382117}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:53 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=152.839587617 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:53 INFO 139662618720064] #progress_metric: host=algo-1, completed 84 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:53 INFO 139662618720064] #quality_metric: host=algo-1, epoch=338, train loss <loss>=0.907981298187\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:53 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:54 INFO 139662618720064] Epoch[339] Batch[0] avg_epoch_loss=1.124694\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:54 INFO 139662618720064] #quality_metric: host=algo-1, epoch=339, batch=0 train loss <loss>=1.12469351292\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:56 INFO 139662618720064] Epoch[339] Batch[5] avg_epoch_loss=0.968856\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:56 INFO 139662618720064] #quality_metric: host=algo-1, epoch=339, batch=5 train loss <loss>=0.968856056531\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:56 INFO 139662618720064] Epoch[339] Batch [5]#011Speed: 188.29 samples/sec#011loss=0.968856\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:57 INFO 139662618720064] processed a total of 603 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3883.1589221954346, \"sum\": 3883.1589221954346, \"min\": 3883.1589221954346}}, \"EndTime\": 1601798337.551736, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798333.668107}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:57 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=155.280862679 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:57 INFO 139662618720064] #progress_metric: host=algo-1, completed 85 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:57 INFO 139662618720064] #quality_metric: host=algo-1, epoch=339, train loss <loss>=1.14262679219\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:57 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:58 INFO 139662618720064] Epoch[340] Batch[0] avg_epoch_loss=0.773836\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:58:58 INFO 139662618720064] #quality_metric: host=algo-1, epoch=340, batch=0 train loss <loss>=0.773835659027\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:00 INFO 139662618720064] Epoch[340] Batch[5] avg_epoch_loss=0.879624\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:00 INFO 139662618720064] #quality_metric: host=algo-1, epoch=340, batch=5 train loss <loss>=0.87962376078\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:00 INFO 139662618720064] Epoch[340] Batch [5]#011Speed: 189.00 samples/sec#011loss=0.879624\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:01 INFO 139662618720064] Epoch[340] Batch[10] avg_epoch_loss=0.915892\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:01 INFO 139662618720064] #quality_metric: host=algo-1, epoch=340, batch=10 train loss <loss>=0.95941324234\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:01 INFO 139662618720064] Epoch[340] Batch [10]#011Speed: 189.90 samples/sec#011loss=0.959413\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:01 INFO 139662618720064] processed a total of 689 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4212.492942810059, \"sum\": 4212.492942810059, \"min\": 4212.492942810059}}, \"EndTime\": 1601798341.76483, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798337.551821}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:01 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=163.556448621 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:01 INFO 139662618720064] #progress_metric: host=algo-1, completed 85 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:01 INFO 139662618720064] #quality_metric: host=algo-1, epoch=340, train loss <loss>=0.915891706944\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:01 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:02 INFO 139662618720064] Epoch[341] Batch[0] avg_epoch_loss=0.859535\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:02 INFO 139662618720064] #quality_metric: host=algo-1, epoch=341, batch=0 train loss <loss>=0.859534978867\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:04 INFO 139662618720064] Epoch[341] Batch[5] avg_epoch_loss=0.906913\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:04 INFO 139662618720064] #quality_metric: host=algo-1, epoch=341, batch=5 train loss <loss>=0.906912654638\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:04 INFO 139662618720064] Epoch[341] Batch [5]#011Speed: 189.04 samples/sec#011loss=0.906913\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:05 INFO 139662618720064] processed a total of 610 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3862.8950119018555, \"sum\": 3862.8950119018555, \"min\": 3862.8950119018555}}, \"EndTime\": 1601798345.628292, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798341.76491}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:05 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=157.907458447 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:05 INFO 139662618720064] #progress_metric: host=algo-1, completed 85 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:05 INFO 139662618720064] #quality_metric: host=algo-1, epoch=341, train loss <loss>=0.908507335186\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:05 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:06 INFO 139662618720064] Epoch[342] Batch[0] avg_epoch_loss=1.114219\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:06 INFO 139662618720064] #quality_metric: host=algo-1, epoch=342, batch=0 train loss <loss>=1.11421859264\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:08 INFO 139662618720064] Epoch[342] Batch[5] avg_epoch_loss=0.964327\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:08 INFO 139662618720064] #quality_metric: host=algo-1, epoch=342, batch=5 train loss <loss>=0.964326908191\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:08 INFO 139662618720064] Epoch[342] Batch [5]#011Speed: 187.81 samples/sec#011loss=0.964327\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:09 INFO 139662618720064] Epoch[342] Batch[10] avg_epoch_loss=0.914375\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:09 INFO 139662618720064] #quality_metric: host=algo-1, epoch=342, batch=10 train loss <loss>=0.854432451725\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:09 INFO 139662618720064] Epoch[342] Batch [10]#011Speed: 188.73 samples/sec#011loss=0.854432\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:09 INFO 139662618720064] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4231.122016906738, \"sum\": 4231.122016906738, \"min\": 4231.122016906738}}, \"EndTime\": 1601798349.860035, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798345.628378}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:09 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=156.691548189 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:09 INFO 139662618720064] #progress_metric: host=algo-1, completed 85 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:09 INFO 139662618720064] #quality_metric: host=algo-1, epoch=342, train loss <loss>=0.914374882525\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:09 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:10 INFO 139662618720064] Epoch[343] Batch[0] avg_epoch_loss=1.096114\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:10 INFO 139662618720064] #quality_metric: host=algo-1, epoch=343, batch=0 train loss <loss>=1.09611392021\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:12 INFO 139662618720064] Epoch[343] Batch[5] avg_epoch_loss=1.040242\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:12 INFO 139662618720064] #quality_metric: host=algo-1, epoch=343, batch=5 train loss <loss>=1.04024199645\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:12 INFO 139662618720064] Epoch[343] Batch [5]#011Speed: 179.17 samples/sec#011loss=1.040242\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:13 INFO 139662618720064] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4028.6099910736084, \"sum\": 4028.6099910736084, \"min\": 4028.6099910736084}}, \"EndTime\": 1601798353.889171, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798349.860114}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:13 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=158.858763564 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:13 INFO 139662618720064] #progress_metric: host=algo-1, completed 86 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:13 INFO 139662618720064] #quality_metric: host=algo-1, epoch=343, train loss <loss>=1.03640116453\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:13 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:14 INFO 139662618720064] Epoch[344] Batch[0] avg_epoch_loss=0.999589\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:14 INFO 139662618720064] #quality_metric: host=algo-1, epoch=344, batch=0 train loss <loss>=0.999588787556\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:16 INFO 139662618720064] Epoch[344] Batch[5] avg_epoch_loss=0.926205\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:16 INFO 139662618720064] #quality_metric: host=algo-1, epoch=344, batch=5 train loss <loss>=0.926205227772\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:16 INFO 139662618720064] Epoch[344] Batch [5]#011Speed: 187.09 samples/sec#011loss=0.926205\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:18 INFO 139662618720064] Epoch[344] Batch[10] avg_epoch_loss=0.855932\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:18 INFO 139662618720064] #quality_metric: host=algo-1, epoch=344, batch=10 train loss <loss>=0.77160461545\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:18 INFO 139662618720064] Epoch[344] Batch [10]#011Speed: 185.33 samples/sec#011loss=0.771605\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:18 INFO 139662618720064] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4338.186979293823, \"sum\": 4338.186979293823, \"min\": 4338.186979293823}}, \"EndTime\": 1601798358.22792, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798353.889255}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:18 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=150.057913239 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:18 INFO 139662618720064] #progress_metric: host=algo-1, completed 86 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:18 INFO 139662618720064] #quality_metric: host=algo-1, epoch=344, train loss <loss>=0.855932222171\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:18 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:19 INFO 139662618720064] Epoch[345] Batch[0] avg_epoch_loss=0.834416\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:19 INFO 139662618720064] #quality_metric: host=algo-1, epoch=345, batch=0 train loss <loss>=0.834416091442\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:20 INFO 139662618720064] Epoch[345] Batch[5] avg_epoch_loss=1.005973\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:20 INFO 139662618720064] #quality_metric: host=algo-1, epoch=345, batch=5 train loss <loss>=1.00597280264\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:20 INFO 139662618720064] Epoch[345] Batch [5]#011Speed: 187.98 samples/sec#011loss=1.005973\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:22 INFO 139662618720064] processed a total of 599 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3832.655906677246, \"sum\": 3832.655906677246, \"min\": 3832.655906677246}}, \"EndTime\": 1601798362.061117, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798358.228019}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:22 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=156.28334596 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:22 INFO 139662618720064] #progress_metric: host=algo-1, completed 86 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:22 INFO 139662618720064] #quality_metric: host=algo-1, epoch=345, train loss <loss>=0.990632754564\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:22 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:22 INFO 139662618720064] Epoch[346] Batch[0] avg_epoch_loss=0.820838\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:22 INFO 139662618720064] #quality_metric: host=algo-1, epoch=346, batch=0 train loss <loss>=0.820837855339\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:24 INFO 139662618720064] Epoch[346] Batch[5] avg_epoch_loss=0.897345\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:24 INFO 139662618720064] #quality_metric: host=algo-1, epoch=346, batch=5 train loss <loss>=0.897344956795\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:24 INFO 139662618720064] Epoch[346] Batch [5]#011Speed: 188.38 samples/sec#011loss=0.897345\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:26 INFO 139662618720064] Epoch[346] Batch[10] avg_epoch_loss=0.985172\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:26 INFO 139662618720064] #quality_metric: host=algo-1, epoch=346, batch=10 train loss <loss>=1.09056347609\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:26 INFO 139662618720064] Epoch[346] Batch [10]#011Speed: 187.95 samples/sec#011loss=1.090563\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:26 INFO 139662618720064] processed a total of 672 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4218.106985092163, \"sum\": 4218.106985092163, \"min\": 4218.106985092163}}, \"EndTime\": 1601798366.279803, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798362.061203}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:26 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=159.308749904 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:26 INFO 139662618720064] #progress_metric: host=algo-1, completed 86 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:26 INFO 139662618720064] #quality_metric: host=algo-1, epoch=346, train loss <loss>=0.985171556473\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:26 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:27 INFO 139662618720064] Epoch[347] Batch[0] avg_epoch_loss=0.758566\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:27 INFO 139662618720064] #quality_metric: host=algo-1, epoch=347, batch=0 train loss <loss>=0.758565723896\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:28 INFO 139662618720064] Epoch[347] Batch[5] avg_epoch_loss=0.929447\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:28 INFO 139662618720064] #quality_metric: host=algo-1, epoch=347, batch=5 train loss <loss>=0.92944697539\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:28 INFO 139662618720064] Epoch[347] Batch [5]#011Speed: 183.80 samples/sec#011loss=0.929447\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:30 INFO 139662618720064] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3895.782947540283, \"sum\": 3895.782947540283, \"min\": 3895.782947540283}}, \"EndTime\": 1601798370.176123, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798366.279879}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:30 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=160.938254554 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:30 INFO 139662618720064] #progress_metric: host=algo-1, completed 87 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:30 INFO 139662618720064] #quality_metric: host=algo-1, epoch=347, train loss <loss>=0.919713526964\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:30 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:30 INFO 139662618720064] Epoch[348] Batch[0] avg_epoch_loss=0.813252\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:30 INFO 139662618720064] #quality_metric: host=algo-1, epoch=348, batch=0 train loss <loss>=0.813252449036\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:32 INFO 139662618720064] Epoch[348] Batch[5] avg_epoch_loss=0.877617\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:32 INFO 139662618720064] #quality_metric: host=algo-1, epoch=348, batch=5 train loss <loss>=0.877617369095\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:32 INFO 139662618720064] Epoch[348] Batch [5]#011Speed: 184.52 samples/sec#011loss=0.877617\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:34 INFO 139662618720064] processed a total of 614 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3890.890121459961, \"sum\": 3890.890121459961, \"min\": 3890.890121459961}}, \"EndTime\": 1601798374.067634, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798370.1762}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:34 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=157.799605308 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:34 INFO 139662618720064] #progress_metric: host=algo-1, completed 87 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:34 INFO 139662618720064] #quality_metric: host=algo-1, epoch=348, train loss <loss>=0.883272486925\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:34 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:34 INFO 139662618720064] Epoch[349] Batch[0] avg_epoch_loss=0.854512\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:34 INFO 139662618720064] #quality_metric: host=algo-1, epoch=349, batch=0 train loss <loss>=0.854512214661\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:36 INFO 139662618720064] Epoch[349] Batch[5] avg_epoch_loss=0.949431\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:36 INFO 139662618720064] #quality_metric: host=algo-1, epoch=349, batch=5 train loss <loss>=0.949431031942\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:36 INFO 139662618720064] Epoch[349] Batch [5]#011Speed: 189.78 samples/sec#011loss=0.949431\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:37 INFO 139662618720064] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3872.704029083252, \"sum\": 3872.704029083252, \"min\": 3872.704029083252}}, \"EndTime\": 1601798377.940923, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798374.067711}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:37 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=160.348928983 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:37 INFO 139662618720064] #progress_metric: host=algo-1, completed 87 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:37 INFO 139662618720064] #quality_metric: host=algo-1, epoch=349, train loss <loss>=0.933357131481\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:37 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:38 INFO 139662618720064] Epoch[350] Batch[0] avg_epoch_loss=0.924471\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:38 INFO 139662618720064] #quality_metric: host=algo-1, epoch=350, batch=0 train loss <loss>=0.924471378326\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:40 INFO 139662618720064] Epoch[350] Batch[5] avg_epoch_loss=0.873539\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:40 INFO 139662618720064] #quality_metric: host=algo-1, epoch=350, batch=5 train loss <loss>=0.873539378246\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:40 INFO 139662618720064] Epoch[350] Batch [5]#011Speed: 188.06 samples/sec#011loss=0.873539\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:42 INFO 139662618720064] Epoch[350] Batch[10] avg_epoch_loss=0.768004\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:42 INFO 139662618720064] #quality_metric: host=algo-1, epoch=350, batch=10 train loss <loss>=0.641360755265\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:42 INFO 139662618720064] Epoch[350] Batch [10]#011Speed: 186.93 samples/sec#011loss=0.641361\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:42 INFO 139662618720064] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4207.725048065186, \"sum\": 4207.725048065186, \"min\": 4207.725048065186}}, \"EndTime\": 1601798382.149206, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798377.940986}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:42 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=153.998033995 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:42 INFO 139662618720064] #progress_metric: host=algo-1, completed 87 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:42 INFO 139662618720064] #quality_metric: host=algo-1, epoch=350, train loss <loss>=0.768003640527\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:42 INFO 139662618720064] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:42 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/state_c8747b56-e8d4-4472-923c-d782c51efa11-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 102.79202461242676, \"sum\": 102.79202461242676, \"min\": 102.79202461242676}}, \"EndTime\": 1601798382.252603, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798382.149286}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:43 INFO 139662618720064] Epoch[351] Batch[0] avg_epoch_loss=1.001848\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:43 INFO 139662618720064] #quality_metric: host=algo-1, epoch=351, batch=0 train loss <loss>=1.0018478632\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:44 INFO 139662618720064] Epoch[351] Batch[5] avg_epoch_loss=1.002486\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:44 INFO 139662618720064] #quality_metric: host=algo-1, epoch=351, batch=5 train loss <loss>=1.00248608987\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:44 INFO 139662618720064] Epoch[351] Batch [5]#011Speed: 185.31 samples/sec#011loss=1.002486\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:46 INFO 139662618720064] processed a total of 597 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3861.1860275268555, \"sum\": 3861.1860275268555, \"min\": 3861.1860275268555}}, \"EndTime\": 1601798386.113935, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798382.252677}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:46 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=154.610616602 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:46 INFO 139662618720064] #progress_metric: host=algo-1, completed 88 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:46 INFO 139662618720064] #quality_metric: host=algo-1, epoch=351, train loss <loss>=1.02511549592\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:46 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:46 INFO 139662618720064] Epoch[352] Batch[0] avg_epoch_loss=1.111097\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:46 INFO 139662618720064] #quality_metric: host=algo-1, epoch=352, batch=0 train loss <loss>=1.11109733582\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:48 INFO 139662618720064] Epoch[352] Batch[5] avg_epoch_loss=1.020011\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:48 INFO 139662618720064] #quality_metric: host=algo-1, epoch=352, batch=5 train loss <loss>=1.02001126607\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:48 INFO 139662618720064] Epoch[352] Batch [5]#011Speed: 186.69 samples/sec#011loss=1.020011\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:50 INFO 139662618720064] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3891.522169113159, \"sum\": 3891.522169113159, \"min\": 3891.522169113159}}, \"EndTime\": 1601798390.006041, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798386.114021}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:50 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=159.316893812 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:50 INFO 139662618720064] #progress_metric: host=algo-1, completed 88 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:50 INFO 139662618720064] #quality_metric: host=algo-1, epoch=352, train loss <loss>=0.977817773819\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:50 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:50 INFO 139662618720064] Epoch[353] Batch[0] avg_epoch_loss=1.029583\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:50 INFO 139662618720064] #quality_metric: host=algo-1, epoch=353, batch=0 train loss <loss>=1.02958321571\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:52 INFO 139662618720064] Epoch[353] Batch[5] avg_epoch_loss=0.933039\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:52 INFO 139662618720064] #quality_metric: host=algo-1, epoch=353, batch=5 train loss <loss>=0.933038651943\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:52 INFO 139662618720064] Epoch[353] Batch [5]#011Speed: 190.51 samples/sec#011loss=0.933039\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:54 INFO 139662618720064] Epoch[353] Batch[10] avg_epoch_loss=0.879811\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:54 INFO 139662618720064] #quality_metric: host=algo-1, epoch=353, batch=10 train loss <loss>=0.815938162804\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:54 INFO 139662618720064] Epoch[353] Batch [10]#011Speed: 185.75 samples/sec#011loss=0.815938\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:54 INFO 139662618720064] processed a total of 677 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4199.542999267578, \"sum\": 4199.542999267578, \"min\": 4199.542999267578}}, \"EndTime\": 1601798394.206147, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798390.006101}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:54 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=161.203450376 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:54 INFO 139662618720064] #progress_metric: host=algo-1, completed 88 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:54 INFO 139662618720064] #quality_metric: host=algo-1, epoch=353, train loss <loss>=0.87981115688\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:54 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:55 INFO 139662618720064] Epoch[354] Batch[0] avg_epoch_loss=0.856571\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:55 INFO 139662618720064] #quality_metric: host=algo-1, epoch=354, batch=0 train loss <loss>=0.856570959091\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:56 INFO 139662618720064] Epoch[354] Batch[5] avg_epoch_loss=0.919616\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:56 INFO 139662618720064] #quality_metric: host=algo-1, epoch=354, batch=5 train loss <loss>=0.919616430998\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:56 INFO 139662618720064] Epoch[354] Batch [5]#011Speed: 189.11 samples/sec#011loss=0.919616\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:58 INFO 139662618720064] processed a total of 616 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3869.3649768829346, \"sum\": 3869.3649768829346, \"min\": 3869.3649768829346}}, \"EndTime\": 1601798398.076085, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798394.206226}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:58 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=159.194109459 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:58 INFO 139662618720064] #progress_metric: host=algo-1, completed 88 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:58 INFO 139662618720064] #quality_metric: host=algo-1, epoch=354, train loss <loss>=0.885356342793\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:58 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:58 INFO 139662618720064] Epoch[355] Batch[0] avg_epoch_loss=0.979266\u001b[0m\n",
      "\u001b[34m[10/04/2020 07:59:58 INFO 139662618720064] #quality_metric: host=algo-1, epoch=355, batch=0 train loss <loss>=0.979266107082\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:00 INFO 139662618720064] Epoch[355] Batch[5] avg_epoch_loss=0.931498\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:00 INFO 139662618720064] #quality_metric: host=algo-1, epoch=355, batch=5 train loss <loss>=0.931497514248\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:00 INFO 139662618720064] Epoch[355] Batch [5]#011Speed: 186.78 samples/sec#011loss=0.931498\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:02 INFO 139662618720064] Epoch[355] Batch[10] avg_epoch_loss=0.855659\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:02 INFO 139662618720064] #quality_metric: host=algo-1, epoch=355, batch=10 train loss <loss>=0.764652645588\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:02 INFO 139662618720064] Epoch[355] Batch [10]#011Speed: 185.95 samples/sec#011loss=0.764653\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:02 INFO 139662618720064] processed a total of 676 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4236.180067062378, \"sum\": 4236.180067062378, \"min\": 4236.180067062378}}, \"EndTime\": 1601798402.312861, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798398.07617}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:02 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=159.573365462 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:02 INFO 139662618720064] #progress_metric: host=algo-1, completed 89 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:02 INFO 139662618720064] #quality_metric: host=algo-1, epoch=355, train loss <loss>=0.855658937584\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:02 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:03 INFO 139662618720064] Epoch[356] Batch[0] avg_epoch_loss=0.963462\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:03 INFO 139662618720064] #quality_metric: host=algo-1, epoch=356, batch=0 train loss <loss>=0.963461875916\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:04 INFO 139662618720064] Epoch[356] Batch[5] avg_epoch_loss=0.876172\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:04 INFO 139662618720064] #quality_metric: host=algo-1, epoch=356, batch=5 train loss <loss>=0.876172244549\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:04 INFO 139662618720064] Epoch[356] Batch [5]#011Speed: 188.25 samples/sec#011loss=0.876172\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:06 INFO 139662618720064] Epoch[356] Batch[10] avg_epoch_loss=0.869811\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:06 INFO 139662618720064] #quality_metric: host=algo-1, epoch=356, batch=10 train loss <loss>=0.862176966667\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:06 INFO 139662618720064] Epoch[356] Batch [10]#011Speed: 187.22 samples/sec#011loss=0.862177\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:06 INFO 139662618720064] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4205.005884170532, \"sum\": 4205.005884170532, \"min\": 4205.005884170532}}, \"EndTime\": 1601798406.518415, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798402.312938}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:06 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=156.475539237 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:06 INFO 139662618720064] #progress_metric: host=algo-1, completed 89 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:06 INFO 139662618720064] #quality_metric: host=algo-1, epoch=356, train loss <loss>=0.869810754603\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:06 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:07 INFO 139662618720064] Epoch[357] Batch[0] avg_epoch_loss=1.210006\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:07 INFO 139662618720064] #quality_metric: host=algo-1, epoch=357, batch=0 train loss <loss>=1.21000635624\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:09 INFO 139662618720064] Epoch[357] Batch[5] avg_epoch_loss=0.974813\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:09 INFO 139662618720064] #quality_metric: host=algo-1, epoch=357, batch=5 train loss <loss>=0.97481333216\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:09 INFO 139662618720064] Epoch[357] Batch [5]#011Speed: 187.61 samples/sec#011loss=0.974813\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:10 INFO 139662618720064] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3889.3120288848877, \"sum\": 3889.3120288848877, \"min\": 3889.3120288848877}}, \"EndTime\": 1601798410.40832, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798406.518496}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:10 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=160.178083631 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:10 INFO 139662618720064] #progress_metric: host=algo-1, completed 89 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:10 INFO 139662618720064] #quality_metric: host=algo-1, epoch=357, train loss <loss>=0.941004657745\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:10 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:11 INFO 139662618720064] Epoch[358] Batch[0] avg_epoch_loss=0.699829\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:11 INFO 139662618720064] #quality_metric: host=algo-1, epoch=358, batch=0 train loss <loss>=0.699829220772\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:12 INFO 139662618720064] Epoch[358] Batch[5] avg_epoch_loss=0.824608\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:12 INFO 139662618720064] #quality_metric: host=algo-1, epoch=358, batch=5 train loss <loss>=0.824607620637\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:12 INFO 139662618720064] Epoch[358] Batch [5]#011Speed: 189.24 samples/sec#011loss=0.824608\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:14 INFO 139662618720064] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3838.275909423828, \"sum\": 3838.275909423828, \"min\": 3838.275909423828}}, \"EndTime\": 1601798414.247234, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798410.408388}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:14 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=161.786205856 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:14 INFO 139662618720064] #progress_metric: host=algo-1, completed 89 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:14 INFO 139662618720064] #quality_metric: host=algo-1, epoch=358, train loss <loss>=0.886225271225\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:14 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:15 INFO 139662618720064] Epoch[359] Batch[0] avg_epoch_loss=0.826803\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:15 INFO 139662618720064] #quality_metric: host=algo-1, epoch=359, batch=0 train loss <loss>=0.826803267002\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:16 INFO 139662618720064] Epoch[359] Batch[5] avg_epoch_loss=0.868372\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:16 INFO 139662618720064] #quality_metric: host=algo-1, epoch=359, batch=5 train loss <loss>=0.868372370799\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:16 INFO 139662618720064] Epoch[359] Batch [5]#011Speed: 186.07 samples/sec#011loss=0.868372\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:18 INFO 139662618720064] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3866.6770458221436, \"sum\": 3866.6770458221436, \"min\": 3866.6770458221436}}, \"EndTime\": 1601798418.114516, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798414.247315}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:18 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=163.959830165 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:18 INFO 139662618720064] #progress_metric: host=algo-1, completed 90 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:18 INFO 139662618720064] #quality_metric: host=algo-1, epoch=359, train loss <loss>=0.860075086355\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:18 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:18 INFO 139662618720064] Epoch[360] Batch[0] avg_epoch_loss=0.782837\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:18 INFO 139662618720064] #quality_metric: host=algo-1, epoch=360, batch=0 train loss <loss>=0.782836735249\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:20 INFO 139662618720064] Epoch[360] Batch[5] avg_epoch_loss=0.930595\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:20 INFO 139662618720064] #quality_metric: host=algo-1, epoch=360, batch=5 train loss <loss>=0.930594762166\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:20 INFO 139662618720064] Epoch[360] Batch [5]#011Speed: 188.25 samples/sec#011loss=0.930595\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:22 INFO 139662618720064] Epoch[360] Batch[10] avg_epoch_loss=0.922990\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:22 INFO 139662618720064] #quality_metric: host=algo-1, epoch=360, batch=10 train loss <loss>=0.913864016533\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:22 INFO 139662618720064] Epoch[360] Batch [10]#011Speed: 186.84 samples/sec#011loss=0.913864\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:22 INFO 139662618720064] processed a total of 671 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4205.291032791138, \"sum\": 4205.291032791138, \"min\": 4205.291032791138}}, \"EndTime\": 1601798422.320424, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798418.114599}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:22 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=159.556615999 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:22 INFO 139662618720064] #progress_metric: host=algo-1, completed 90 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:22 INFO 139662618720064] #quality_metric: host=algo-1, epoch=360, train loss <loss>=0.922989877788\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:22 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:23 INFO 139662618720064] Epoch[361] Batch[0] avg_epoch_loss=0.876692\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:23 INFO 139662618720064] #quality_metric: host=algo-1, epoch=361, batch=0 train loss <loss>=0.876691699028\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:24 INFO 139662618720064] Epoch[361] Batch[5] avg_epoch_loss=0.848767\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:24 INFO 139662618720064] #quality_metric: host=algo-1, epoch=361, batch=5 train loss <loss>=0.848766674598\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:24 INFO 139662618720064] Epoch[361] Batch [5]#011Speed: 188.73 samples/sec#011loss=0.848767\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:26 INFO 139662618720064] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3846.475124359131, \"sum\": 3846.475124359131, \"min\": 3846.475124359131}}, \"EndTime\": 1601798426.167449, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798422.320498}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:26 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=164.821092925 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:26 INFO 139662618720064] #progress_metric: host=algo-1, completed 90 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:26 INFO 139662618720064] #quality_metric: host=algo-1, epoch=361, train loss <loss>=0.844574809074\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:26 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:26 INFO 139662618720064] Epoch[362] Batch[0] avg_epoch_loss=0.890313\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:26 INFO 139662618720064] #quality_metric: host=algo-1, epoch=362, batch=0 train loss <loss>=0.890313267708\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:28 INFO 139662618720064] Epoch[362] Batch[5] avg_epoch_loss=0.880595\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:28 INFO 139662618720064] #quality_metric: host=algo-1, epoch=362, batch=5 train loss <loss>=0.880594611168\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:28 INFO 139662618720064] Epoch[362] Batch [5]#011Speed: 190.03 samples/sec#011loss=0.880595\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:30 INFO 139662618720064] Epoch[362] Batch[10] avg_epoch_loss=0.880952\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:30 INFO 139662618720064] #quality_metric: host=algo-1, epoch=362, batch=10 train loss <loss>=0.881381618977\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:30 INFO 139662618720064] Epoch[362] Batch [10]#011Speed: 188.77 samples/sec#011loss=0.881382\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:30 INFO 139662618720064] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4194.243907928467, \"sum\": 4194.243907928467, \"min\": 4194.243907928467}}, \"EndTime\": 1601798430.362209, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798426.167529}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:30 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=154.254760502 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:30 INFO 139662618720064] #progress_metric: host=algo-1, completed 90 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:30 INFO 139662618720064] #quality_metric: host=algo-1, epoch=362, train loss <loss>=0.88095234199\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:30 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:31 INFO 139662618720064] Epoch[363] Batch[0] avg_epoch_loss=0.866293\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:31 INFO 139662618720064] #quality_metric: host=algo-1, epoch=363, batch=0 train loss <loss>=0.866293013096\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:32 INFO 139662618720064] Epoch[363] Batch[5] avg_epoch_loss=0.930468\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:32 INFO 139662618720064] #quality_metric: host=algo-1, epoch=363, batch=5 train loss <loss>=0.930468122164\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:32 INFO 139662618720064] Epoch[363] Batch [5]#011Speed: 189.69 samples/sec#011loss=0.930468\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:34 INFO 139662618720064] Epoch[363] Batch[10] avg_epoch_loss=0.867762\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:34 INFO 139662618720064] #quality_metric: host=algo-1, epoch=363, batch=10 train loss <loss>=0.792514228821\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:34 INFO 139662618720064] Epoch[363] Batch [10]#011Speed: 188.06 samples/sec#011loss=0.792514\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:34 INFO 139662618720064] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4191.964149475098, \"sum\": 4191.964149475098, \"min\": 4191.964149475098}}, \"EndTime\": 1601798434.554695, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798430.362289}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:34 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=155.292687004 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:34 INFO 139662618720064] #progress_metric: host=algo-1, completed 91 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:34 INFO 139662618720064] #quality_metric: host=algo-1, epoch=363, train loss <loss>=0.867761807008\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:34 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:35 INFO 139662618720064] Epoch[364] Batch[0] avg_epoch_loss=0.892381\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:35 INFO 139662618720064] #quality_metric: host=algo-1, epoch=364, batch=0 train loss <loss>=0.892381250858\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:37 INFO 139662618720064] Epoch[364] Batch[5] avg_epoch_loss=0.936333\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:37 INFO 139662618720064] #quality_metric: host=algo-1, epoch=364, batch=5 train loss <loss>=0.936332911253\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:37 INFO 139662618720064] Epoch[364] Batch [5]#011Speed: 190.04 samples/sec#011loss=0.936333\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:38 INFO 139662618720064] Epoch[364] Batch[10] avg_epoch_loss=1.021293\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:38 INFO 139662618720064] #quality_metric: host=algo-1, epoch=364, batch=10 train loss <loss>=1.12324463129\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:38 INFO 139662618720064] Epoch[364] Batch [10]#011Speed: 188.94 samples/sec#011loss=1.123245\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:38 INFO 139662618720064] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4214.915990829468, \"sum\": 4214.915990829468, \"min\": 4214.915990829468}}, \"EndTime\": 1601798438.770199, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798434.554776}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:38 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=153.972695263 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:38 INFO 139662618720064] #progress_metric: host=algo-1, completed 91 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:38 INFO 139662618720064] #quality_metric: host=algo-1, epoch=364, train loss <loss>=1.021292784\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:38 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:39 INFO 139662618720064] Epoch[365] Batch[0] avg_epoch_loss=0.797094\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:39 INFO 139662618720064] #quality_metric: host=algo-1, epoch=365, batch=0 train loss <loss>=0.79709404707\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:41 INFO 139662618720064] Epoch[365] Batch[5] avg_epoch_loss=0.875033\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:41 INFO 139662618720064] #quality_metric: host=algo-1, epoch=365, batch=5 train loss <loss>=0.875033468008\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:41 INFO 139662618720064] Epoch[365] Batch [5]#011Speed: 186.90 samples/sec#011loss=0.875033\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:43 INFO 139662618720064] Epoch[365] Batch[10] avg_epoch_loss=0.854301\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:43 INFO 139662618720064] #quality_metric: host=algo-1, epoch=365, batch=10 train loss <loss>=0.829421901703\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:43 INFO 139662618720064] Epoch[365] Batch [10]#011Speed: 188.34 samples/sec#011loss=0.829422\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:43 INFO 139662618720064] processed a total of 687 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4250.409126281738, \"sum\": 4250.409126281738, \"min\": 4250.409126281738}}, \"EndTime\": 1601798443.021132, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798438.770277}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:43 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=161.626866563 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:43 INFO 139662618720064] #progress_metric: host=algo-1, completed 91 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:43 INFO 139662618720064] #quality_metric: host=algo-1, epoch=365, train loss <loss>=0.854300937869\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:43 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:43 INFO 139662618720064] Epoch[366] Batch[0] avg_epoch_loss=1.009906\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:43 INFO 139662618720064] #quality_metric: host=algo-1, epoch=366, batch=0 train loss <loss>=1.00990569592\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:45 INFO 139662618720064] Epoch[366] Batch[5] avg_epoch_loss=0.855792\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:45 INFO 139662618720064] #quality_metric: host=algo-1, epoch=366, batch=5 train loss <loss>=0.855791767438\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:45 INFO 139662618720064] Epoch[366] Batch [5]#011Speed: 188.94 samples/sec#011loss=0.855792\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:46 INFO 139662618720064] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3860.4960441589355, \"sum\": 3860.4960441589355, \"min\": 3860.4960441589355}}, \"EndTime\": 1601798446.882215, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798443.021214}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:46 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=161.891054306 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:46 INFO 139662618720064] #progress_metric: host=algo-1, completed 91 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:46 INFO 139662618720064] #quality_metric: host=algo-1, epoch=366, train loss <loss>=0.891181784868\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:46 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:47 INFO 139662618720064] Epoch[367] Batch[0] avg_epoch_loss=1.019420\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:47 INFO 139662618720064] #quality_metric: host=algo-1, epoch=367, batch=0 train loss <loss>=1.01942038536\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:49 INFO 139662618720064] Epoch[367] Batch[5] avg_epoch_loss=0.932611\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:49 INFO 139662618720064] #quality_metric: host=algo-1, epoch=367, batch=5 train loss <loss>=0.932610799869\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:49 INFO 139662618720064] Epoch[367] Batch [5]#011Speed: 190.31 samples/sec#011loss=0.932611\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:51 INFO 139662618720064] Epoch[367] Batch[10] avg_epoch_loss=0.884531\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:51 INFO 139662618720064] #quality_metric: host=algo-1, epoch=367, batch=10 train loss <loss>=0.826836276054\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:51 INFO 139662618720064] Epoch[367] Batch [10]#011Speed: 189.37 samples/sec#011loss=0.826836\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:51 INFO 139662618720064] processed a total of 672 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4183.049917221069, \"sum\": 4183.049917221069, \"min\": 4183.049917221069}}, \"EndTime\": 1601798451.065835, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798446.882298}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:51 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=160.643829135 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:51 INFO 139662618720064] #progress_metric: host=algo-1, completed 92 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:51 INFO 139662618720064] #quality_metric: host=algo-1, epoch=367, train loss <loss>=0.884531470862\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:51 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:51 INFO 139662618720064] Epoch[368] Batch[0] avg_epoch_loss=1.000982\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:51 INFO 139662618720064] #quality_metric: host=algo-1, epoch=368, batch=0 train loss <loss>=1.0009816885\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:53 INFO 139662618720064] Epoch[368] Batch[5] avg_epoch_loss=0.924616\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:53 INFO 139662618720064] #quality_metric: host=algo-1, epoch=368, batch=5 train loss <loss>=0.92461558183\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:53 INFO 139662618720064] Epoch[368] Batch [5]#011Speed: 189.95 samples/sec#011loss=0.924616\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:55 INFO 139662618720064] processed a total of 609 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3940.443992614746, \"sum\": 3940.443992614746, \"min\": 3940.443992614746}}, \"EndTime\": 1601798455.006832, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798451.065913}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:55 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=154.544828042 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:55 INFO 139662618720064] #progress_metric: host=algo-1, completed 92 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:55 INFO 139662618720064] #quality_metric: host=algo-1, epoch=368, train loss <loss>=0.876952075958\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:55 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:55 INFO 139662618720064] Epoch[369] Batch[0] avg_epoch_loss=0.940389\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:55 INFO 139662618720064] #quality_metric: host=algo-1, epoch=369, batch=0 train loss <loss>=0.940388858318\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:57 INFO 139662618720064] Epoch[369] Batch[5] avg_epoch_loss=0.887769\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:57 INFO 139662618720064] #quality_metric: host=algo-1, epoch=369, batch=5 train loss <loss>=0.887769281864\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:57 INFO 139662618720064] Epoch[369] Batch [5]#011Speed: 189.85 samples/sec#011loss=0.887769\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:59 INFO 139662618720064] Epoch[369] Batch[10] avg_epoch_loss=0.895354\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:59 INFO 139662618720064] #quality_metric: host=algo-1, epoch=369, batch=10 train loss <loss>=0.904455459118\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:59 INFO 139662618720064] Epoch[369] Batch [10]#011Speed: 188.60 samples/sec#011loss=0.904455\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:59 INFO 139662618720064] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4188.950061798096, \"sum\": 4188.950061798096, \"min\": 4188.950061798096}}, \"EndTime\": 1601798459.196367, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798455.006918}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:59 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=157.552906112 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:59 INFO 139662618720064] #progress_metric: host=algo-1, completed 92 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:59 INFO 139662618720064] #quality_metric: host=algo-1, epoch=369, train loss <loss>=0.895353907889\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:00:59 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:00 INFO 139662618720064] Epoch[370] Batch[0] avg_epoch_loss=0.832244\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:00 INFO 139662618720064] #quality_metric: host=algo-1, epoch=370, batch=0 train loss <loss>=0.832243919373\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:01 INFO 139662618720064] Epoch[370] Batch[5] avg_epoch_loss=0.860724\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:01 INFO 139662618720064] #quality_metric: host=algo-1, epoch=370, batch=5 train loss <loss>=0.860723912716\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:01 INFO 139662618720064] Epoch[370] Batch [5]#011Speed: 188.14 samples/sec#011loss=0.860724\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:03 INFO 139662618720064] Epoch[370] Batch[10] avg_epoch_loss=0.851569\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:03 INFO 139662618720064] #quality_metric: host=algo-1, epoch=370, batch=10 train loss <loss>=0.84058214426\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:03 INFO 139662618720064] Epoch[370] Batch [10]#011Speed: 189.21 samples/sec#011loss=0.840582\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:03 INFO 139662618720064] processed a total of 675 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4210.194826126099, \"sum\": 4210.194826126099, \"min\": 4210.194826126099}}, \"EndTime\": 1601798463.407075, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798459.196448}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:03 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=160.320546503 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:03 INFO 139662618720064] #progress_metric: host=algo-1, completed 92 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:03 INFO 139662618720064] #quality_metric: host=algo-1, epoch=370, train loss <loss>=0.851568563418\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:03 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:04 INFO 139662618720064] Epoch[371] Batch[0] avg_epoch_loss=0.970881\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:04 INFO 139662618720064] #quality_metric: host=algo-1, epoch=371, batch=0 train loss <loss>=0.970881164074\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:05 INFO 139662618720064] Epoch[371] Batch[5] avg_epoch_loss=0.874617\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:05 INFO 139662618720064] #quality_metric: host=algo-1, epoch=371, batch=5 train loss <loss>=0.874617209037\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:05 INFO 139662618720064] Epoch[371] Batch [5]#011Speed: 186.11 samples/sec#011loss=0.874617\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:07 INFO 139662618720064] processed a total of 610 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3873.826026916504, \"sum\": 3873.826026916504, \"min\": 3873.826026916504}}, \"EndTime\": 1601798467.28142, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798463.407156}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:07 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=157.462302816 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:07 INFO 139662618720064] #progress_metric: host=algo-1, completed 93 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:07 INFO 139662618720064] #quality_metric: host=algo-1, epoch=371, train loss <loss>=0.897213804722\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:07 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:08 INFO 139662618720064] Epoch[372] Batch[0] avg_epoch_loss=1.085774\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:08 INFO 139662618720064] #quality_metric: host=algo-1, epoch=372, batch=0 train loss <loss>=1.08577406406\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:09 INFO 139662618720064] Epoch[372] Batch[5] avg_epoch_loss=0.895872\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:09 INFO 139662618720064] #quality_metric: host=algo-1, epoch=372, batch=5 train loss <loss>=0.895872424046\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:09 INFO 139662618720064] Epoch[372] Batch [5]#011Speed: 189.67 samples/sec#011loss=0.895872\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:11 INFO 139662618720064] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3848.5751152038574, \"sum\": 3848.5751152038574, \"min\": 3848.5751152038574}}, \"EndTime\": 1601798471.130532, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798467.2815}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:11 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=162.652322195 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:11 INFO 139662618720064] #progress_metric: host=algo-1, completed 93 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:11 INFO 139662618720064] #quality_metric: host=algo-1, epoch=372, train loss <loss>=0.877808874846\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:11 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:11 INFO 139662618720064] Epoch[373] Batch[0] avg_epoch_loss=0.913897\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:11 INFO 139662618720064] #quality_metric: host=algo-1, epoch=373, batch=0 train loss <loss>=0.913896739483\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:13 INFO 139662618720064] Epoch[373] Batch[5] avg_epoch_loss=0.921961\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:13 INFO 139662618720064] #quality_metric: host=algo-1, epoch=373, batch=5 train loss <loss>=0.921960671743\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:13 INFO 139662618720064] Epoch[373] Batch [5]#011Speed: 190.37 samples/sec#011loss=0.921961\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:14 INFO 139662618720064] processed a total of 609 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3857.8639030456543, \"sum\": 3857.8639030456543, \"min\": 3857.8639030456543}}, \"EndTime\": 1601798474.988992, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798471.130617}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:14 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=157.854218342 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:14 INFO 139662618720064] #progress_metric: host=algo-1, completed 93 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:14 INFO 139662618720064] #quality_metric: host=algo-1, epoch=373, train loss <loss>=0.897628307343\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:14 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:15 INFO 139662618720064] Epoch[374] Batch[0] avg_epoch_loss=0.965548\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:15 INFO 139662618720064] #quality_metric: host=algo-1, epoch=374, batch=0 train loss <loss>=0.965548157692\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:17 INFO 139662618720064] Epoch[374] Batch[5] avg_epoch_loss=0.890001\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:17 INFO 139662618720064] #quality_metric: host=algo-1, epoch=374, batch=5 train loss <loss>=0.890001108249\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:17 INFO 139662618720064] Epoch[374] Batch [5]#011Speed: 185.09 samples/sec#011loss=0.890001\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:19 INFO 139662618720064] Epoch[374] Batch[10] avg_epoch_loss=0.880160\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:19 INFO 139662618720064] #quality_metric: host=algo-1, epoch=374, batch=10 train loss <loss>=0.868351376057\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:19 INFO 139662618720064] Epoch[374] Batch [10]#011Speed: 190.21 samples/sec#011loss=0.868351\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:19 INFO 139662618720064] processed a total of 698 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4276.510000228882, \"sum\": 4276.510000228882, \"min\": 4276.510000228882}}, \"EndTime\": 1601798479.266084, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798474.989077}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:19 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=163.21266229 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:19 INFO 139662618720064] #progress_metric: host=algo-1, completed 93 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:19 INFO 139662618720064] #quality_metric: host=algo-1, epoch=374, train loss <loss>=0.880160320889\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:19 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:20 INFO 139662618720064] Epoch[375] Batch[0] avg_epoch_loss=1.029749\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:20 INFO 139662618720064] #quality_metric: host=algo-1, epoch=375, batch=0 train loss <loss>=1.02974879742\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:21 INFO 139662618720064] Epoch[375] Batch[5] avg_epoch_loss=0.986771\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:21 INFO 139662618720064] #quality_metric: host=algo-1, epoch=375, batch=5 train loss <loss>=0.986770679553\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:21 INFO 139662618720064] Epoch[375] Batch [5]#011Speed: 190.53 samples/sec#011loss=0.986771\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:23 INFO 139662618720064] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3859.0941429138184, \"sum\": 3859.0941429138184, \"min\": 3859.0941429138184}}, \"EndTime\": 1601798483.125683, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798479.266164}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:23 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=162.208942603 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:23 INFO 139662618720064] #progress_metric: host=algo-1, completed 94 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:23 INFO 139662618720064] #quality_metric: host=algo-1, epoch=375, train loss <loss>=0.942391705513\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:23 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:23 INFO 139662618720064] Epoch[376] Batch[0] avg_epoch_loss=0.707645\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:23 INFO 139662618720064] #quality_metric: host=algo-1, epoch=376, batch=0 train loss <loss>=0.707645237446\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:25 INFO 139662618720064] Epoch[376] Batch[5] avg_epoch_loss=0.857557\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:25 INFO 139662618720064] #quality_metric: host=algo-1, epoch=376, batch=5 train loss <loss>=0.857557306687\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:25 INFO 139662618720064] Epoch[376] Batch [5]#011Speed: 189.36 samples/sec#011loss=0.857557\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:27 INFO 139662618720064] Epoch[376] Batch[10] avg_epoch_loss=1.098875\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:27 INFO 139662618720064] #quality_metric: host=algo-1, epoch=376, batch=10 train loss <loss>=1.38845723867\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:27 INFO 139662618720064] Epoch[376] Batch [10]#011Speed: 188.28 samples/sec#011loss=1.388457\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:27 INFO 139662618720064] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4204.576015472412, \"sum\": 4204.576015472412, \"min\": 4204.576015472412}}, \"EndTime\": 1601798487.330839, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798483.125769}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:27 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=153.161251992 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:27 INFO 139662618720064] #progress_metric: host=algo-1, completed 94 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:27 INFO 139662618720064] #quality_metric: host=algo-1, epoch=376, train loss <loss>=1.09887545759\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:27 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:28 INFO 139662618720064] Epoch[377] Batch[0] avg_epoch_loss=0.973616\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:28 INFO 139662618720064] #quality_metric: host=algo-1, epoch=377, batch=0 train loss <loss>=0.973616242409\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:29 INFO 139662618720064] Epoch[377] Batch[5] avg_epoch_loss=0.914601\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:29 INFO 139662618720064] #quality_metric: host=algo-1, epoch=377, batch=5 train loss <loss>=0.91460125645\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:29 INFO 139662618720064] Epoch[377] Batch [5]#011Speed: 188.10 samples/sec#011loss=0.914601\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:31 INFO 139662618720064] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3859.037160873413, \"sum\": 3859.037160873413, \"min\": 3859.037160873413}}, \"EndTime\": 1601798491.190411, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798487.33092}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:31 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=164.802878552 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:31 INFO 139662618720064] #progress_metric: host=algo-1, completed 94 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:31 INFO 139662618720064] #quality_metric: host=algo-1, epoch=377, train loss <loss>=0.892949569225\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:31 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:32 INFO 139662618720064] Epoch[378] Batch[0] avg_epoch_loss=0.990122\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:32 INFO 139662618720064] #quality_metric: host=algo-1, epoch=378, batch=0 train loss <loss>=0.990122437477\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:33 INFO 139662618720064] Epoch[378] Batch[5] avg_epoch_loss=1.060360\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:33 INFO 139662618720064] #quality_metric: host=algo-1, epoch=378, batch=5 train loss <loss>=1.06035985549\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:33 INFO 139662618720064] Epoch[378] Batch [5]#011Speed: 189.62 samples/sec#011loss=1.060360\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:35 INFO 139662618720064] Epoch[378] Batch[10] avg_epoch_loss=1.015596\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:35 INFO 139662618720064] #quality_metric: host=algo-1, epoch=378, batch=10 train loss <loss>=0.961880195141\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:35 INFO 139662618720064] Epoch[378] Batch [10]#011Speed: 185.97 samples/sec#011loss=0.961880\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:35 INFO 139662618720064] processed a total of 675 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4221.276044845581, \"sum\": 4221.276044845581, \"min\": 4221.276044845581}}, \"EndTime\": 1601798495.412273, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798491.19049}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:35 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=159.899558535 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:35 INFO 139662618720064] #progress_metric: host=algo-1, completed 94 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:35 INFO 139662618720064] #quality_metric: host=algo-1, epoch=378, train loss <loss>=1.01559637351\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:35 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:36 INFO 139662618720064] Epoch[379] Batch[0] avg_epoch_loss=1.182562\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:36 INFO 139662618720064] #quality_metric: host=algo-1, epoch=379, batch=0 train loss <loss>=1.18256187439\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:37 INFO 139662618720064] Epoch[379] Batch[5] avg_epoch_loss=1.069863\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:37 INFO 139662618720064] #quality_metric: host=algo-1, epoch=379, batch=5 train loss <loss>=1.06986304124\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:37 INFO 139662618720064] Epoch[379] Batch [5]#011Speed: 189.74 samples/sec#011loss=1.069863\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:39 INFO 139662618720064] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3832.2010040283203, \"sum\": 3832.2010040283203, \"min\": 3832.2010040283203}}, \"EndTime\": 1601798499.244993, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798495.412357}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:39 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=163.347234755 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:39 INFO 139662618720064] #progress_metric: host=algo-1, completed 95 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:39 INFO 139662618720064] #quality_metric: host=algo-1, epoch=379, train loss <loss>=0.987619125843\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:39 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:40 INFO 139662618720064] Epoch[380] Batch[0] avg_epoch_loss=0.961323\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:40 INFO 139662618720064] #quality_metric: host=algo-1, epoch=380, batch=0 train loss <loss>=0.961323261261\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:41 INFO 139662618720064] Epoch[380] Batch[5] avg_epoch_loss=1.009143\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:41 INFO 139662618720064] #quality_metric: host=algo-1, epoch=380, batch=5 train loss <loss>=1.00914253791\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:41 INFO 139662618720064] Epoch[380] Batch [5]#011Speed: 189.18 samples/sec#011loss=1.009143\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:43 INFO 139662618720064] processed a total of 612 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3873.6538887023926, \"sum\": 3873.6538887023926, \"min\": 3873.6538887023926}}, \"EndTime\": 1601798503.119232, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798499.245079}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:43 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=157.985262134 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:43 INFO 139662618720064] #progress_metric: host=algo-1, completed 95 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:43 INFO 139662618720064] #quality_metric: host=algo-1, epoch=380, train loss <loss>=0.96589075923\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:43 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:43 INFO 139662618720064] Epoch[381] Batch[0] avg_epoch_loss=0.876209\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:43 INFO 139662618720064] #quality_metric: host=algo-1, epoch=381, batch=0 train loss <loss>=0.876209497452\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:45 INFO 139662618720064] Epoch[381] Batch[5] avg_epoch_loss=0.883701\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:45 INFO 139662618720064] #quality_metric: host=algo-1, epoch=381, batch=5 train loss <loss>=0.883700956901\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:45 INFO 139662618720064] Epoch[381] Batch [5]#011Speed: 187.60 samples/sec#011loss=0.883701\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:46 INFO 139662618720064] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3870.532989501953, \"sum\": 3870.532989501953, \"min\": 3870.532989501953}}, \"EndTime\": 1601798506.990328, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798503.119317}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:46 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=164.829808409 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:46 INFO 139662618720064] #progress_metric: host=algo-1, completed 95 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:46 INFO 139662618720064] #quality_metric: host=algo-1, epoch=381, train loss <loss>=0.905672723055\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:46 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:47 INFO 139662618720064] Epoch[382] Batch[0] avg_epoch_loss=1.134502\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:47 INFO 139662618720064] #quality_metric: host=algo-1, epoch=382, batch=0 train loss <loss>=1.13450217247\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:49 INFO 139662618720064] Epoch[382] Batch[5] avg_epoch_loss=0.940477\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:49 INFO 139662618720064] #quality_metric: host=algo-1, epoch=382, batch=5 train loss <loss>=0.94047738115\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:49 INFO 139662618720064] Epoch[382] Batch [5]#011Speed: 189.15 samples/sec#011loss=0.940477\u001b[0m\n",
      "\n",
      "2020-10-04 08:02:30 Uploading - Uploading generated training model\u001b[34m[10/04/2020 08:01:51 INFO 139662618720064] Epoch[382] Batch[10] avg_epoch_loss=0.915794\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:51 INFO 139662618720064] #quality_metric: host=algo-1, epoch=382, batch=10 train loss <loss>=0.886174666882\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:51 INFO 139662618720064] Epoch[382] Batch [10]#011Speed: 186.31 samples/sec#011loss=0.886175\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:51 INFO 139662618720064] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4239.09592628479, \"sum\": 4239.09592628479, \"min\": 4239.09592628479}}, \"EndTime\": 1601798511.230084, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798506.990413}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:51 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=156.63269733 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:51 INFO 139662618720064] #progress_metric: host=algo-1, completed 95 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:51 INFO 139662618720064] #quality_metric: host=algo-1, epoch=382, train loss <loss>=0.91579432921\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:51 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:52 INFO 139662618720064] Epoch[383] Batch[0] avg_epoch_loss=0.761608\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:52 INFO 139662618720064] #quality_metric: host=algo-1, epoch=383, batch=0 train loss <loss>=0.761607825756\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:53 INFO 139662618720064] Epoch[383] Batch[5] avg_epoch_loss=0.944493\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:53 INFO 139662618720064] #quality_metric: host=algo-1, epoch=383, batch=5 train loss <loss>=0.944493075212\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:53 INFO 139662618720064] Epoch[383] Batch [5]#011Speed: 188.25 samples/sec#011loss=0.944493\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:55 INFO 139662618720064] Epoch[383] Batch[10] avg_epoch_loss=1.010268\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:55 INFO 139662618720064] #quality_metric: host=algo-1, epoch=383, batch=10 train loss <loss>=1.08919855356\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:55 INFO 139662618720064] Epoch[383] Batch [10]#011Speed: 185.17 samples/sec#011loss=1.089199\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:55 INFO 139662618720064] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4277.348041534424, \"sum\": 4277.348041534424, \"min\": 4277.348041534424}}, \"EndTime\": 1601798515.507973, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798511.230165}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:55 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=149.855568501 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:55 INFO 139662618720064] #progress_metric: host=algo-1, completed 96 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:55 INFO 139662618720064] #quality_metric: host=algo-1, epoch=383, train loss <loss>=1.01026829264\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:55 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:56 INFO 139662618720064] Epoch[384] Batch[0] avg_epoch_loss=0.806250\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:56 INFO 139662618720064] #quality_metric: host=algo-1, epoch=384, batch=0 train loss <loss>=0.806249916553\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:57 INFO 139662618720064] Epoch[384] Batch[5] avg_epoch_loss=0.871276\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:57 INFO 139662618720064] #quality_metric: host=algo-1, epoch=384, batch=5 train loss <loss>=0.871276130279\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:57 INFO 139662618720064] Epoch[384] Batch [5]#011Speed: 188.28 samples/sec#011loss=0.871276\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:59 INFO 139662618720064] processed a total of 611 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3844.1920280456543, \"sum\": 3844.1920280456543, \"min\": 3844.1920280456543}}, \"EndTime\": 1601798519.352706, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798515.508037}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:59 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=158.936034429 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:59 INFO 139662618720064] #progress_metric: host=algo-1, completed 96 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:59 INFO 139662618720064] #quality_metric: host=algo-1, epoch=384, train loss <loss>=0.822476890683\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:01:59 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:00 INFO 139662618720064] Epoch[385] Batch[0] avg_epoch_loss=0.719643\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:00 INFO 139662618720064] #quality_metric: host=algo-1, epoch=385, batch=0 train loss <loss>=0.719643354416\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:01 INFO 139662618720064] Epoch[385] Batch[5] avg_epoch_loss=0.827374\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:01 INFO 139662618720064] #quality_metric: host=algo-1, epoch=385, batch=5 train loss <loss>=0.827373633782\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:01 INFO 139662618720064] Epoch[385] Batch [5]#011Speed: 186.40 samples/sec#011loss=0.827374\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:03 INFO 139662618720064] Epoch[385] Batch[10] avg_epoch_loss=0.913003\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:03 INFO 139662618720064] #quality_metric: host=algo-1, epoch=385, batch=10 train loss <loss>=1.0157571435\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:03 INFO 139662618720064] Epoch[385] Batch [10]#011Speed: 187.74 samples/sec#011loss=1.015757\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:03 INFO 139662618720064] processed a total of 694 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4252.618789672852, \"sum\": 4252.618789672852, \"min\": 4252.618789672852}}, \"EndTime\": 1601798523.605859, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798519.352788}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:03 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=163.188674525 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:03 INFO 139662618720064] #progress_metric: host=algo-1, completed 96 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:03 INFO 139662618720064] #quality_metric: host=algo-1, epoch=385, train loss <loss>=0.913002501835\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:03 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:04 INFO 139662618720064] Epoch[386] Batch[0] avg_epoch_loss=1.014761\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:04 INFO 139662618720064] #quality_metric: host=algo-1, epoch=386, batch=0 train loss <loss>=1.01476061344\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:06 INFO 139662618720064] Epoch[386] Batch[5] avg_epoch_loss=0.820277\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:06 INFO 139662618720064] #quality_metric: host=algo-1, epoch=386, batch=5 train loss <loss>=0.820277035236\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:06 INFO 139662618720064] Epoch[386] Batch [5]#011Speed: 183.27 samples/sec#011loss=0.820277\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:07 INFO 139662618720064] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3880.044937133789, \"sum\": 3880.044937133789, \"min\": 3880.044937133789}}, \"EndTime\": 1601798527.486471, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798523.605944}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:07 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=162.36401566 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:07 INFO 139662618720064] #progress_metric: host=algo-1, completed 96 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:07 INFO 139662618720064] #quality_metric: host=algo-1, epoch=386, train loss <loss>=0.822577768564\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:07 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:08 INFO 139662618720064] Epoch[387] Batch[0] avg_epoch_loss=0.753877\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:08 INFO 139662618720064] #quality_metric: host=algo-1, epoch=387, batch=0 train loss <loss>=0.753876566887\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:09 INFO 139662618720064] Epoch[387] Batch[5] avg_epoch_loss=0.786328\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:09 INFO 139662618720064] #quality_metric: host=algo-1, epoch=387, batch=5 train loss <loss>=0.786327928305\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:09 INFO 139662618720064] Epoch[387] Batch [5]#011Speed: 189.39 samples/sec#011loss=0.786328\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:11 INFO 139662618720064] processed a total of 608 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3869.1649436950684, \"sum\": 3869.1649436950684, \"min\": 3869.1649436950684}}, \"EndTime\": 1601798531.356233, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798527.486555}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:11 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=157.1348153 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:11 INFO 139662618720064] #progress_metric: host=algo-1, completed 97 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:11 INFO 139662618720064] #quality_metric: host=algo-1, epoch=387, train loss <loss>=0.801132124662\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:11 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:12 INFO 139662618720064] Epoch[388] Batch[0] avg_epoch_loss=0.896632\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:12 INFO 139662618720064] #quality_metric: host=algo-1, epoch=388, batch=0 train loss <loss>=0.896632015705\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:13 INFO 139662618720064] Epoch[388] Batch[5] avg_epoch_loss=0.834430\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:13 INFO 139662618720064] #quality_metric: host=algo-1, epoch=388, batch=5 train loss <loss>=0.83443030715\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:13 INFO 139662618720064] Epoch[388] Batch [5]#011Speed: 187.64 samples/sec#011loss=0.834430\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:15 INFO 139662618720064] processed a total of 622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3974.900960922241, \"sum\": 3974.900960922241, \"min\": 3974.900960922241}}, \"EndTime\": 1601798535.331779, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798531.356317}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:15 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=156.47695878 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:15 INFO 139662618720064] #progress_metric: host=algo-1, completed 97 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:15 INFO 139662618720064] #quality_metric: host=algo-1, epoch=388, train loss <loss>=0.848994904757\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:15 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:16 INFO 139662618720064] Epoch[389] Batch[0] avg_epoch_loss=1.122581\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:16 INFO 139662618720064] #quality_metric: host=algo-1, epoch=389, batch=0 train loss <loss>=1.12258124352\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:17 INFO 139662618720064] Epoch[389] Batch[5] avg_epoch_loss=0.983940\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:17 INFO 139662618720064] #quality_metric: host=algo-1, epoch=389, batch=5 train loss <loss>=0.98394048214\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:17 INFO 139662618720064] Epoch[389] Batch [5]#011Speed: 188.28 samples/sec#011loss=0.983940\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:19 INFO 139662618720064] Epoch[389] Batch[10] avg_epoch_loss=0.999753\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:19 INFO 139662618720064] #quality_metric: host=algo-1, epoch=389, batch=10 train loss <loss>=1.01872706413\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:19 INFO 139662618720064] Epoch[389] Batch [10]#011Speed: 189.18 samples/sec#011loss=1.018727\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:19 INFO 139662618720064] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4215.101957321167, \"sum\": 4215.101957321167, \"min\": 4215.101957321167}}, \"EndTime\": 1601798539.547608, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798535.331863}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:19 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=153.728666718 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:19 INFO 139662618720064] #progress_metric: host=algo-1, completed 97 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:19 INFO 139662618720064] #quality_metric: host=algo-1, epoch=389, train loss <loss>=0.999752564864\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:19 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:20 INFO 139662618720064] Epoch[390] Batch[0] avg_epoch_loss=0.989634\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:20 INFO 139662618720064] #quality_metric: host=algo-1, epoch=390, batch=0 train loss <loss>=0.989634215832\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:22 INFO 139662618720064] Epoch[390] Batch[5] avg_epoch_loss=0.874073\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:22 INFO 139662618720064] #quality_metric: host=algo-1, epoch=390, batch=5 train loss <loss>=0.874072591464\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:22 INFO 139662618720064] Epoch[390] Batch [5]#011Speed: 189.01 samples/sec#011loss=0.874073\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:23 INFO 139662618720064] processed a total of 617 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3857.8760623931885, \"sum\": 3857.8760623931885, \"min\": 3857.8760623931885}}, \"EndTime\": 1601798543.406008, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798539.547686}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:23 INFO 139662618720064] #throughput_metric: host=algo-1, train throughput=159.927342809 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:23 INFO 139662618720064] #progress_metric: host=algo-1, completed 97 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:23 INFO 139662618720064] #quality_metric: host=algo-1, epoch=390, train loss <loss>=0.905109971762\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:23 INFO 139662618720064] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:23 INFO 139662618720064] Loading parameters from best epoch (350)\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.deserialize.time\": {\"count\": 1, \"max\": 40.95602035522461, \"sum\": 40.95602035522461, \"min\": 40.95602035522461}}, \"EndTime\": 1601798543.447592, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798543.406093}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:23 INFO 139662618720064] stopping training now\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:23 INFO 139662618720064] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:23 INFO 139662618720064] Final loss: 0.768003640527 (occurred at epoch 350)\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:23 INFO 139662618720064] #quality_metric: host=algo-1, train final_loss <loss>=0.768003640527\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:23 WARNING 139662618720064] You are using large values for `context_length` and/or `prediction_length`. The following step may take some time. If the step crashes, use an instance with more memory or reduce these two parameters.\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:23 INFO 139662618720064] Worker algo-1 finished training.\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:23 WARNING 139662618720064] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:23 INFO 139662618720064] All workers finished. Serializing model for prediction.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 3064.237117767334, \"sum\": 3064.237117767334, \"min\": 3064.237117767334}}, \"EndTime\": 1601798546.512759, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798543.447662}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:26 INFO 139662618720064] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 3529.973030090332, \"sum\": 3529.973030090332, \"min\": 3529.973030090332}}, \"EndTime\": 1601798546.978453, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798546.51286}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:26 INFO 139662618720064] Serializing to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:27 INFO 139662618720064] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.serialize.time\": {\"count\": 1, \"max\": 72.7839469909668, \"sum\": 72.7839469909668, \"min\": 72.7839469909668}}, \"EndTime\": 1601798547.051343, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798546.978514}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:27 INFO 139662618720064] Successfully serialized the model for prediction.\u001b[0m\n",
      "\u001b[34m[10/04/2020 08:02:27 INFO 139662618720064] No test data passed, skipping evaluation.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 1593181.3712120056, \"sum\": 1593181.3712120056, \"min\": 1593181.3712120056}, \"setuptime\": {\"count\": 1, \"max\": 8.507013320922852, \"sum\": 8.507013320922852, \"min\": 8.507013320922852}}, \"EndTime\": 1601798547.161262, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601798547.0514}\n",
      "\u001b[0m\n",
      "\n",
      "2020-10-04 08:02:52 Completed - Training job completed\n",
      "Training seconds: 1663\n",
      "Billable seconds: 1663\n"
     ]
    }
   ],
   "source": [
    "sagemaker_session.logs_for_job(estimator.latest_training_job.name, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prediction\n",
    "\n",
    "When deploying trained model to SageMaker endpoint, we will pass below utility class together: this allows to return a dcitionary encoding for requests using pandas.Series objects rather than raw JSON strings.\n",
    "\n",
    "In generel, you may copy this code to your system but slightly change some numbsers such as time delta, prediction lengths, etc. For more information, you can refer to the [RealTimePredictor in SageMaker SDK](https://sagemaker.readthedocs.io/en/v1.2.3/predictors.html) which is the parent of this utility class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepARPredictor(sagemaker.predictor.RealTimePredictor):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, content_type=sagemaker.content_types.CONTENT_TYPE_JSON, **kwargs)\n",
    "        \n",
    "    def predict(self, ts, cat=None, dynamic_feat=None, \n",
    "                num_samples=100, return_samples=False, quantiles=[\"0.1\", \"0.5\", \"0.9\"]):\n",
    "        \"\"\"Requests the prediction of for the time series listed in `ts`, each with the (optional)\n",
    "        corresponding category listed in `cat`.\n",
    "        \n",
    "        ts -- `pandas.Series` object, the time series to predict\n",
    "        cat -- integer, the group associated to the time series (default: None)\n",
    "        num_samples -- integer, number of samples to compute at prediction time (default: 100)\n",
    "        return_samples -- boolean indicating whether to include samples in the response (default: False)\n",
    "        quantiles -- list of strings specifying the quantiles to compute (default: [\"0.1\", \"0.5\", \"0.9\"])\n",
    "        \n",
    "        Return value: list of `pandas.DataFrame` objects, each containing the predictions\n",
    "        \"\"\"\n",
    "        prediction_time = ts.index[-1] + datetime.timedelta(minutes=10)\n",
    "#         prediction_time = 144\n",
    "        quantiles = [str(q) for q in quantiles]\n",
    "        req = self.__encode_request(ts, cat, dynamic_feat, num_samples, return_samples, quantiles)\n",
    "        res = super(DeepARPredictor, self).predict(req)\n",
    "        return self.__decode_response(res, ts.index.freq, prediction_time, return_samples)\n",
    "    \n",
    "    def __encode_request(self, ts, cat, dynamic_feat, num_samples, return_samples, quantiles):\n",
    "        instance = series_to_dict(ts, cat if cat is not None else None, dynamic_feat if dynamic_feat else None)\n",
    "\n",
    "        configuration = {\n",
    "            \"num_samples\": num_samples,\n",
    "            \"output_types\": [\"quantiles\", \"samples\"] if return_samples else [\"quantiles\"],\n",
    "            \"quantiles\": quantiles\n",
    "        }\n",
    "        \n",
    "        http_request_data = {\n",
    "            \"instances\": [instance],\n",
    "            \"configuration\": configuration\n",
    "        }\n",
    "        \n",
    "        return json.dumps(http_request_data).encode('utf-8')\n",
    "    \n",
    "    def __decode_response(self, response, freq, prediction_time, return_samples):\n",
    "        # we only sent one time series so we only receive one in return\n",
    "        # however, if possible one will pass multiple time series as predictions will then be faster\n",
    "        predictions = json.loads(response.decode('utf-8'))['predictions'][0]\n",
    "        prediction_length = len(next(iter(predictions['quantiles'].values())))\n",
    "        \n",
    "        prediction_index = pd.date_range(prediction_time, prediction_time + freq * (prediction_length-1), freq=freq)\n",
    "        \n",
    "        if return_samples:\n",
    "            dict_of_samples = {'sample_' + str(i): s for i, s in enumerate(predictions['samples'])}\n",
    "        else:\n",
    "            dict_of_samples = {}\n",
    "        return pd.DataFrame(data={**predictions['quantiles'], **dict_of_samples}, index=prediction_index)\n",
    "\n",
    "    def set_frequency(self, freq):\n",
    "        self.freq = freq\n",
    "        \n",
    "def encode_target(ts):\n",
    "    return [x if np.isfinite(x) else \"NaN\" for x in ts]        \n",
    "\n",
    "def series_to_dict(ts, cat=None, dynamic_feat=None):\n",
    "    \"\"\"Given a pandas.Series object, returns a dictionary encoding the time series.\n",
    "\n",
    "    ts -- a pands.Series object with the target time series\n",
    "    cat -- an integer indicating the time series category\n",
    "\n",
    "    Return value: a dictionary\n",
    "    \"\"\"\n",
    "    obj = {\"start\": str(ts.index[0]), \"target\": encode_target(ts)}\n",
    "    if cat is not None:\n",
    "        obj[\"cat\"] = cat\n",
    "    if dynamic_feat is not None:\n",
    "        obj[\"dynamic_feat\"] = dynamic_feat        \n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's deploy the model with below code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "# predictor.delete_endpoint()\n",
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    predictor_cls=DeepARPredictor, \n",
    "    wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass the test dataset in CSV format to the inference endpoint. Note that the serializer and deserializer will automatically take care of the datatype conversion from Numpy NDArrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-03-01 00:00:00    24.0\n",
       "2012-03-01 00:10:00    22.0\n",
       "2012-03-01 00:20:00    20.0\n",
       "2012-03-01 00:30:00    17.0\n",
       "2012-03-01 00:40:00    15.0\n",
       "                       ... \n",
       "2012-03-14 23:10:00    60.0\n",
       "2012-03-14 23:20:00    60.0\n",
       "2012-03-14 23:30:00    38.0\n",
       "2012-03-14 23:40:00    36.0\n",
       "2012-03-14 23:50:00    29.0\n",
       "Freq: 10T, Length: 2016, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.Series(training_data[0]['target'][:-144])\n",
    "test_data.index=pd.date_range(training_data[0]['start'], \n",
    "                              datetime.datetime.strptime(training_data[0]['start'],'%Y-%m-%d %H:%M:%S')+datetime.timedelta(minutes=10*2015), \n",
    "                              freq='10T')\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.9</th>\n",
       "      <th>0.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-03-15 00:00:00</th>\n",
       "      <td>17.826349</td>\n",
       "      <td>28.005518</td>\n",
       "      <td>23.360205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-15 00:10:00</th>\n",
       "      <td>13.563330</td>\n",
       "      <td>21.258057</td>\n",
       "      <td>17.840389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-15 00:20:00</th>\n",
       "      <td>9.901986</td>\n",
       "      <td>17.281578</td>\n",
       "      <td>13.462849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-15 00:30:00</th>\n",
       "      <td>6.711700</td>\n",
       "      <td>14.006804</td>\n",
       "      <td>10.369482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-15 00:40:00</th>\n",
       "      <td>1.495702</td>\n",
       "      <td>4.387959</td>\n",
       "      <td>3.201825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-15 23:10:00</th>\n",
       "      <td>41.342560</td>\n",
       "      <td>55.319458</td>\n",
       "      <td>48.083168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-15 23:20:00</th>\n",
       "      <td>46.127647</td>\n",
       "      <td>61.442574</td>\n",
       "      <td>54.074722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-15 23:30:00</th>\n",
       "      <td>34.619801</td>\n",
       "      <td>46.944485</td>\n",
       "      <td>40.545750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-15 23:40:00</th>\n",
       "      <td>25.640291</td>\n",
       "      <td>35.685738</td>\n",
       "      <td>30.381281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-15 23:50:00</th>\n",
       "      <td>31.545135</td>\n",
       "      <td>41.270714</td>\n",
       "      <td>37.066158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows Ã 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0.1        0.9        0.5\n",
       "2012-03-15 00:00:00  17.826349  28.005518  23.360205\n",
       "2012-03-15 00:10:00  13.563330  21.258057  17.840389\n",
       "2012-03-15 00:20:00   9.901986  17.281578  13.462849\n",
       "2012-03-15 00:30:00   6.711700  14.006804  10.369482\n",
       "2012-03-15 00:40:00   1.495702   4.387959   3.201825\n",
       "...                        ...        ...        ...\n",
       "2012-03-15 23:10:00  41.342560  55.319458  48.083168\n",
       "2012-03-15 23:20:00  46.127647  61.442574  54.074722\n",
       "2012-03-15 23:30:00  34.619801  46.944485  40.545750\n",
       "2012-03-15 23:40:00  25.640291  35.685738  30.381281\n",
       "2012-03-15 23:50:00  31.545135  41.270714  37.066158\n",
       "\n",
       "[144 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = predictor.predict(ts=test_data, \n",
    "                               dynamic_feat=training_data[0]['dynamic_feat'],\n",
    "                               quantiles=[0.10, 0.5, 0.90])\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-03-01 00:00:00    24.0\n",
       "2012-03-01 00:10:00    22.0\n",
       "2012-03-01 00:20:00    20.0\n",
       "2012-03-01 00:30:00    17.0\n",
       "2012-03-01 00:40:00    15.0\n",
       "                       ... \n",
       "2012-03-15 23:10:00    68.0\n",
       "2012-03-15 23:20:00    70.0\n",
       "2012-03-15 23:30:00    50.0\n",
       "2012-03-15 23:40:00    45.0\n",
       "2012-03-15 23:50:00    37.0\n",
       "Freq: 10T, Length: 2160, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data = pd.Series(training_data[0]['target'])\n",
    "full_data.index=pd.date_range(training_data[0]['start'], \n",
    "                              datetime.datetime.strptime(training_data[0]['start'],'%Y-%m-%d %H:%M:%S')+datetime.timedelta(minutes=10*2159), \n",
    "                              freq='10T')\n",
    "full_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Plotting the Prediction\n",
    "\n",
    "Now we can use the previously created predictor object. To check the result, we will predict data after March 15, 2012 00:00 used for training, and compare the results with the original training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "anomalies = full_data['2012-03-15 00:00:00':][full_data['2012-03-15 00:00:00':].values-prediction['0.9'].values > 0]\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(full_data['2012-03-14 14:20:00':])\n",
    "plt.plot(prediction)\n",
    "plt.fill_between(prediction.index, prediction['0.9'],prediction['0.1'], alpha=0.5)\n",
    "plt.scatter(anomalies.index, anomalies.values, color='red')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can aggregate values to smooth out the noisy result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample_prediction = prediction.resample('2H').sum()\n",
    "resample_full_data = full_data['2012-03-13 23:20:00':].resample('2H').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following figure is the result of resampling the prediction results from 10 minutes to 2 hours. Depending on the business case, the forecasting unit may be different from the one used in the training. If you resample them with larger units of time, the prediction results will be smoother. This kind of manipulation can be used to prevent too much frequent noise alarms when setting the upper/lower monitoring limit with the prediction range of time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "resample_anomalies = resample_full_data['2012-03-15 00:00:00':][resample_full_data['2012-03-15 00:00:00':].values-resample_prediction['0.9'].values > 0]\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(resample_full_data['2012-03-14 14:20:00':])\n",
    "plt.plot(resample_prediction)\n",
    "plt.fill_between(resample_prediction.index, resample_prediction['0.9'],resample_prediction['0.1'], alpha=0.5)\n",
    "plt.scatter(resample_anomalies.index, resample_anomalies.values, color='red')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop and Delete the Endpoint\n",
    "\n",
    "Finally, we should delete the endpoint before we close the notebook.\n",
    "\n",
    "To do so execute the cell below. Alternately, you can navigate to the \"Endpoints\" tab in the SageMaker console, select the endpoint with the name stored in the variable endpoint_name, and select \"Delete\" from the \"Actions\" dropdown menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.Session().delete_endpoint(predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
